{"meta":{"title":"Yvan Blog","subtitle":"Schrödinger","description":"","author":"Yvan Yang","url":"http://fyvan.github.io","root":"/"},"pages":[{"title":"404","date":"2019-10-28T08:41:10.000Z","updated":"2020-05-24T07:27:31.413Z","comments":true,"path":"404.html","permalink":"http://fyvan.github.io/404.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"关于","date":"2018-09-30T09:25:30.000Z","updated":"2020-05-24T05:30:21.600Z","comments":true,"path":"about/index.html","permalink":"http://fyvan.github.io/about/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"分类","date":"2018-09-30T09:25:30.000Z","updated":"2020-05-24T05:30:34.255Z","comments":true,"path":"categories/index.html","permalink":"http://fyvan.github.io/categories/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"标签","date":"2018-09-30T10:23:38.000Z","updated":"2020-05-24T05:31:27.006Z","comments":true,"path":"tags/index.html","permalink":"http://fyvan.github.io/tags/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"留言板","date":"2018-09-30T09:25:30.000Z","updated":"2020-05-24T05:30:51.841Z","comments":true,"path":"contact/index.html","permalink":"http://fyvan.github.io/contact/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"友情链接","date":"2018-12-12T13:25:30.000Z","updated":"2020-05-24T05:31:13.584Z","comments":true,"path":"friends/index.html","permalink":"http://fyvan.github.io/friends/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"}],"posts":[{"title":"多线程与高并发1-多线程","slug":"多线程与高并发1-多线程","date":"2020-07-06T05:53:54.572Z","updated":"2020-07-06T07:27:33.433Z","comments":true,"path":"undefined/9aed.html","link":"","permalink":"http://fyvan.github.io/undefined/9aed.html","excerpt":"","text":"1. 什么是线程线程（thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一个进程可以开启多个线程。 多线程扩展了多进程的概念，使得同一个进程可以同时并发处理多个任务。 简而言之，一个程序运行后至少一个进程，一个进程里包含多个线程。 如果一个进程只有一个线程，这种程序被称为单线程。 如果一个进程中有多条执行路径被称为多线程程序。 代码测试: WhatIsThread是运行的一个程序进程,那么这个进程中有两个线程分别是T1和main这两个线程在运行 //什么是线程 public class WhatIsThread { private static class T1 extends Thread{ @Override public void run(){ for (int i = 0; i{ for (int i=0; i{ for (int i=0; i{ for (int i=0; i{ for (int i=0; i{ try{ t1.join(); }catch (InterruptedException e){ e.printStackTrace(); } for (int i=0; i { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"多线程与高并发","slug":"多线程与高并发","permalink":"http://fyvan.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"http://fyvan.github.io/tags/Thread/"}],"author":"fyang"},{"title":"hello hexo","slug":"SpringBoot-解析-启动流程","date":"2020-06-19T13:08:56.581Z","updated":"2020-06-20T03:55:28.003Z","comments":true,"path":"undefined/b659.html","link":"","permalink":"http://fyvan.github.io/undefined/b659.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. 从SPring Factories文件中去除初始化器和监听器 初始化器一共7个 监听器11个 只去取出了类名和包名 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[],"tags":[]},{"title":"JVM垃圾回收器","slug":"Java-JVM-垃圾回收算法","date":"2020-06-18T08:39:34.863Z","updated":"2020-07-06T07:28:10.815Z","comments":true,"path":"undefined/86cc.html","link":"","permalink":"http://fyvan.github.io/undefined/86cc.html","excerpt":"","text":"JVM垃圾收集器的前世今生1. JVM垃圾收集器的发展历程HotSpot的垃圾收集器从Serial发展到CMS再到G1，经历了逾二十年时间，经过了数百上千万台服务器上的应用实践。从JDK1.3开始，直到最近的JDK13，从Serial收集器到Paralle收集器，再到Concurrent Mark Sweep和 Garbage First收集器，直到现在垃圾收集器的最前成果 Shenandoah 和ZGC，用户线程的停顿时间在持续缩短，但是仍然无法彻底消除，探索更优秀的垃圾收集器的工作，任重而道远。 Serial 串行收集器 新生代收集器、最基本、发展历史最久（jdk1.3之前）、单线程、基于复制算法 Serial Old 串行老年代收集器 老年代版本的Serial收集器、单线程、基于标记-整理算法 ParNew 收集器 Serial的多线程版本、新生代收集器、多线程、基于复制算法、关注用户停顿时间 Parallel Scavenge 收集器 新生代收集器，基于复制算法，并行的多线程、关注吞吐量 Parallel Old收集器 Parallel Scavenge的老年代版本，使用多线程和“标记-整理”算法 CMS（Conturrent Mark Sweep）收集器 并发、基于标记-清除算法 G1（Garbage-First）收集器 并行与并 发、分代收集、空间整合 Shenandoah 支持并发的整理算法、基于读写屏障、旋转指针 ZGC 支持并发收集、基于动态Region、染色指针、虚拟内存映射 Epsilon垃圾收集器 没有操作的垃圾收集器、处理内存分配但不实现任何实际内存回收机制的GC 2. JVM垃圾回收算法判断Java中对象存活的算法 引用计数法 可达性分析算法 垃圾回收算法 标记-清除算法 标记-复制算法 标记-整理算法 分代收集算法 3. 引用计数法一个比较普通的方法就是当对象在创建的时候,就给对象创建一个对象计数器,每当有一个地方引用到这个对象的时候,计数器加一;当引用失效的时候,计数器减一;任何时候计数器为0的对象就是不可能被引用的,就是我们所认知的 —死亡对象. 引用计数算法的实现比较简单,判定效率也较高,在大部分情况下它都是一个不错的算法,也有一些比较著名的应用案例,例如微软公司的COM(Component Object Mode)技术,使用ActionScript3的FlashPlayer等技术都引用了计数算法进行内存呢管理. 主流的Java虚拟机里面没有用到引用计数算法来管理内存,其中最主要的问题就是它很难解决对象之间相互循环引用的问题. 4. 对象可达性分析根搜索方式是通过一些GC Roots对象作为起点, 从这些节点开始往下搜索, 搜索通过的路径成为引用链(ReferenceChain), 当一个对象没有被GC Roots的引用链连接的时候, 说明这个对象是不可用的 5. JVM垃圾回收算法之–标记-清除算法清除算法是第一种使用和比较完善的垃圾回收算法, 算法分为两个过程: 标记正所有需要回收的对象 标记完成后清除被标记的对象 其标记的过程就是判断对象有效性, 执行可达性分析的过程. 6. JVM垃圾回收算法之–分代回收JVM对象的生存周期总体可分为三种: 新生代、老年代和永久代.(JDK1.8废弃永久代,由元空间代替) 根据各个年代的特点采用适当的垃圾回收算法 新生代的对象在每次垃圾回收时,都会有大量的对象死去,只有很少一部分存活,那就可以选择标记-复制算法. 在新生代中每次死亡对象约占98%, 那么在标记-复制算法中就不需要按照1:1的比例来划分内存区域, 而是将新生代细分为了一块较大的Eden和两块较小的Survivor区域,HotSpot中默认这两块区域的大小比例为8:2. 每次新生代可用区域为Eden加上其中一块Survivor区域,共90%的内存空间,这样就只有10%的内存空间处于被闲置状态. 在进行垃圾回收时, 存活的对象被转移到原本处在”空闲的”Eden区域. 如果某次垃圾回收之后,存活的对象所占空间远大于这10%的内存空间时, 也就是Survivor空间不够时,需要额外的空间来担保,通常是将这些对象转移到老年代. 对于老年代来说,大部分对象都处于存活状态.同时,如果一个大对象需要在该区域进行分配,而内存空间又不足,那么在没有外部内存空间担保的情况下,就必须选用标记-清除或者标记-整理算法来进行垃圾回收. 7. JVM垃圾回收算法之–分代划分Eden区 Eden区位于Java堆的年轻代，是新对象分配内存的地方，由于堆是所有线程共享的，因此在堆上分配内存需要加锁。而Sun JDK为提升效率，会为每个新建的线程在Eden上分配一块独立的空间由该线程独享，这块空间称为TLAB（Thread Local Allocation Buffer）。在TLAB上分配内存不需要加锁，因此JVM在给线程中的对象分配内存时会尽量在TLAB上分配。如果对象过大或TLAB用完，则仍然在堆上进行分配。如果Eden区内存也用完了，则会进行一次Minor GC（young GC）。 Survival from to Survival区与Eden区相同都在Java堆的年轻代。Survival区有两块，一块称为from区，另一块为to区，这两个区是相对的，在发生一次Minor GC后，from区就会和to区互换。在发生Minor GC时，Eden区和Survivalfrom区会把一些仍然存活的对象复制进Survival to区，并清除内存。Survival to区会把一些存活得足够旧的对象移至年老代。 GC有两种类型: MinorGC和Full GC MinorGC 一般情况下, 当新对象生成, 并且在Eden申请空间失败时, 就会触发MinorGC, 对Eden区域进行GC, 清除非存活对象, 并且把尚且存活的对象移动到Survivor区. 然后整理Survivor的两个区. 这种方式的GC是对年轻代的Eden区进行,不会影响到老年代. 因为大部分对象都是从Eden区开始的, 同时Eden区不会分配的很大,所以Eden区的GC会频繁进行. 因而, 一般在这里需要使用速度快、效率高的算法, 使Eden区能尽快空闲出来. Full GC 对整个堆进行整理, 包括Young、Tenured和Perm. Full GC因为需要对整个堆进行回收, 所以比Scavenge GC要慢, 因此应该尽可能减少Full GC的次数. 在堆JVM调优的过程中,很大一部分工作就是对于Full GC的调节. 8. 垃圾回收器8.1 Serial收集器 Serial收集器是最基本、发展历史最悠久的收集器,JDK1.3.1之前虚拟机新生代收集的唯一选择 Serial收集器是一个单线程的收集器. “单线程”的意义不仅仅是它只会用一个CPU或者一条收集器线程去完成垃圾收集工作,更重要的是它在垃圾收集的时候, 必须暂停其它所有工作的线程,直到它收集结束 Serial收集器是HotSpot虚拟机运行在Client模式下的默认新生代收集器 Serial收集器具有简单而搞笑, 由于没有线程交互的开销, 可以获得最高的但像成收集效率(单CPU环境) 开启参数 : --XX:+UseSerialGC 8.2 ParNew收集器 ParNew收集器是Serial收集器的多线程版本, 除了使用多线程进行垃圾收集之外, 其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The Word、对象分配规则、回收策略等斗鱼Serial收集器一致 ParNew收集器是许多运行在Server模式下的虚拟机首选的新生代收集器,其中一个原因是,除了Serial收集器之外, 目前只有ParNew收集器能与CMS收集器配合工作 并行(Parallel): 指多条垃圾收集线程并行工作,但此时用户线程处于仍然等待状态 并发(Concurrent): 指用户线程与垃圾收集线程同时执行(但不一定是并行,可能是交替执行), 用户线程继续工作, 而垃圾收集程序运行在另外一个CPU上 优点: 在多CPU时,比Serial效率高 缺点: 收集过程暂停所有应用程序线程, 单CPU时比Serial效率差 使用算法: 复制算法 使用范围: 新生代 应用: 运行在Server模式下的虚拟机中首选的新生代收集器 开启参数: 8.3 Serial Old收集器 Serial Old收集器是Serial收集器的老年代版本, 它同样是一个单线程收集器,使用”标记-整理”算法 Serial Old收集器主要用于Client模式下的虚拟机使用 Server模式下的两大用途 : 在JDK1.5及之前的版本与Parallel Scavenge收集器搭配使用 作为CMS收集器的后被方案,在并发收集发生Conturrent Mode Failure时使用 8.4 Parallel Scavenge收集器 Parallel Scavenge收集器也是一个新生代收集器, 它也是使用复制算法的收集器,有实并行的多线程收集器, 和 ParNew类似, 但是关注点不同 Parallel Scavenge收集器的目标是达到一个可控制的吞吐量. 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值, 即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间), 如果虚拟机总共运行需要100分钟, 其中垃圾收集花掉1分钟, 那么吞吐量就是99%. 适用场景: 高吞吐量则可用最高效率地利用CPU时间, 尽快地完成程序的运算任务, 主要适合在受台运算而不需要太多交互的任务 Parallel Scavenge收集器提供了两个参数用户精确控制吞吐量,分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数及直接设置吞吐量大小的-XX:GCTimeRatio参数 8.5 Parallel Old收集器 是Parallel Scavenge收集器的老年代版本，用于老年代的垃圾回收，但与Parallel Scavenge不同的是，它使用的是“标记-整理算法”。 适用于注重于吞吐量及CPU资源敏感的场合 8.6 CMS收集器 CMS收集器是一种以获取最短回收停顿时间为目标的收集器 CMS收集器是基于标记-清除算法实现的,他的整个运行过程可以分为: 初始登记 (标记以下GC Roots能直接关联到的对象,这个过程速度很快) 并发标记(进行GCRoots Tracing的过程) 重新标记(修正并发标记期因用户线程继续运作而导致标记产生变动的那一部分对象的标记记录,速度稍慢) 并发清除(清除死亡的对象) 4个步骤;其中,初始标记和重新标记仍然需要Stop The World CMS收集器运行的整个过程中,最耗费时间的是并发标记和并发清除过程, 收集器线程和用户线程是一起工作的,所以总体来说,CMS收集器的内存回收过程是与用户线程一起来并发执行的 开启参数 : -XX:+UseParNewGC , -XX:+UseConcMarkSweepGC 优点: 并发是收集、低停顿 缺点: CMS收集器堆CPU资源非常敏感.虽然在两个阶段并发阶段不会导致用户线程停顿, 但是会因为占用了一部分线程而导致应用程序变慢,总吞吐量下降. CMS,默认启动的回收线程数(CPU数量+3)/4 CMS收集器无法处理浮动垃圾, 可能出现”Conturrent Mode Failure”失败而导致另一次Full FC产生. 由于CMS并发清除阶段用户线程还在运行, 伴随着程序还在产生新的垃圾, 这一部分垃圾出现在标记之后, CMS无法在档次收集中处理掉它们, 只能留到下次再清理, 这一部分垃圾成为浮动垃圾. 也正是由于再垃圾收集阶段用户线程还在运行, 那么也就需要预留有足够的内存空间给用户线程使用, 因此CMS收集器不能像其他收集器那样等待老年代填满之后再进行收集, 需要预留一部分空间给并发收集时用户程序使用, 可以通过-XX:CMSInitiatingOccupancyFraction参数设置老年代内存使用达到多少时启动收集. 由于CMS收集器是一个基于标记-清除算法的收集器, 那么意味着收集结束会产生大量碎片, 有时候往往还有很多内存未使用, 可是没有一块连续的空间来分配一个对象, 导致不得不提前触发一次Full GC. CMS收集器提供了一个-XX: UseCMSCompactAtFullCollection参数(默认是开启的)用户在CMS收集器顶不住要FullGC是开启内存碎片整理(内存碎片整理意味着无法并发执行不得不停顿用户线程). 参数-XX:CMSFullGCsBeforeCompaction来设置执行多少次不压缩的Full GC后,跟着来一次带压缩的(默认值是0,意味着每次进入Full GC时都要进行碎片整理). 8.7 G1收集器 G1收集器的运作大致可分为 初始标记: 需要停顿, 耗时短 并发标记 最终标记: 需要停顿, 可并发执行 筛选标记 G1收集器是当今收集器技术发展的最前沿成果之一 相比其它收集器, 具有如下特点: 并行与并发: G1能够重发利用多CPU、多核环境下的有实,使用多个CPU来缩短Stop -The-World停顿时间 分代收集: 与其他收集器一样,分代概念在G1中依然存在 空间整合: 与CMS的标记-清除算法不同,G1从整体来看是基于标记-整理来实现的收集器,从局部(两个Region之间)上来看是基于复制算法实现的,着两种算法都意味着G1运作期间不会产生内存空间碎片,收集后能够提供整体的可用内存 可预测停顿: G1除了追求低停顿之外,还能简历可预测的停顿时间模型,能让使用者明确指定在一个长度为M毫秒的时间片段内,小号在垃圾收集上的时间不得超过N毫秒 使用G1收集器时,Java堆内的内存布局与其它收集器有很大的却别,它将整个Java堆划分为多个大小相等的独立区域(Region), 虽然还保留着新生代和老年代的概念, 但新生代和老年代不再是物理隔离的了,他们都是一部分Region(不需要连续)的集合. G1收集器之所以能够建立可预测的停顿时间模型,是因为它可以有计划的避免在整个Java堆中进行全区域的垃圾收集. G1跟踪各个Region里面垃圾堆积的价值大小(回收所获得的空间大小以及回收所需要时间的经验值), 在后台维护一个优先列表,每次根据允许的收集时间,优先回收价值最大的Region(这也是Garbage First名称的又来) 开启参数: -XX:+useG1GC 8.8 ZGC收集器 一款由Oracle公司研发的, 以低延迟为首要目标的一款垃圾收集器. 它是基于动态Region内存布局,(暂时)不设年龄分代, 使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记整理算法的收集器. 在JDK11新加入,还在实验阶段, 主要特点是: 回收TB级内存(最大4T),停顿时间不超过10ms 优点: 低停顿,高吞吐量,ZGC收集过程中额外耗费的内存小 缺点: 浮动垃圾 ZGC目前只在Linux/64上可用,如果有足够的需求,将来可能会增加对其他平台的支持 启动参数: -XX:+UnlockExperimentalVMOption, -XX:+Use ZGC,-Xmx10g,-Xlog:gc 8.8.1 ZGC收集器之动态Region 小型Region（Small Region）：容量固定为2MB，用于放置小于256KB的小对象 中型Region（Medium Region）：容量固定为32MB，用于放置大于等于256KB但小于4MB的对象 大型Region（Large Region）：容量不固定，可以动态变化，但必须为2MB的整数倍，用于放置4MB或以上的大对象。每个大型Region中只会存放一个大对象，最小容量可低至4MB，所有大型Region可能小于中型Region 大型Region在ZGC的实现中是不会被重分配的，因为复制一个大对象的代价非常高昂 8.8.2 ZGC收集器之染色指针 HotSpot虚拟机的标记实现方案有如下几种： 把标记直接记录在对象头上（如Serial收集器）； 把标记记录在与对象相互独立的数据结构上（如G1、Shenandoah使用了一种相当于堆内存的1/64大小的，称为BitMap的结构来记录标记信息） 直接把标记信息记在引用对象的指针上（如ZGC） 染色指针是一种直接将少量额外的信息存储在指针上的技术 目前在Linux下64位的操作系统中高18位是不能用来寻址的，但是剩余的46位却可以支持64T的空间，到目前为止我们几乎还用不到这么多内存。于是ZGC将46位中的高4位取出，用来存储4个标志位，剩余的42位可以支持4T的内存 8.8.3 ZGC收集器之三色标记在并发的可达性分析算法中我们使用三色标记（Tri-color Marking）来标记对象是否被收集器访问过 白色：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达 黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接（不经过灰色对象）指向某个白色对象。 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 8.8.4 ZGC收集器之读屏障当对象从堆中加载的时候，就会使用到读屏障（Load Barrier）。这里使用读屏障的主要作用就是检查指针上的三色标记位，根据标记位判断出对象是否被移动过，如果没有可以直接访问，如果移动过就需要进行“自愈”（对象访问会变慢，但也只会有一次变慢），当“自愈”完成后，后续访问就不会变慢 读写屏障可以理解成对象访问的“AOP”操作 8.8.5 ZGC收集器之内存多重映射ZGC使用了内存多重映射（Multi-Mapping）将多个不同的虚拟内存地址映射到同一个物理内存地址上，这是一种多对一映射，意味着ZGC在虚拟内存中看到的地址空间要比实际的堆内存容量来得更大。把染色指针中的标志位看作是地址的分段符，那只要将这些不同的地址段都映射到同一个物理内存空间，经过多重映射转换后，就可以使用染色指针正常进行寻址了. ZGC的多重映射只是它采用染色指针技术的伴生产物 8.8.6 ZGC收集器运作过程并发标记：与G1、Shenandoah一样，并发标记是遍历对象图做可达性分析的阶段，它的初始标记和最终标记也会出现短暂的停顿，整个标记阶段只会更新染色指针中的Marked 0、Marked 1标志位 并发预备重分配：这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集（Relocation Set）。ZGC每次回收都会扫描所有的Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本 并发重分配：重分配是ZGC执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表（Forward Table），记录从旧对象到新对象的转向关系。ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”（Self-Healing）能力 并发重映射（Concurrent Remap）：重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，但是ZGC中对象引用存在“自愈”功能，所以这个重映射操作并不是很迫切。ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里去完成，反正它们都是要遍历所有对象的，这样合并就节省了一次遍历对象图的开销 8.9 Epsilon 收集器Epsilon（A No-Op Garbage Collector）垃圾回收器控制内存分配，但是不执行任何垃圾回收工作。一旦java的堆被耗尽，jvm就直接关闭。设计的目的是提供一个完全消极的GC实现，分配有限的内存分配，最大限度降低消费内存占用量和内存吞吐时的延迟时间。一个好的实现是隔离代码变化，不影响其他GC，最小限度的改变其他的JVM代码 适用场景: Performance testing,什么都不执行的GC非常适合用于差异性分析 在测试java代码时，确定分配内存的阈值有助于设置内存压力常量值。这时no-op就很有用，它可以简单地接受一个分配的内存分配上限，当内存超限时就失败。例如：测试需要分配小于1G的内存，就使用-Xmx1g参数来配置no-op GC，然后当内存耗尽的时候就直接crash 相关启动参数 UnlockExperimentalVMOptions：解锁隐藏的虚拟机参数 -XX:+UnlockExperimentalVMOptions, -XX:+UseEpsilonGC, -Xms100m, -Xmx100m 8.10 Shenandoah 收集器一款只有OpenJDK才会包含的收集器，最开始由RedHat公司独立发展后来贡献给了OpenJDK Shenandoah与G1类似，也是使用基于Region的堆内存布局，同样有着用于存放大对象的Humongous Region，默认的回收策略也同样是优先处理回收价值最大的Region 但是管理堆内存方面，与G1至少有三个明显的不同之处： Shenandoah 支持并发的整理算法;G1支持并行整理算法。 Shenandoah（目前）是默认不使用分代收集的；G1 有专门的新生代Region或者老年代Region的存在; Shenandoah摒弃了在G1中耗费大量内存和计算资源去维护的记忆集，改用名为连接矩阵（Connection Matrix）的全局数据结构来记录跨Region的引用关系，降低了处理跨代指针时的记忆集维护消耗，也降低了伪共享问题的发生概率 优点：延迟低 缺点：高运行负担使得吞吐量下降；使用大量的读写屏障，尤其是读屏障，增大了系统的性能开销； 开启参数: -XX:+UnlockExperimentalVMOptions, -XX:+UseShenandoahGC 8.10.1 Shenandoah 收集器之连接矩阵 连接矩阵可以简单理解为一张二维表格，如果Region N有对象指向RegionM，就在表格的N行M列中打上一个标记，如右图所示，如果Region 5中的对象Baz引用了Region 3的Foo，Foo又引用了Region 1的Bar，那连接矩阵中的5行3列、3行1列就应该被打上标记。在回收时通过这张表格就可以得出哪些Region之间产生了跨代引用 8.10.2 Shenandoah 收集器之转发指针 转发指针（Forwarding Pointer，也常被称为Indirection Pointer）来实现对象移动与用户程序并发的一种解决方案 Brooks提出的新方案不需要用到内存保护陷阱，而是在原有对象布局结构的最前面统一增加一个新的引用字段，在正常不处于并发移动的情况下，该引用指向对象自己。从结构上来看，Brooks提出的转发指针与某些早期Java虚拟机使用过的句柄定位，有一些相似之处，两者都是一种间接性的对象访问方式，差别是句柄通常会统一存储在专门的句柄池中，而转发指针是分散存放在每一个对象头前面 8.10.3 Shenandoah 收集器之读写屏障 Brooks形式的转发指针在设计上决定了它是必然会出现多线程竞争问题的，如果收集器线程与用户线程发生的只是并发读取，那无论读到旧对象还是新对象上的字段，返回的结果都应该是一样的，这个场景还可以有一些“偷懒”的处理余地；但如果发生的是并发写入，就一定必须保证写操作只能发生在新复制的对象上，而不是写入旧对象的内存中 解决方案: Shenandoah不得不同时设置读、写屏障去拦截 9. 如何评估一款GC的性能 吞吐量: 程序运行时间(程序运行时间 + 内存回收的时间) 垃圾收集开销: 吞吐量的补救,垃圾收集器所占时间与总时间的比例 暂停时间: 执行垃圾收集,程序的工作线程被暂停的时间 收集频率: 相对于应用程序的执行,收集操作发生的频率 堆空间: Java堆区所栈的内存大小 快速: 一个对象从诞生到被回收所经历的时间 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/tags/JVM/"}],"author":"fyang"},{"title":"Redis常见的性能问题","slug":"Redis常见性能问题","date":"2020-06-09T00:38:57.562Z","updated":"2020-06-18T08:18:32.971Z","comments":true,"path":"undefined/776d.html","link":"","permalink":"http://fyvan.github.io/undefined/776d.html","excerpt":"","text":"Redis 常见的性能问题都有哪些？如何解决？ Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://fyvan.github.io/tags/redis/"}],"author":"fyang"},{"title":"Zookeeper安装与单机集群","slug":"Zookeeper-install-2020-6-6","date":"2020-06-06T11:38:55.668Z","updated":"2020-06-18T08:14:08.565Z","comments":true,"path":"undefined/e6b7.html","link":"","permalink":"http://fyvan.github.io/undefined/e6b7.html","excerpt":"","text":"1 Zookeeper介绍ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 ZooKeeper包含一个简单的原语集,提供Java和C的接口。 ZooKeeper代码版本中，提供了分布式独享锁、选举、队列的接口，代码在zookeeper-3.4.3\\src\\recipes。其中分布锁和队列有Java和C两个版本，选举只有Java版本。 总结:Zookeeper负责服务的协调调度.当客户端发起请求时,返回正确的服务器地址. 2 Zookeeper下载网址: http://zookeeper.apache.org/releases.html;下载路径,点击download. 下载Zookeeper地址. http://mirrors.hust.edu.cn/apache/zookeeper/ 3 Zookeeper安装3.1 安装jdkZooKeeper是用Java编写的，运行在baiJava环境上，du因此，在部署zk的机器上zhi需要安装Java运行环境。dao为了正常运行zk，我们需要JRE1.6或者以上的版本。 将JDK1.8文件上传到Linux操作系统中/src/usr/local/java/文件下. 解压文件 # 解压上传的压缩包xxx.tar.gz tar -xvf jdk-8u51-linux-x64.tar.gz # 重命名 mv jdk.1.8.0_51 jdk.1.8 配置环境变量/etc/profile vim /etc/profile # 添加如下内容 export JAVA_HOME=/usr/local/src/jdk1.8 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib 检查安装是否成功 # 添加完环境变量后,执行下面命令使之生效 source /etc/profile # 查看JDK版本信息 java -version 3.2 安装Zookeeper 上传下载好的安装包到服务器 解压文件 # 解压上传的压缩包xxx.tar.gz tar -xvf apache-zookeeper-3.6.0-bin.tar.gz # 重命名 mv apache-zookeeper-3.6.0-bin zookeeper-3.6.0 修改配置文件 在zookeeper-3.6.0目录下面新建2个文件夹data和log mkdir data log 进入conf目录中修改配置文件zoo_sample.cfg # 复制配置文件并修改名称 cp zoo_sample.cfg zoo.cfg ​ 修改该下面图片中红框中的内容 启动Zookeeper 进入bin目录下, 执行下面命令进行测试 sh zkServer.sh start 或者 ./zkServer.sh start sh zkServer.sh stop sh zkServer.sh status 4. Zookeeper单机集群安装4.1 准备安装文件夹在zookeeper根目录中创建新的集群目录zkCluster. mkdir zkClusters 在集群目录zkCluster中创建节点目录zk1,zk2,zk3,并在每个目录里创建data/log文件夹 mkdir {zk1,zk2,zk3}/{data,log} 4.2 添加myid文件分别在zk1/zk2/zk3中的data文件夹中创建新的文件myid.其中的内容依次为1/2/3,与zk节点号对应. echo \"1\">/usr/local/src/zookeeper-3.6.0/zkClusters/zk1/data/myid echo \"2\">/usr/local/src/zookeeper-3.6.0/zkClusters/zk2/data/myid echo \"3\">/usr/local/src/zookeeper-3.6.0/zkClusters/zk3/data/myid 4.3 编辑配置文件将zoo_sample.cfg 复制为zoo1.cfg之后修改配置文件. dataDir=/usr/local/src/zookeeper-3.6.0/zkClusters/zk1/data dataLogDir=/usr/local/src/zookeeper-3.6.0/zkClusters/zk1/log # the port at which the clients will connect clientPort=2181 server.1=192.168.126.129:2887:3887 server.2=192.168.126.129:2888:3888 server.3=192.168.126.129:2889:3889 配置完成后将zoo1.cfg复制为zoo2.cfg和zoo3.cfg.修改与之对应的节点目录和端口号. 修改zoo2.cgf 修改zoo3.cgf 4.4 集群测试 启动集群 sh zkServer.sh start zoo1.cfg sh zkServer.sh start zoo2.cfg sh zkServer.sh start zoo3.cfg 启动后集群状态 sh zkServer.sh status zoo1.cfg sh zkServer.sh status zoo2.cfg sh zkServer.sh status zoo3.cfg document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"software","slug":"software","permalink":"http://fyvan.github.io/categories/software/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://fyvan.github.io/tags/Zookeeper/"}],"author":"fyang"},{"title":"IDEA使用","slug":"Tool-IDEA","date":"2020-06-03T02:43:43.803Z","updated":"2020-06-24T02:46:52.656Z","comments":true,"path":"undefined/91c5.html","link":"","permalink":"http://fyvan.github.io/undefined/91c5.html","excerpt":"","text":"IDEA开发使用异常处理1. springboot项目访问项目主页出现404 IDEA设置: 添加工作目录 2. 配置zuul启动报错 SpringBoot版本问题, 之前SpringBoot版本为2.1.0,SpringCloud为Finchley.SR1 降低SpringBoot版本为2.0.4后成功解决. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"software","slug":"software","permalink":"http://fyvan.github.io/categories/software/"}],"tags":[{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"http://fyvan.github.io/tags/IntelliJ-IDEA/"}],"author":"fyang"},{"title":"synchronized原理分析","slug":"Java-synchronized","date":"2020-06-01T11:30:33.608Z","updated":"2020-06-18T08:17:10.495Z","comments":true,"path":"undefined/7ebc.html","link":"","permalink":"http://fyvan.github.io/undefined/7ebc.html","excerpt":"","text":"1. 概念synchronized 是 Java 中的关键字，是利用锁的机制来实现同步的。 锁机制有如下两种特性： 互斥性：即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程中的协调机制，这样在同一时间只有一个线程对需同步的代码块(复合操作)进行访问。互斥性我们也往往称为操作的原子性。 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值），否则另一个线程可能是在本地缓存的某个副本上继续操作从而引起不一致。 2. 对象锁和类锁2.1 对象锁在 Java 中，每个对象都会有一个 monitor 对象，这个对象其实就是 Java 对象的锁，通常会被称为“内置锁”或“对象锁”。类的对象可以有多个，所以每个对象有其独立的对象锁，互不干扰。 2.2 类锁在 Java 中，针对每个类也有一个锁，可以称为“类锁”，类锁实际上是通过对象锁实现的，即类的 Class 对象锁。每个类只有一个 Class 对象，所以每个类只有一个类锁。 3. synchronized的三种应用方式3.1 同步普通方法锁的是当前对象, 进入同步代码块前要获得当前实例的锁 public class AccountingSync implements Runnable{ //共享资源(临界资源) static int i=0; /** * synchronized 修饰实例方法 */ public synchronized void increase(){ i++; } @Override public void run() { for(int j=0;j&lt;1000000;j++){ increase(); } } public static void main(String[] args) throws InterruptedException { AccountingSync instance=new AccountingSync(); Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); //join含义:当前线程A等待thread线程终止之后才能从thread.join()返回 t1.join(); t2.join(); System.out.println(i); } /** * 输出结果: * 2000000 */ } 上述代码中，我们开启两个线程操作同一个共享资源即变量i，由于i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全。此时我们应该注意到synchronized修饰的是实例方法increase，在这样的情况下，当前线程的锁便是实例对象instance，注意Java中的线程同步锁可以是任意对象。 3.2 同步静态方法锁的是当前 Class 对象, 进入同步代码前要获得当前类对象的锁. 由于静态成员不专属于任何一个实例对象，是类成员，因此通过class对象锁可以控制静态 成员的并发操作。 需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁，但我们应该意识到这种情况下可能会发现线程安全问题(操作了共享静态变量i)。 看如下代码 public class AccountingSyncClass implements Runnable{ static int i=0; /** * 作用于静态方法,锁是当前class对象,也就是 * AccountingSyncClass类对应的class对象 */ public static synchronized void increase(){ i++; } /** * 非静态,访问时锁不一样不会发生互斥 */ public synchronized void increase4Obj(){ i++; } @Override public void run() { for(int j=0;j&lt;1000000;j++){ increase(); } } public static void main(String[] args) throws InterruptedException { //new新实例 Thread t1=new Thread(new AccountingSyncClass()); //new新实例 Thread t2=new Thread(new AccountingSyncClass()); //启动线程 t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); } } 3.3 同步代码块指定加锁对象, 锁的是 ( ) 中的对象, 进入同步代码库前要获得给定对象的锁 在某些情况下，我们编写的方法体可能比较大，同时存在一些比较耗时的操作，而需要同步的代码又只有一小部分，如果直接对整个方法进行同步操作，可能会得不偿失，此时我们可以使用同步代码块的方式对需要同步的代码进行包裹，这样就无需对整个方法进行同步操作了，同步代码块的使用示例如下： public class AccountingSync implements Runnable{ static AccountingSync instance=new AccountingSync(); static int i=0; @Override public void run() { //省略其他耗时操作.... //使用同步代码块对变量i进行同步操作,锁对象为instance synchronized(instance){ for(int j=0;j&lt;1000000;j++){ i++; } } } public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); } } 从代码看出，将synchronized作用于一个给定的实例对象instance，即当前实例对象就是锁对象，每次当线程进入synchronized包裹的代码块时就会要求当前线程持有instance实例对象锁，如果当前有其他线程正持有该对象锁，那么新到的线程就必须等待，这样也就保证了每次只有一个线程执行i++;操作。当然除了instance作为对象外，我们还可以使用this对象(代表当前实例)或者当前类的class对象作为锁，如下代码： //this,当前实例对象锁 synchronized(this){ for(int j=0;j&lt;1000000;j++){ i++; } } //class对象锁 synchronized(AccountingSync.class){ for(int j=0;j&lt;1000000;j++){ i++; } } 4. synchronized底层语义原理4.1 JVM层级-synchronized底层语义原理（Hotspot）理解Java对象头与Monitor 在JVM中，对象(new Object())在内存中的布局分为四块区域：对象头、实例数据和对齐填充。如下： mark word和 class pointer表示Java头对象 实例变量: 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。 填充数据: 由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。 而对于顶部，则是Java头对象，它实现synchronized的锁对象的基础. 一般而言，synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class pointer组成，其结构说明如下表： 虚拟机位数 头对象结构 说明 32/64bit Mark Word 存储对象的hashCode、锁信息或分代年龄或GC标志等信息 32/64bit Class pointer 类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例 其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等以下是32位JVM的Mark Word默认存储结构由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，如32位JVM下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构： 其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） ObjectMonitor() { _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示 由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因,有了上述知识基础后，下面我们将进一步分析synchronized在字节码层面的具体语义实现。 4.2 字节码层级-synchronized代码块底层原理JVM 是通过进入、退出对象监视器( Monitor )来实现对方法、同步块的同步的。 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 现在我们重新定义一个synchronized修饰的同步代码块，在代码块中操作共享变量i，如下 public class SyncCodeBlock { public int i; public void syncTask(){ //同步代码库 synchronized (this){ i++; } } } 编译上述代码并使用javap反编译后得到字节码如下(这里我们省略一部分没有必要的信息)： MD5 checksum c80bc322c87b312de760942820b4fed5 Compiled from \"SyncCodeBlock.java\" public class com.zejian.concurrencys.SyncCodeBlock minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: //........省略常量池中数据 //构造函数 public com.zejian.concurrencys.SyncCodeBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init>\":()V 4: return LineNumberTable: line 7: 0 //===========主要看看syncTask方法实现================ public void syncTask(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //注意此处，进入同步方法 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit //注意此处，退出同步方法 16: goto 24 19: astore_2 20: aload_1 21: monitorexit //注意此处，退出同步方法 22: aload_2 23: athrow 24: return Exception table: //省略其他字节码....... } SourceFile: \"SyncCodeBlock.java\" 我们主要关注字节码中的如下代码 3: monitorenter //进入同步方法 //..........省略其他 15: monitorexit //退出同步方法 16: goto 24 //省略其他....... 21: monitorexit //退出同步方法 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令. 其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置. 当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。 如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。 倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。 值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。 为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。 从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 4.3 字节码层级-synchronized方法底层原理方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。 JVM可以从方法常量池中的方法表结构(method_info Structure) 中的ACC_SYNCHRONIZED访问标志区分一个方法是否同步方法。 当方法调用时，调用指令将会 检查方法的ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。 在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。 下面我们看看字节码层面如何实现： public class SyncMethod { public int i; public synchronized void syncTask(){ i++; } } 使用javap反编译后的字节码如下： Last modified 2017-6-2; size 308 bytes MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94 Compiled from \"SyncMethod.java\" public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10 } SourceFile: \"SyncMethod.java\" 从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是``ACC_SYNCHRONIZED`标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 这便是synchronized锁在同步代码块和同步方法上实现的基本原理。 5. Java虚拟机对synchronized的优化在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。 5.1 偏向锁偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。 偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。 但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 5.2 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。 轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 5.3 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。 这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 5.4 锁消除消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。 5.5 锁升级过程 new → 偏向锁 → 轻量级锁 （无锁, 自旋锁，自适应自旋）→ 重量级锁 synchronized优化的过程和markword息息相关 用markword中最低的三位代表锁状态 其中1位是偏向锁位 两位是普通锁位用markword中最低的三位代表锁状态 其中1位是偏向锁位 两位是普通锁位 Object o = new Object()锁 = 0 01 无锁态注意：如果偏向锁打开，默认是匿名偏向状态 o.hashCode()001 + hashcode 00000001 10101101 00110100 00110110 01011001 00000000 00000000 00000000 little endian big endian 00000000 00000000 00000000 01011001 00110110 00110100 10101101 00000000 默认synchronized(o)00 -&gt; 轻量级锁默认情况 偏向锁有个时延，默认是4秒why? 因为JVM虚拟机自己有一些默认启动的线程，里面有好多sync代码，这些sync代码启动时就知道肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作，效率较低。 -XX:BiasedLockingStartupDelay=0 如果设定上述参数new Object () - &gt; 101 偏向锁 -&gt;线程ID为0 -&gt; Anonymous BiasedLock打开偏向锁，new出来的对象，默认就是一个可偏向匿名对象101 如果有线程上锁上偏向锁，指的就是，把markword的线程ID改为自己线程ID的过程偏向锁不可重偏向 批量偏向 批量撤销 如果有线程竞争撤销偏向锁，升级轻量级锁线程在自己的线程栈生成LockRecord ，用CAS操作将markword设置为指向自己这个线程的LR的指针，设置成功者得到锁 如果竞争加剧竞争加剧：有线程超过10次自旋， -XX:PreBlockSpin， 或者自旋线程数超过CPU核数的一半， 1.6之后，加入自适应自旋 Adapative Self Spinning ， JVM自己控制升级重量级锁：-&gt; 向操作系统申请资源，linux mutex , CPU从3级-0级系统调用，线程挂起，进入等待队列，等待操作系统的调度，然后再映射回用户空间 偏向锁默认是打开的，但是有一个时延，如果要观察到偏向锁，应该设定参数 为什么有自旋锁还需要重量级锁？ 自旋锁什么时候升级为重量级锁？ 自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗 重量级锁有等待队列，所有拿不到锁的进入等待队列，不需要消耗CPU资源 偏向锁是否一定比自旋锁效率高？ 不一定，在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用自旋锁 JVM启动过程，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开 6 关于synchronized 可能需要了解的关键点6.1 synchronized的可重入性从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。如下： public class AccountingSync implements Runnable{ static AccountingSync instance=new AccountingSync(); static int i=0; static int j=0; @Override public void run() { for(int j=0;j&lt;1000000;j++){ //this,当前实例对象锁 synchronized(this){ i++; increase();//synchronized的可重入性 } } } public synchronized void increase(){ j++; } public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); } } 正如代码所演示的，在获取当前实例对象锁后进入synchronized代码块执行同步代码，并在代码块中调用了当前实例对象的另外一个synchronized方法，再次请求当前实例锁时，将被允许，进而执行方法体代码，这就是重入锁最直接的体现，需要特别注意另外一种情况，当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法。注意由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。 6.2 线程中断与synchronized6.2.1线程中断正如中断二字所表达的意义，在线程运行(run方法)中间打断它，在Java中，提供了以下3个有关线程中断的方法 //中断线程（实例方法） public void Thread.interrupt(); //判断线程是否被中断（实例方法） public boolean Thread.isInterrupted(); //判断是否被中断并清除当前中断状态（静态方法） public static boolean Thread.interrupted(); 当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态)，如下代码将演示该过程： public class InterruputSleepThread3 { public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread() { @Override public void run() { //while在try中，通过异常中断就可以退出run循环 try { while (true) { //当前线程处于阻塞状态，异常必须捕捉处理，无法往外抛出 TimeUnit.SECONDS.sleep(2); } } catch (InterruptedException e) { System.out.println(\"Interruted When Sleep\"); boolean interrupt = this.isInterrupted(); //中断状态被复位 System.out.println(\"interrupt:\"+interrupt); } } }; t1.start(); TimeUnit.SECONDS.sleep(2); //中断处于阻塞状态的线程 t1.interrupt(); /** * 输出结果: Interruted When Sleep interrupt:false */ } } 如上述代码所示，我们创建一个线程，并在线程中调用了sleep方法从而使用线程进入阻塞状态，启动线程后，调用线程实例对象的interrupt方法中断阻塞异常，并抛出InterruptedException异常，此时中断状态也将被复位。这里有些人可能会诧异，为什么不用Thread.sleep(2000);而是用TimeUnit.SECONDS.sleep(2);其实原因很简单，前者使用时并没有明确的单位说明，而后者非常明确表达秒的单位，事实上后者的内部实现最终还是调用了Thread.sleep(2000);，但为了编写的代码语义更清晰，建议使用TimeUnit.SECONDS.sleep(2);的方式，注意TimeUnit是个枚举类型。ok~，除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的，如下代码，将无法中断非阻塞状态下的线程： public class InterruputThread { public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(){ @Override public void run(){ while(true){ System.out.println(\"未被中断\"); } } }; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果(无限执行): 未被中断 未被中断 未被中断 ...... */ } } 虽然我们调用了interrupt方法，但线程t1并未被中断，因为处于非阻塞状态的线程需要我们手动进行中断检测并结束程序，改进后代码如下： public class InterruputThread { public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(){ @Override public void run(){ while(true){ //判断当前线程是否被中断 if (this.isInterrupted()){ System.out.println(\"线程中断\"); break; } } System.out.println(\"已跳出循环,线程中断!\"); } }; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果: 线程中断 已跳出循环,线程中断! */ } } 是的，我们在代码中使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用interrupt()并不会导致中断状态重置。综合所述，可以简单总结一下中断两种情况，一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写： public void run(){ try { //判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位 while (!Thread.interrupted()) { TimeUnit.SECONDS.sleep(2); } } catch (InterruptedException e) { } }6.2.2 中断与synchronized事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。演示代码如下 /** * Created by zejian on 2017/6/2. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */ public class SynchronizedBlocked implements Runnable{ public synchronized void f() { System.out.println(\"Trying to call f()\"); while(true) // Never releases lock Thread.yield(); } /** * 在构造器中创建新线程并启动获取对象锁 */ public SynchronizedBlocked() { //该线程已持有当前实例锁 new Thread() { public void run() { f(); // Lock acquired by this thread } }.start(); } public void run() { //中断判断 while (true) { if (Thread.interrupted()) { System.out.println(\"中断线程!!\"); break; } else { f(); } } } public static void main(String[] args) throws InterruptedException { SynchronizedBlocked sync = new SynchronizedBlocked(); Thread t = new Thread(sync); //启动后调用f()方法,无法获取当前实例锁处于等待状态 t.start(); TimeUnit.SECONDS.sleep(1); //中断线程,无法生效 t.interrupt(); } } 我们在SynchronizedBlocked构造函数中创建一个新线程并启动获取调用f()获取到当前实例锁，由于SynchronizedBlocked自身也是线程，启动后在其run方法中也调用了f()，但由于对象锁被其他线程占用，导致t线程只能等到锁，此时我们调用了t.interrupt();但并不能中断线程。 6.3 等待唤醒机制与synchronized所谓等待唤醒机制本篇主要指的是notify/notifyAll和wait方法，在使用这3个方法时，必须处于synchronized代码块或者synchronized方法中，否则就会抛出IllegalMonitorStateException异常，这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。 synchronized (obj) { obj.wait(); obj.notify(); obj.notifyAll(); } 需要特别理解的一点是，与sleep方法不同的是wait方法调用完成后，线程将被暂停，但wait方法将会释放当前持有的监视器锁(monitor)，直到有线程调用notify/notifyAll方法后方能继续执行，而sleep方法只让线程休眠并不释放锁。同时notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。 原文链接：https://blog.csdn.net/javazejian/article/details/72828483 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"多线程","slug":"多线程","permalink":"http://fyvan.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"synchronized","slug":"synchronized","permalink":"http://fyvan.github.io/tags/synchronized/"}],"author":"fyang"},{"title":"ObjectMapper工具API","slug":"API-ObjectMapper","date":"2020-05-29T09:01:04.028Z","updated":"2020-06-24T03:55:50.774Z","comments":true,"path":"undefined/fcf2.html","link":"","permalink":"http://fyvan.github.io/undefined/fcf2.html","excerpt":"","text":"在了解ObjectMapper之前,我们先要了解下什么是JSON. JSON(JavaScript Object Notation) 是一种轻量级的基于文本的数据交换格式。它采用完全独立于语言的文本格式，易于读写同时也易于机器解析和生成(网络传输速率)，因此使JSON成为理想的数据交换语言。 Java中的三种JSON库：Jackson、Gson、Fastjson. 其中Jackson旧称为：Java(或JVM平台)\\的标准JSON库，或者是Java的*最佳JSON解析器*，或者简称为“Java的JSON”. Jackson是一个简单的、功能强大的、基于Java的应用库。它可以很方便完成Java对象和json对象(xml文档or其它格式）进行互转。Jackson社区相对比较活跃，更新速度也比较快。Jackson库有如下几大特性： 高性能且稳定：低内存占用，对大/小JSON串，大/小对象的解析表现均很优秀 流行度高：是很多流行框架的默认选择 容易使用：提供高层次的API，极大简化了日常使用案例 无需自己手动创建映射：内置了绝大部分序列化时和Java类型的映射关系 干净的JSON：创建的JSON具有干净、紧凑、体积小等特点 无三方依赖：仅依赖于JDK Spring生态加持：jackson是Spring家族的默认JSON/XML解析器 1. ObjectMapper工具API介绍ObjectMapper是Jackson三大核心模块(core module)中的数据绑定模块(com.fasterxml.jackson.databind)包下的程序, 可以从 String，File，InputStream，URL，自定义的 Java 类中读取 JSON，ObjectMapper 中的重载方法 readValue() 实现了这些功能。 2.ObjectMapper入门 POJO与JSON之间的互相转化 POJO类代码如下: @EqualsAndHashCode(callSuper = true) @Data @Accessors(chain = true) @NoArgsConstructor @AllArgsConstructor @TableName(\"tb_item_desc\") public class ItemDesc extends BasePojo{ @TableId //只设定主键,不能自增 private Long itemId; private String itemDesc; } 这里用private修饰属性, 使用lombok提供getters/setters. 互相转化具体实现如下: @Test public void test01() throws JsonProcessingException { //提供一个测试对象 ItemDesc itemDesc = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); //使用databind，我们需要一个最基础的对象com.fasterxml.jackson.databind.ObjectMapper ObjectMapper objectMapper = new ObjectMapper(); //1.对象转化为JSON String json = objectMapper.writeValueAsString(itemDesc); System.out.println(json); //测试结果: //{\"created\":1590854279701,\"updated\":1590854279701,\"itemId\":100,\"itemDesc\":\"测试数据\"} //2.JSON转化为对象 ItemDesc itemDesc2 = objectMapper.readValue(json,ItemDesc.class); System.out.println(itemDesc2.toString()+ \":\" + itemDesc2.getCreated()); //测试结果: //ItemDesc(itemId=100, itemDesc=测试数据):Sat May 30 23:57:59 CST 2020 } list集合转化 @Test public void test02() throws JsonProcessingException { //提供测试数据 ItemDesc itemDesc = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); ItemDesc itemDesc2 = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); //提供集合 List&lt;ItemDesc> list = new ArrayList&lt;>(); list.add(itemDesc); list.add(itemDesc2); //1.list转化为JSON String json = OBJECTMAPPER.writeValueAsString(list); System.out.println(json); //测试结果 //[{\"created\":1590854579886,\"updated\":1590854579886,\"itemId\":100,\"itemDesc\":\"测试数据\"},{\"created\":1590854579886,\"updated\":1590854579886,\"itemId\":101,\"itemDesc\":\"测试数据2\"}] //2.json转化为list List&lt;ItemDesc> list2 = OBJECTMAPPER.readValue(json,list.getClass()); System.out.println(list2); //测试结果 //[{created=1590854579886, updated=1590854579886, itemId=100, itemDesc=测试数据}, {created=1590854579886, updated=1590854579886, itemId=101, itemDesc=测试数据2}] 3. JSON转化的原理/** * 原理说明: * 1.对象转化JSON时,其实调用的是对象身上的getXXXX()方法. * 获取所有的getLyj()方法-----之后去掉get-----首字母小写---lyj属性. * json串中的key就是该属性.value就是属性的值. lyj:\"xxxxx\" * * 2.JSON转化为对象原理说明 * 1).定义转化对象的类型(ItemDesc.class) * 2).利用反射机制实例化对象 class.forName(class) 现在的属性都为null * 3).将json串解析 * object key:value * array value1,value2 * 4).根据json串中的属性的itemId,之后调用对象的(set+首字母大写)setItemId方法实现赋值 */ @Test public void test03() throws JsonProcessingException { ItemDesc itemDesc = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); //思考:对象转化为JSON时,底层实现如何. String json = OBJECTMAPPER.writeValueAsString(itemDesc); System.out.println(json); //{id:1,name:\"xxxx\"} OBJECTMAPPER.readValue(json,ItemDesc.class); } 4. 封装ObjectMapperUtil:该方法的主要的作用 就是将对象与json实现灵活的转化,并且内部优化了异常. 为了通用,将ObjectMapperUtil写入common中. public class JsonUtils { public static final ObjectMapper mapper = new ObjectMapper(); private static final Logger logger = LoggerFactory.getLogger(JsonUtils.class); //序列化 obj-to-json public static String serialize(Object obj) { if (obj == null) { return null; } if (obj.getClass() == String.class) { return (String) obj; } try { return mapper.writeValueAsString(obj); } catch (JsonProcessingException e) { logger.error(\"json序列化出错：\" + obj, e); return null; } } //反序列化 json-to-obj public static &lt;T> T parse(String json, Class&lt;T> tClass) { try { return mapper.readValue(json, tClass); } catch (IOException e) { logger.error(\"json解析出错：\" + json, e); return null; } } //json-to-list public static &lt;E> List&lt;E> parseList(String json, Class&lt;E> eClass) { try { return mapper.readValue(json, mapper.getTypeFactory().constructCollectionType(List.class, eClass)); } catch (IOException e) { logger.error(\"json解析出错：\" + json, e); return null; } } //json-to-map public static &lt;K, V> Map&lt;K, V> parseMap(String json, Class&lt;K> kClass, Class&lt;V> vClass) { try { return mapper.readValue(json, mapper.getTypeFactory().constructMapType(Map.class, kClass, vClass)); } catch (IOException e) { logger.error(\"json解析出错：\" + json, e); return null; } } //复杂对象转换 public static &lt;T> T nativeRead(String json, TypeReference&lt;T> type) { try { return mapper.readValue(json, type); } catch (IOException e) { logger.error(\"json解析出错：\" + json, e); return null; } } //测试 @Data @AllArgsConstructor @NoArgsConstructor static class User{ String name; Integer age; } public static void main(String[] args) { User user = new User(\"Jack\",21); //serialize 序列化obj-to-json // String json = serialize(user); // System.out.println(\"json = \" + json); //反序列化 json-to-obj // User user1 = parse(json,User.class); // System.out.println(\"user1 = \" + user1); //parseList // String json = \"[20, -10, 5, 15]\"; // List&lt;Integer> list = parseList(json,Integer.class); // System.out.println(\"list = \" + list); //parseMap // String json = \"{\\\"name\\\":\\\"jack\\\", \\\"age\\\":\\\"21\\\"}\"; // Map&lt;String,String> map = parseMap(json, String.class, String.class); // System.out.println(\"map = \" + map); //list里面装的map String json = \"[{\\\"name\\\":\\\"jack\\\", \\\"age\\\":\\\"21\\\"}, {\\\"name\\\":\\\"rose\\\", \\\"age\\\":\\\"18\\\"}]\"; //类型引用, 匿名内部类 List&lt;Map&lt;String, String>> maps = nativeRead(json, new TypeReference&lt;List&lt;Map&lt;String, String>>>() {}); for (Map&lt;String, String> map : maps){ System.out.println(\"map = \" + map); } } } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"API","slug":"API","permalink":"http://fyvan.github.io/categories/API/"}],"tags":[{"name":"ObjectMapper","slug":"ObjectMapper","permalink":"http://fyvan.github.io/tags/ObjectMapper/"}],"author":"fyang"},{"title":"CentOS 7安装Docker","slug":"SoftwareInstall-2020-05-28-CentOS-Docker","date":"2020-05-28T13:13:32.898Z","updated":"2020-06-18T08:20:00.343Z","comments":true,"path":"undefined/674f.html","link":"","permalink":"http://fyvan.github.io/undefined/674f.html","excerpt":"","text":"1. 前言Docker 使用越来越多，安装也很简单，本次记录一下基本的步骤。 Docker 目前支持 CentOS 7 及以后的版本，内核要求至少为 3.10。 Docker 官网有安装步骤，本文只是记录一下，您也可以参考 Get Docker CE for CentOS 2. 环境说明RedHat 7.6 (Minimal Install) [root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 3. 准备工作 操作系统要求 CentOS 7 以后都可以安装 Docker 了，也可以确认一下。 [root@localhost ~]# uname -a Linux localhost.localdomain 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux Docker 需要用到 centos-extra 这个源，如果关闭了，需要重启启用，可以参考 Available Repositories for CentOS。 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。 vim /etc/yum.repos.d/docker-ce.repo 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1 卸载旧版本的Docker 旧版本的 Docker 被叫做 docker 或 docker-engine，如果安装了旧版本的 Docker ，您需要卸载掉它。 我的系统上没有安装,所以结果下 [root@localhost ~]# yum remove docker \\ > docker-client \\ > docker-client-latest \\ > docker-common \\ > docker-latest \\ > docker-latest-logrotate \\ > docker-logrotate \\ > docker-engine 已加载插件：fastestmirror 参数 docker 没有匹配 参数 docker-client 没有匹配 参数 docker-client-latest 没有匹配 参数 docker-common 没有匹配 参数 docker-latest 没有匹配 参数 docker-latest-logrotate 没有匹配 参数 docker-logrotate 没有匹配 参数 docker-engine 没有匹配 不删除任何软件包 旧版本的内容在 /var/lib/docker 下，目录中的镜像(images), 容器(containers), 存储卷(volumes), 和 网络配置（networks）都可以保留。 Docker CE 包，目前的包名为 docker-ce。 4. 安装Docker-CE: 安装准备 为了方便添加软件源，支持 device-mapper 存储类型，安装如下软件包 [root@localhost ~]# sudo yum update [root@localhost ~]# sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加 yum 软件源 添加 Docker 稳定版本的 yum 软件源 # 官方源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 阿里云源 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装 更新一下 yum 软件源的缓存，并安装 Docker,下载慢的话可以尝试使用下面阿里云Docker CE 镜像源站安装 [root@localhost ~]# sudo yum update [root@localhost ~]# sudo yum -y install docker-ce 如果弹出 GPG key 的接收提示，请确认是否为 060a 61c5 1b55 8a7f 742b 77aa c52f eb6b 621e 9f35，如果是，可以接受并继续安装。 至此，Docker 已经安装完成了，Docker 服务是没有启动的，操作系统里的 docker 组被创建，但是没有用户在这个组里。 注意 默认的 docker 组是没有用户的（也就是说需要使用 sudo 才能使用 docker 命令）。您可以将用户添加到 docker 组中（此用户就可以直接使用 docker 命令了）。 加入 docker 用户组命令 sudo usermod -aG docker USER_NAME 用户更新组信息后，重新登录系统即可生效。 5. 安装指定版本Docker-CE: 查找Docker-CE的版本: yum list docker-ce.x86_64 --showduplicates | sort -r Loading mirror speeds from cached hostfile Loaded plugins: branch, fastestmirror, langpacks docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable Available Packages 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) sudo yum -y install docker-ce-[VERSION] 注意：在某些版本之后，docker-ce安装出现了其他依赖包，如果安装失败的话请关注错误信息。例如 docker-ce 17.03 之后，需要先安装 docker-ce-selinux。 yum list docker-ce-selinux- --showduplicates | sort -r sudo yum -y install docker-ce-selinux-[VERSION] 通过经典网络、VPC网络内网安装时，用以下命令替换Step 2中的命令 经典网络：sudo yum-config-manager –add-repo http://mirrors.aliyuncs.com/doer-ce/linux/centos/docker-ce.repo VPC网络：sudo yum-config-manager –add-repo http://mirrors.could.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo 6. 启动Docker启动 docker 服务 sudo systemctl start docker 添加到开机启动 sudo systemctl enable docker 7. 安装校验[root@localhost ~]# docker version Client: Version: 17.03.0-ce API version: 1.26 Go version: go1.7.5 Git commit: 3a232c8 Built: Tue Feb 28 07:52:04 2017 OS/Arch: linux/amd64 Server: Version: 17.03.0-ce API version: 1.26 (minimum version 1.12) Go version: go1.7.5 Git commit: 3a232c8 Built: Tue Feb 28 07:52:04 2017 OS/Arch: linux/amd64 Experimental: false 运行 hello-world 镜像 sudo docker run hello-world 8. 更新和卸载使用 yum 管理，更新和卸载都很方便。 更新Docker CE sudo yum update docker-ce 卸载Docker CE sudo yum remove docker-ce 删除本地文件 注意，docker 的本地文件，包括镜像(images), 容器(containers), 存储卷(volumes)等，都需要手工删除。默认目录存储在 /var/lib/docker。 sudo rm -rf /var/lib/docker 9. Docker拉取镜像慢解决方法镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。 新版的 Docker 使用 /etc/docker/daemon.conf（Linux） 或者 %programdata%\\docker\\config\\daemon.json（Windows） 来配置 Daemon。 请在该配置文件中加入（没有该文件的话，请先建一个）： { “registry-mirrors”: [“http://hub-mirror.c.163.com\"]} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://fyvan.github.io/tags/Docker/"}],"author":"fyang"},{"title":"Redis安装与用法","slug":"SoftwareInstall-2020-05-27-CentsOS-Redis","date":"2020-05-27T01:06:48.520Z","updated":"2020-06-18T08:19:42.281Z","comments":true,"path":"undefined/d618.html","link":"","permalink":"http://fyvan.github.io/undefined/d618.html","excerpt":"","text":"1. 在Redis官网下载软件包下载地址 2. 上传文件到Linux使用lrzsz或者ftp上传 [root@localhost src]# rz -E rz waiting to receive. [root@localhost src]# ls images jdk1.8 nginx-1.19.0 redis-6.0.3.tar.gz tomcats # 检查防火墙状态是否关闭 [root@localhost src]# firewall-cmd --state not running 3. 解压Redis压缩包# 解压并删除tar.gz压缩包 [root@localhost src]# tar -xvf redis-5.0.4.tar.gz [root@localhost src]# rm -f redis-5.0.4.tar.gz [root@localhost src]# ls images jdk1.8 nginx-1.19.0 redis-5.0.4 tomcats 4. 安装Redis 进入解压后的redis目录 [root@localhost src]# cd redis-5.0.4/ [root@localhost redis-5.0.4]# ll 总用量 252 -rw-rw-r--. 1 root root 99445 3月 19 2019 00-RELEASENOTES -rw-rw-r--. 1 root root 53 3月 19 2019 BUGS -rw-rw-r--. 1 root root 1894 3月 19 2019 CONTRIBUTING -rw-rw-r--. 1 root root 1487 3月 19 2019 COPYING drwxrwxr-x. 6 root root 124 3月 19 2019 deps -rw-rw-r--. 1 root root 11 3月 19 2019 INSTALL -rw-rw-r--. 1 root root 151 3月 19 2019 Makefile -rw-rw-r--. 1 root root 4223 3月 19 2019 MANIFESTO -rw-rw-r--. 1 root root 20555 3月 19 2019 README.md -rw-rw-r--. 1 root root 62155 3月 19 2019 redis.conf -rwxrwxr-x. 1 root root 275 3月 19 2019 runtest -rwxrwxr-x. 1 root root 280 3月 19 2019 runtest-cluster -rwxrwxr-x. 1 root root 281 3月 19 2019 runtest-sentinel -rw-rw-r--. 1 root root 9710 3月 19 2019 sentinel.conf drwxrwxr-x. 3 root root 4096 3月 19 2019 src drwxrwxr-x. 10 root root 167 3月 19 2019 tests drwxrwxr-x. 8 root root 4096 3月 19 2019 utils 编译redis [root@localhost src]# make cd src && make all make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” CC Makefile.dep make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” ... LINK redis-server INSTALL redis-sentinel CC redis-cli.o LINK redis-cli CC redis-benchmark.o LINK redis-benchmark INSTALL redis-check-rdb INSTALL redis-check-aof Hint: It's a good idea to run 'make test' ;) make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” 执行安装 [root@localhost redis-5.0.4]# make install cd src && make install make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” CC Makefile.dep make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” 5. 修改Redis配置文件 关闭IP绑定 注释配置文件中的IP绑定 只有去除IP绑定,远程机才能进行访问 关闭保护模式 protected-mode yes yes—to—&gt;no 开启后台启动 daemonize yes no—to—&gt;yes 阻止启动redis后独占终端 Esc———-:wq———-保存退出 6. Reids命令可以在官网查看Redis命令的使用https://redis.io/commands 启动Redis [root@localhost redis-5.0.4]# redis-server redis.conf 9700:C 27 May 2020 17:47:09.537 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 9700:C 27 May 2020 17:47:09.537 # Redis version=5.0.4, bits=64, commit=00000000, modified=0, pid=9700, just started 9700:C 27 May 2020 17:47:09.537 # Configuration loaded 检查Redis进程信息 [root@localhost redis-5.0.4]# ps -ef | grep redis root 9701 1 0 17:47 ? 00:00:00 redis-server *:6379 root 9708 1448 0 17:48 pts/0 00:00:00 grep --color=auto redis 关闭Redis [root@localhost redis-5.0.4]# redis-cli -p 6379 shutdown 进入Redis客户端 [root@localhost redis-5.0.4]# redis-cli -p 6379 127.0.0.1:6379> # 使用默认端口6379可以省略不写 [root@localhost redis-5.0.4]# redis-cli 关闭客户端 Ctrl + C6.1 String类型数据 命令 说明 案例 set 添加key-value set username admin get 根据key获取数据 get username strlen 根据key获取值的长度 strlen key exists 判断key是否存在 exists name 返回1存在 0不存在 del 删除redis中的key del key Keys 用于查询符合条件的key keys * 查询redis中全部的key keys n?me 使用占位符获取数据 keys nam* 获取nam开头的数据 mset 赋值多个key-value mset key1 value1 key2 value2 key3 value3 mget 获取多个key的值 mget key1 key2 append 对某个key的值进行追加 append key value type 检查某个key的类型 type key select 切换redis数据库 select 0-15 redis中共有16个数据库 flushdb 清空单个数据库 flushdb flushall 清空全部数据库 flushall incr 自动加1 incr key decr 自动减1 decr key incrby 指定数值添加 incrby 10 decrby 指定数值减 decrby 10 expire 指定key的生效时间 单位秒 expire key 20 key20秒后失效 pexpire 指定key的失效时间 单位毫秒 pexpire key 2000 key 2000毫秒后失效 ttl 检查key的剩余存活时间 ttl key -2数据不存在 -1该数据永不超时 persist 撤销key的失效时间 persist key 6.2 Hash类型说明:可以用散列类型保存对象和属性值 例子:User对象{id:2,name:小明,age:19} 命令 说明 案例 hset 为对象添加数据 hset key field value hget 获取对象的属性值 hget key field hexists 判断对象的属性是否存在 HEXISTS key field 1表示存在 0表示不存在 hdel 删除hash中的属性 hdel user field [field …] hgetall 获取hash全部元素和值 HGETALL key hkyes 获取hash中的所有字段 HKEYS key hlen 获取hash中所有属性的数量 hlen key hmget 获取hash里面指定字段的值 hmget key field [field …] hmset 为hash的多个字段设定值 hmset key field value [field value …] hsetnx 设置hash的一个字段,只有当这个字段不存在时有效 HSETNX key field value hstrlen 获取hash中指定key的值的长度 HSTRLEN key field hvals 获取hash的所有值 HVALS user 6.3 List类型说明:Redis中的List集合是双端循环列表,分别可以从左右两个方向插入数据. List集合可以当做队列使用,也可以当做栈使用 队列:存入数据的方向和获取数据的方向相反 栈:存入数据的方向和获取数据的方向相同 命令 说明 案例 lpush 从队列的左边入队一个或多个元素 LPUSH key value [value …] rpush 从队列的右边入队一个或多个元素 RPUSH key value [value …] lpop 从队列的左端出队一个元素 LPOP key rpop 从队列的右端出队一个元素 RPOP key lpushx 当队列存在时从队列的左侧入队一个元素 LPUSHX key value rpushx 当队列存在时从队列的右侧入队一个元素 RPUSHx key value lrange 从列表中获取指定返回的元素 LRANGE key start stop Lrange key 0 -1 获取全部队列的数据 lrem 从存于 key 的列表里移除前 count 次出现的值为 value 的元素。 这个 count 参数通过下面几种方式影响这个操作： · count &gt; 0: 从头往尾移除值为 value 的元素。 · count &lt; 0: 从尾往头移除值为 value 的元素。 · count = 0: 移除所有值为 value 的元素。 LREM list -2 “hello” 会从存于 list 的列表里移除最后两个出现的 “hello”。 需要注意的是，如果list里没有存在key就会被当作空list处理，所以当 key 不存在的时候，这个命令会返回 0。 Lset 设置 index 位置的list元素的值为 value LSET key index value 6.4 Redis事务命令说明:redis中操作可以添加事务的支持.一项任务可以由多个redis命令完成,如果有一个命令失败导致入库失败时.需要实现事务回滚. 命令 说明 案例 multi 标记一个事务开始 127.0.0.1:6379&gt; MULTI OK exec 执行所有multi之后发的命令 127.0.0.1:6379&gt; EXEC OK discard 丢弃所有multi之后发的命令 7. Redis高级应用7.1 在pom.xml中添加jar包文件说明:在JT-PARENT项目中添加jar包文件 &lt;!-- jedis --> &lt;dependency> &lt;groupId>redis.clients&lt;/groupId> &lt;artifactId>jedis&lt;/artifactId> &lt;version>${jedis.version}&lt;/version> &lt;/dependency> &lt;!--添加spring-datajar包 --> &lt;dependency> &lt;groupId>org.springframework.data&lt;/groupId> &lt;artifactId>spring-data-redis&lt;/artifactId> &lt;version>1.4.1.RELEASE&lt;/version> &lt;/dependency> 7.2 String类型数据测试package com.jt.test; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Test; import redis.clients.jedis.Jedis; import redis.clients.jedis.params.SetParams; public class TestRedis { @Test public void testString01(){ //1.连接Redis String host = \"192.168.126.129\"; int port= 6379; Jedis jedis = new Jedis(host, port); //2.操作redis jedis.set(\"2002\",\"学习好辛苦\"); String value = jedis.get(\"2002\"); System.out.println(value); //3.判断redis中是否有指定数据 if(!jedis.exists(\"2002\")){ jedis.set(\"2002\",\"两会精神\"); } //4.删除 jedis.del(\"2002\"); //5.检索数据 System.out.println(jedis.keys(\"*\")); //6.清空数据 jedis.flushAll(); } //测试类的初始化操作 private Jedis jedis; @BeforeEach public void init(){ jedis = new Jedis(\"192.168.126.129\", 6379); } //如果采用expire则不能保证超时时间的原子性操作!!! //lock锁: 死锁 @Test public void testStringEX() throws InterruptedException { jedis.set(\"abc\",\"测试数据的有效期\"); //1.没有设定超时时间,用不过期 //int a = 1/0; //如果发生异常,数据已存入redis数据库中 jedis.expire(\"abc\",5); //2.设定超时 Thread.sleep(2000); Long seconds = jedis.ttl(\"abc\"); System.out.println(\"abc剩余的存活时间: \" + seconds); jedis.persist(\"abc\"); //保证赋值的原子性操作 jedis.setex(\"www\",10,\"超时测试\"); } /** * 需求:如果a存在,则不允许重新赋值 * @throws InterruptedException */ @Test public void testStringNX() throws InterruptedException { /*jedis.set(\"a\",\"123\"); jedis.set(\"a\",\"456\"); System.out.println(jedis.get(\"a\")); if (!jedis.exists(\"a\")){ jedis.set(\"a\",\"11111111\"); } System.out.println(jedis.get(\"a\"));*/ //如果key不存在时,则赋值 jedis.setnx(\"a\",\"123\"); jedis.setnx(\"a\",\"456\"); System.out.println(jedis.get(\"a\")); //123 } /** * 1.保证超时时间的原子性操作 EX * 2.保证如果key存在,则不允许赋值 NX * 需求:既满足超时定义,又要满足数据不允许修改 * SetParams:参数 * EX: 秒 * PX: 毫秒 * NX: 有值不修改 * XX: 如果key不存在,则数据不修改 */ @Test public void testStringEXNX(){ SetParams setParams = new SetParams(); setParams.ex(20).nx(); jedis.set(\"a\",\"66666666666\",setParams); jedis.set(\"a\",\"1111111111111111\",setParams); System.out.println(jedis.get(\"a\")); } } 7.3 hash类型测试/** * 一般会将有关联关系的数据利用hash方式进行保存. * orderID: * userID:下单用户 * price: xxxxx * items: [xxxxx] * orderShipping: xxxxx */ @Test public void testHash(){ jedis.hset(\"orderID\",\"userID\",\"100\"); jedis.hset(\"orderID\",\"price\",\"2341.34\"); jedis.hset(\"orderID\",\"items\",\"描述信息\"); jedis.hset(\"orderID\",\"orderShipping\",\"物流信息\"); System.out.println(jedis.hgetAll(\"orderID\")); System.out.println(jedis.hkeys(\"orderID\")); System.out.println(jedis.hvals(\"orderID\")); } 结果展现: 操作完成!!!1 {userID=100, items=描述信息, orderShipping=物流信息, price=2341.34} [userID, items, orderShipping, price] [100, 2341.34, 描述信息, 物流信息] 7.4 List类型测试@Test public void testList(){ jedis.lpush(\"list1\",\"1,2,3,4,5\"); String value1 = jedis.rpop(\"list1\"); System.out.println(value1); //1,2,3,4,5 jedis.lpush(\"list2\",\"1\",\"2\",\"3\",\"4\",\"5\"); String value2 = jedis.rpop(\"list2\"); System.out.println(value2); //1 } 结果展现: 1,2,3,4,5 1 7.5 事务测试@Test public void testTX(){ Transaction transaction = jedis.multi(); //开始事务 try{ transaction.set(\"a\",\"a\"); transaction.set(\"b\",\"b\"); transaction.exec(); //提交事务 }catch (Exception e){ transaction.discard(); //事务回滚 } } 注意: 虽然redis提供了事务操作,但是该事务是一种弱事务. 只对单台redis有效 如果存在多台redis,并且需要使用事务控制,一般使用队列的形式进行事务控制 8. SpringBoot整合Redis8.1 整合Redis的步骤 将redis的配置文件写入到properties文件中. 利用SpringBoot的配置类整合Redis. 实现Redis的复用. 8.2 编辑properties文件 说明: 为了实现redis整合的通用,所以将redis.properties文件放到jt-common中 #配置单台redis redis.host=192.168.126.129 redis.port=6379 8.3 编辑redis.config配置文件 作用:将redis对象交给spring容器进行管理.并且用户通过@Autowired注解动态获取对象. 细节:在jt-common中编辑配置类 配置类: @Configuration //标识配置类 一般和@Bean注解连用 @PropertySource(\"classpath:/properties/redis.properties\") public class RedisConfig { @Value(\"${redis.host}\") private String host; @Value(\"${redis.port}\") private Integer port; //将哪个对象交给容器管理,返回值就是什么对象 @Bean public Jedis jedis(){ return new Jedis(host, port); } } 测试: @SpringBootTest public class RedisConfigTests { @Autowired private Jedis jedis; @Test public void redisConfTest(){ jedis.set(\"key\",\"Hello Redis\"); String value = jedis.get(\"key\"); System.out.println(value); } } 结果: document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, Redis","slug":"CentOS7-Redis","permalink":"http://fyvan.github.io/tags/CentOS7-Redis/"}],"author":"fyang"},{"title":"CentOS7安装Mysql","slug":"SoftwareInstall-2020-05-26-CentOS-mysql","date":"2020-05-26T08:09:00.910Z","updated":"2020-06-18T08:19:18.401Z","comments":true,"path":"undefined/4871.html","link":"","permalink":"http://fyvan.github.io/undefined/4871.html","excerpt":"","text":"1. 安装Maria DB使用yum安装 (需要配置好yum,有网络) yum install mariadb-server 需要依赖, 输入y 回车继续 安装完成后如下所示: 2. MariaDB 命令 启动数据库: systemctl start mariadb 停止数据库: systemctl stop mariadb 重启数据库: systemctl restart mariadb 3. MariaDB 配置输入mysql_secure_installation命令配置数据库,如下注释中的解释 [root@localhost src]# mysql_secure_installation NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] Y # 设置密码 y New password: # 新密码 Re-enter new password: # 再次输入密码 Password updated successfully! Reloading privilege tables.. ... Success! By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] Y #是否移除匿名用户,输入Y,回车继续 ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. # 拒绝root远程登录,n, 不管y/n,都会拒绝root远程登录 Disallow root login remotely? [Y/n] n ... skipping. By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. # 删除test数据库,y:删除 n:不删除. 数据库中会有一个test数据库,一般不需要 Remove test database and access to it? [Y/n] n ... skipping. Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] y # 重新加载权限表,y. 或者重启服务也行 ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! 4. 数据库登录测试使用用户名:root &amp; 密码:root 登录数据库 [root@localhost src]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 7 Server version: 5.5.65-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> 5. 设定远程访问说明:Mysql数据库默认条件下不允许远程用户访问数据库,只允许本地服务通过127.0.0.1/localhost的方式访问! 需求:想通过Windows的SqlYog程序远程访问数据库,则必须修改mysql的权限列表. 本地登录数据库: [root@localhost src]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 8 Server version: 5.5.65-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> 查看并切换数据库: MariaDB [(none)]> show databases; # 查看数据库 +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | test | +--------------------+ 4 rows in set (0.00 sec) MariaDB [(none)]> use mysql; # 切换数据库 Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed MariaDB [mysql]> 查看数据库表信息: MariaDB [mysql]> show tables; # 查看数据库表信息 +---------------------------+ | Tables_in_mysql | +---------------------------+ | columns_priv | | db | | event | | func | | general_log | | help_category | | help_keyword | | help_relation | | help_topic | | host | | ndb_binlog_index | | plugin | | proc | | procs_priv | | proxies_priv | | servers | | slow_log | | tables_priv | | time_zone | | time_zone_leap_second | | time_zone_name | | time_zone_transition | | time_zone_transition_type | | user | +---------------------------+ 24 rows in set (0.00 sec) 查看root账户权限信息 # host : 表示允许访问的主机 # user : 用户信息 # password : 密码信息 (MD5加密) MariaDB [mysql]> select host,user,password from user; +-----------+------+-------------------------------------------+ | host | user | password | +-----------+------+-------------------------------------------+ | localhost | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | 127.0.0.1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | ::1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | +-----------+------+-------------------------------------------+ 3 rows in set (0.00 sec) 修改用户权限列表,实现用户远程访问 将与主机名相等的字段改为\" % \",我的主机名为root MariaDB [mysql]> update user set host='%' where host='localhost'; Query OK, 1 rows affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 MariaDB [mysql]> select host,user,password from user; +-----------+------+-------------------------------------------+ | host | user | password | +-----------+------+-------------------------------------------+ | % | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | 127.0.0.1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | ::1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | +-----------+------+-------------------------------------------+ 3 rows in set (0.00 sec) 刷新权限列表或者重启数据库服务 # 刷新权限列表 MariaDB [mysql]> flush privileges; Query OK, 0 rows affected (0.00 sec) # 或者重启数据库服务 [root@localhost src]# systemctl restart mariadb [root@localhost src]# 关闭Linux防火墙,使用SQLyog连接数据库 设置Linux开机自动启动数据库服务 [root@localhost ~]# systemctl enable mariadb Created symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service. 6. Linux中的防火墙 检查防火墙状态信息 [root@localhost src]# firewall-cmd --state running 临时关闭防火墙操作,系统重启后防火墙会重新开启. [root@localhost src]# systemctl stop firewalld.service [root@localhost src]# firewall-cmd --state not running 开启防火墙操作 [root@localhost src]# systemctl stop firewalld.service [root@localhost src]# firewall-cmd --state not running 永久关闭防火墙操作 # 表示系统下次启动时不开启防火墙 [root@localhost src]# systemctl disable firewalld.service Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. # 防火墙还是运行状态 [root@localhost src]# firewall-cmd --state running # 还需要将当前防火墙关闭 [root@localhost src]# systemctl stop firewalld.service [root@localhost src]# firewall-cmd --state not running 永久开启防火墙操作 # 表示系统下次启动时开启防火墙 [root@localhost src]# systemctl enable firewalld.service Created symlink from /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service to /usr/lib/systemd/system/firewalld.service. Created symlink from /etc/systemd/system/multi-user.target.wants/firewalld.service to /usr/lib/systemd/system/firewalld.service. # 防火墙还是关闭状态 [root@localhost src]# firewall-cmd --state not running # 还需要将当前防火墙开启 [root@localhost src]# systemctl start firewalld.service [root@localhost src]# firewall-cmd --state running 7. 使用Docker安装mysql项目的底层数据库采用MySQL，而MySQL采用衍生版本Percona，并且采用docker容器化的方式进行部署。 什么是percona？ Percona 为 MySQL 数据库服务器进行了改进，在功能和性能上较 MySQL 有着很显著的提升。该版本提升了在高负载情况下的 InnoDB 的性能、为 DBA 提供一些非常有用的性能诊断工具；另外有更多的参数和命令来控制服务器行为。Percona Server 只包含 MySQL 的服务器版，并没有提供相应对 MySQL 的 Connector 和 GUI 工具进行改进。Percona Server 使用了一些 google-mysql-tools, Proven Scaling, Open Query 对 MySQL 进行改造。官网：https://www.percona.com/software/mysql-database 安装部署 #镜像地址：https://hub.docker.com/_/percona/ #拉取镜像 docker pull percona:5.7.23 #创建容器 docker create --name percona -v /data/mysql-data:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root percona:5.7.23 c5af61393e45d4565c247139f7daea1acce7b057a722fd877ee4e456e2ffc3a0 #参数解释： --name： percona 指定是容器的名称 -v： /data/mysql-data:/var/lib/mysql 将主机目录/data/mysql-data挂载到容器 的/var/lib/mysql上 -p： 3306:3306 设置端口映射，主机端口是3306，容器内部端口3306 -e： MYSQL_ROOT_PASSWORD=root 设置容器参数，设置root用户的密码为root percona:5.7.23： 镜像名:版本 #启动容器 docker start percona 测试： 启动percona的时候发现没啥问题，但是在docker ps查看的时候会发现没有percona，而且查看/data/mysql-data文件也没有写入内容。 使用docker ps -a查看就可以看见问题 Exited (1) About a minute ago 服务闪退了 解决方案 给data文件添加权限即可 chmod -R 777 /data 测试宿主机客户端: 连接成功 8. docker常用命令列出所有容器ID docker ps -aq 查看所有运行或者不运行容器 docker ps -a 停止所有的container（容器），这样才能够删除其中的images： docker stop $(docker ps -a -q) 或者 docker stop $(docker ps -aq) 如果想要删除所有container（容器）的话再加一个指令： docker rm $(docker ps -a -q) 或者 docker rm $(docker ps -aq) 查看当前有些什么images docker images 删除images（镜像），通过image的id来指定删除谁 docker rmi 想要删除untagged images，也就是那些id为的image的话可以用 docker rmi $(docker images | grep \"^\" | awk \"{print $3}\") 要删除全部image（镜像）的话 docker rmi $(docker images -q) 强制删除全部image的话 强制删除全部image的话 docker rmi -f $(docker images -q) 从容器到宿主机复制 docker cp tomcat：/webapps/js/text.js /home/admin docker cp 容器名: 容器路径 宿主机路径 从宿主机到容器复制 从宿主机到容器复制 docker cp /home/admin/text.js tomcat：/webapps/js docker cp 宿主路径中文件 容器名 容器路径 删除所有停止的容器 docker container prune 删除所有不使用的镜像 docker image prune --force --all或者docker image prune -f -a 停止、启动、杀死、重启一个容器 停止、启动、杀死、重启一个容器 docker stop Name或者ID docker start Name或者ID docker kill Name或者ID docker restart name或者ID docker进入容器，查看配置文件 docker进入容器，查看配置文件 docker exec ：在运行的容器中执行命令 -d :分离模式: 在后台运行 -i :即使没有附加也保持STDIN（标准输入） 打开,以交互模式运行容器，通常与 -t 同时使用； -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； docker exec -it f94d2c317477 /bin/bash出现root@f94d2c317477:/usr/share/elasticsearch/config# vi elasticsearch.ymlbash: vi: command not found apt-get update && apt-get install vim -y 修改配置、退出容器 1、如果要正常退出不关闭容器，请按Ctrl+P+Q进行退出容器 2、如果使用exit退出，那么在退出之后会关闭容器，可以使用下面的流程进行恢复 使用docker restart命令重启容器 使用docker attach命令进入容器 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, mariadb","slug":"CentOS7-mariadb","permalink":"http://fyvan.github.io/tags/CentOS7-mariadb/"}],"author":"fyang"},{"title":"CentOS7安装Nginx","slug":"SoftwareInstall-2020-05-26-Centos-nginx","date":"2020-05-26T08:04:06.090Z","updated":"2020-06-18T08:19:31.666Z","comments":true,"path":"undefined/981a.html","link":"","permalink":"http://fyvan.github.io/undefined/981a.html","excerpt":"","text":"1. 下载Linux版的Ngnix 下载链接 2. 上传文件到Linux服务器使用lrzsz方式上传,直接拖拽 3. 解压上传文件,并删除压缩包# 解压文件 [root@localhost src]# tar -xzvf nginx-1.19.0.tar.gz nginx-1.19.0/ nginx-1.19.0/auto/ ...... nginx-1.19.0/auto/cc/name nginx-1.19.0/auto/cc/owc nginx-1.19.0/auto/cc/sunc # 查看文件目录结构 [root@localhost src]# ls images jdk1.8 nginx-1.19.0 nginx-1.19.0.tar.gz tomcats # 删除压缩包 [root@localhost src]# rm -rf nginx-1.19.0.tar.gz 4. 安装Nginxnginx安装中会有源文件目录和工作目录之分 配置Nginx # 查看文件目录结构 [root@localhost nginx-1.19.0]# ls auto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src [root@localhost nginx-1.19.0]# ./configure checking for OS + Linux 3.10.0-1062.18.1.el7.x86_64 x86_64 checking for C compiler ... found + using GNU C compiler + gcc version: 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ....... # 校验文件 creating objs/Makefile Configuration summary + using system PCRE library + OpenSSL library is not used + using system zlib library nginx path prefix: \"/usr/local/nginx\" # 工作目录 nginx binary file: \"/usr/local/nginx/sbin/nginx\" nginx modules path: \"/usr/local/nginx/modules\" nginx configuration prefix: \"/usr/local/nginx/conf\" nginx configuration file: \"/usr/local/nginx/conf/nginx.conf\" nginx pid file: \"/usr/local/nginx/logs/nginx.pid\" nginx error log file: \"/usr/local/nginx/logs/error.log\" nginx http access log file: \"/usr/local/nginx/logs/access.log\" nginx http client request body temporary files: \"client_body_temp\" nginx http proxy temporary files: \"proxy_temp\" nginx http fastcgi temporary files: \"fastcgi_temp\" nginx http uwsgi temporary files: \"uwsgi_temp\" nginx http scgi temporary files: \"scgi_temp\" 编译源文件 [root@localhost nginx-1.19.0]# make make -f objs/Makefile make[1]: 进入目录“/usr/local/src/nginx-1.19.0” cc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\ ...... -Wl,-E sed -e \"s|%%PREFIX%%|/usr/local/nginx|\" \\ -e \"s|%%PID_PATH%%|/usr/local/nginx/logs/nginx.pid|\" \\ -e \"s|%%CONF_PATH%%|/usr/local/nginx/conf/nginx.conf|\" \\ -e \"s|%%ERROR_LOG_PATH%%|/usr/local/nginx/logs/error.log|\" \\ < man/nginx.8 > objs/nginx.8 make[1]: 离开目录“/usr/local/src/nginx-1.19.0” 执行安装指令 [root@localhost nginx-1.19.0]# make install make -f objs/Makefile install make[1]: 进入目录“/usr/local/src/nginx-1.19.0” test -d '/usr/local/nginx' || mkdir -p '/usr/local/nginx' ... make[1]: 离开目录“/usr/local/src/nginx-1.19.0” 检查安装路径 # 工作目录 [root@localhost nginx-1.19.0]# whereis nginx nginx: /usr/local/nginx 安装中报错信息: #安装Nginx时报错 ./configure: error: the HTTP rewrite module requires the PCRE library. #安装pcre-devel解决问题 yum -y install pcre-devel #错误提示： ./configure: error: the HTTP cache module requires md5 functions from OpenSSL library. You can either disable the module by using --without-http-cache option, or install the OpenSSL library into the system, or build the OpenSSL library statically from the source with nginx by using --with-http_ssl_module --with-openssl= options. # 解决办法： yum -y install openssl openssl-devel # 总结： yum -y install pcre-devel openssl openssl-devel ./configure --prefix=/usr/local/nginx make make install 5. Nginx命令 进入工作目录,查看目录结构 [root@localhost nginx-1.19.0]# cd /usr/local/nginx/ [root@localhost nginx]# ll 总用量 4 drwxr-xr-x. 2 root root 4096 5月 27 11:43 conf # 配置文件 drwxr-xr-x. 2 root root 40 5月 27 11:43 html # 欢迎页 drwxr-xr-x. 2 root root 6 5月 27 11:43 logs # 日志文件 drwxr-xr-x. 2 root root 19 5月 27 11:43 sbin # nginx命令 使用nginx命令 启动nginx并查看进程 ./nginx [root@localhost nginx]# cd sbin/ [root@localhost sbin]# ll 总用量 3764 -rwxr-xr-x. 1 root root 3851112 5月 27 11:43 nginx [root@localhost sbin]# ./nginx [root@localhost sbin]# ps -ef | grep nginx root 12672 1 0 11:49 ? 00:00:00 nginx: master process ./nginx nobody 12673 12672 0 11:49 ? 00:00:00 nginx: worker process root 12687 1829 0 11:49 pts/0 00:00:00 grep --color=auto nginx 更新nginx配置 [root@localhost sbin]# ./nginx -s reload 停止nginx服务 [root@localhost sbin]# ./nginx -s stop 6. 测试Nginxwindow浏览器访问localhost,虚拟机访问分配的ip地址:192.168.126.129 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, Nginx","slug":"CentOS7-Nginx","permalink":"http://fyvan.github.io/tags/CentOS7-Nginx/"}],"author":"fyang"},{"title":"CentOS7安装jdk1.8","slug":"SoftwareInstall-2020-05-26-Centos-jdk","date":"2020-05-26T07:25:41.609Z","updated":"2020-06-18T08:19:04.332Z","comments":true,"path":"undefined/f754.html","link":"","permalink":"http://fyvan.github.io/undefined/f754.html","excerpt":"","text":"1. 安装lrzsz我们常用ftp上传一些文件到Linux服务器,或者从LInux服务器上下载一些文件到本地.如果只是传输一些小文件的话,可以使用lrzsz,作为ftp的代替品. 使用如下命令安装lrzsz yum -y install lrzsz 安装完成后在Xshell中到想安装的目录下,我的是在/usr/local/src/,直接拖拽上传: 2. 解压上传的jdk文件tar -zxvf jdk-8u51-linux-x64.tar.gz 解压完成后目录文件如下: 3. 删除jdk的压缩包rm -f jdk-8u51-linux-x64.tar.gz 4. 重命名jdk的解压文件夹[root@localhost src]# mv jdk1.8.0_51 jdk1.8 [root@localhost src]# ll 总用量 0 drwxr-xr-x. 8 10 143 255 6月 9 2015 jdk1.8 5. 配置环境变量#修改/etc/profile文件,添加下面内容 export JAVA_HOME=/usr/local/src/jdk1.8 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib #配置类加载器 6. 刷新环境变量,是配置立即生效[root@localhost jdk1.8.0]# source /etc/profile 7. 验证安装结果如下显示jdk版本则表示成功 [root@localhost jdk1.8.0]# java -version java version \"1.8.0_51\" Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, jdk1.8","slug":"CentOS7-jdk1-8","permalink":"http://fyvan.github.io/tags/CentOS7-jdk1-8/"}],"author":"fyang"},{"title":"MySql数据库优化","slug":"Mysql优化面试-2020-05-25","date":"2020-05-25T12:20:53.927Z","updated":"2020-06-18T08:18:08.871Z","comments":true,"path":"undefined/276e.html","link":"","permalink":"http://fyvan.github.io/undefined/276e.html","excerpt":"","text":"1. 概述1.1 为什么要优化 系统的吞吐量瓶颈往往出现在数据库的访问速度上 随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢 数据是存放在磁盘上的，读写速度无法和内存相比 1.2 如何优化 设计数据库时：数据库表、字段的设计，存储引擎 利用好MySQL自身提供的功能，如索引等 横向扩展：MySQL集群、负载均衡、读写分离 SQL语句的优化（收效甚微） 2. 字段设计 字段类型的选择，设计规范，范式，常见设计案例 2.1 原则：尽量使用整型表示字符串2.1.1存储IPINET_ATON(str)，address to number INET_NTOA(number)，number to address 2.1.2 MySQL内部的枚举类型（单选）和集合（多选）类型但是因为维护成本较高因此不常使用，使用关联表的方式来替代enum 2.2 原则：定长和非定长数据类型的选择 decimal不会损失精度，存储空间会随数据的增大而增大。double占用固定空间，较大数的存储会损失精度。非定长的还有varchar、text 2.2.1 金额 对数据的精度要求较高，小数的运算和存储存在精度问题（不能将所有小数转换成二进制） 2.2.2 定点数decimalprice decimal(8,2)有2位小数的定点数，定点数支持很大的数（甚至是超过int,bigint存储范围的数） 2.2.3 小单位大数额避免出现小数元-&gt;分 2.2.4字符串存储定长char，非定长varchar、text（上限65535，其中varchar还会消耗1-3字节记录长度，而text使用额外空间记录长度） 2.3 原则：尽可能选择小的数据类型和指定短的长度2.4 原则：尽可能使用 not null非null字段的处理要比null字段的处理高效些！且不需要判断是否为null。 null在MySQL中，不好处理，存储需要额外空间，运算也需要特殊的运算符。如select null = null和select null &lt;&gt; null（&lt;&gt;为不等号）有着同样的结果，只能通过is null和is not null来判断字段是否为null。 如何存储？MySQL中每条记录都需要额外的存储空间，表示每个字段是否为null。因此通常使用特殊的数据进行占位，比如int not null default 0、string not null default ‘’ 2.5 原则：字段注释要完整，见名知意2.6 原则：单表字段不宜过多二三十个就极限了 2.7 原则：可以预留字段 在使用以上原则之前首先要满足业务需求 3. 关联表的设计 外键foreign key只能实现一对一或一对多的映射 3.1 一对一如商品的基本信息（item）和商品的详细信息（item_intro），通常使用相同的主键或者增加一个外键字段（item_id） 3.2 一对多使用外键 3.3 多对多单独新建一张表将多对多拆分成两个一对多 4. 范式 Normal Format 数据表的设计规范，一套越来越严格的规范体系（如果需要满足N范式，首先要满足N-1范式）。N 4.1 第一范式1NF：字段原子性字段原子性，字段不可再分割。 关系型数据库，默认满足第一范式 注意比较容易出错的一点，在一对多的设计中使用逗号分隔多个外键，这种方法虽然存储方便，但不利于维护和索引（比如查找带标签java的文章） 4.2 第二范式：消除对主键的部分依赖 即在表中加上一个与业务逻辑无关的字段作为主键 主键：可以唯一标识记录的字段或者字段集合。 course_name course_class weekday（周几） course_teacher MySQL 教育大楼1525 周一 张三 Java 教育大楼1521 周三 李四 MySQL 教育大楼1521 周五 张三 依赖：A字段可以确定B字段，则B字段依赖A字段。比如知道了下一节课是数学课，就能确定任课老师是谁。于是周几和下一节课和就能构成复合主键，能够确定去哪个教室上课，任课老师是谁等。但我们常常增加一个id作为主键，而消除对主键的部分依赖。 对主键的部分依赖：某个字段依赖复合主键中的一部分。 解决方案：新增一个独立字段作为主键。 4.3 第三范式：消除对主键的传递依赖传递依赖：B字段依赖于A，C字段又依赖于B。比如上例中，任课老师是谁取决于是什么课，是什么课又取决于主键id。因此需要将此表拆分为两张表日程表和课程表（独立数据独立建表）： id weekday course_class course_id 1001 周一 教育大楼1521 3546 course_id course_name course_teacher 3546 Java 张三 这样就减少了数据的冗余（即使周一至周日每天都有Java课，也只是course_id:3546出现了7次） 5. 存储引擎选择 早期问题：如何选择MyISAM和Innodb？ 现在不存在这个问题了，Innodb不断完善，从各个方面赶超MyISAM，也是MySQL默认使用的。 存储引擎Storage engine：MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。 5.1 功能差异show engines Engine Support Comment InnoDB DEFAULT Supports transactions, row-level locking, and foreign keys MyISAM YES MyISAM storage engine 5.2 存储差异 MyISAM Innodb 文件格式 数据和索引是分别存储的，数据.MYD，索引.MYI 数据和索引是集中存储的，.ibd 文件能否移动 能，一张表就对应.frm、MYD、MYI3个文件 否，因为关联的还有data下的其它文件 记录存储顺序 按记录插入顺序保存 按主键大小有序插入 空间碎片（删除记录并flush table 表名之后，表文件大小不变） 产生。定时整理：使用命令optimize table 表名实现 不产生 事务 不支持 支持 外键 不支持 支持 锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的） 表级锁定 行级锁定、表级锁定，锁定力度小并发能力高 锁扩展 表级锁（table-level lock）：lock tables &lt;table_name1&gt;,&lt;table_name2&gt;... read/write，unlock tables &lt;table_name1&gt;,&lt;table_name2&gt;...。其中read是共享锁，一旦锁定任何客户端都不可读；write是独占/写锁，只有加锁的客户端可读可写，其他客户端既不可读也不可写。锁定的是一张表或几张表。 行级锁（row-level lock）：锁定的是一行或几行记录。共享锁：select * from &lt;table_name&gt; where &lt;条件&gt; LOCK IN SHARE MODE;，对查询的记录增加共享锁；select * from &lt;table_name&gt; where &lt;条件&gt; FOR UPDATE;，对查询的记录增加排他锁。这里值得注意的是：innodb的行锁，其实是一个子范围锁，依据条件锁定部分范围，而不是就映射到具体的行上，因此还有一个学名：间隙锁。比如select * from stu where id &lt; 20 LOCK IN SHARE MODE会锁定id在20左右以下的范围，你可能无法插入id为18或22的一条新纪录。 5.3 选择依据如果没有特别的需求，使用默认的Innodb即可。 MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键保证数据完整性。比如OA自动化办公系统。 6. 索引 关键字与数据的映射关系称为索引（==包含关键字和对应的记录在磁盘中的地址==）。关键字是从数据当中提取的用于标识、检索数据的特定内容。 6.1 索引检索为什么快？ 关键字相对于数据本身，数据量小 关键字是有序的，二分查找可快速确定位置 图书馆为每本书都加了索引号（类别-楼层-书架）、字典为词语解释按字母顺序编写目录等都用到了索引。 6.2 MySQL中索引类型 普通索引（key），唯一索引（unique key），主键索引（primary key），全文索引（fulltext key） 三种索引的索引方式是一样的，只不过对索引的关键字有不同的限制： 普通索引：对关键字没有限制 唯一索引：要求记录提供的关键字不能重复 主键索引：要求关键字唯一且不为null 6.3 索引管理语法6.3.1 查看索引show create table 表名`： desc 表名 6.3.2 创建索引6.3.2.1 创建表之后建立索引create TABLE user_index( id int auto_increment primary key, first_name varchar(16), last_name VARCHAR(16), id_card VARCHAR(18), information text ); -- 更改表结构 alter table user_index -- 创建一个first_name和last_name的复合索引，并命名为name add key name (first_name,last_name), -- 创建一个id_card的唯一索引，默认以字段名作为索引名 add UNIQUE KEY (id_card), -- 鸡肋，全文索引不支持中文 add FULLTEXT KEY (information); show create table user_index 6.3.2.2 创建表时指定索引CREATE TABLE user_index2 ( id INT auto_increment PRIMARY KEY, first_name VARCHAR (16), last_name VARCHAR (16), id_card VARCHAR (18), information text, KEY name (first_name, last_name), FULLTEXT KEY (information), UNIQUE KEY (id_card) ); 6.3.3 删除索引根据索引名删除普通索引、唯一索引、全文索引：alter table 表名 drop KEY 索引名 alter table user_index drop KEY name; alter table user_index drop KEY id_card; alter table user_index drop KEY information; 删除主键索引：alter table 表名 drop primary key（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）： 需要取消自增长再行删除： alter table user_index -- 重新定义字段 MODIFY id int, drop PRIMARY KEY 但通常不会删除主键，因为设计主键一定与业务逻辑无关。 6.4 执行计划explainCREATE TABLE innodb1 ( id INT auto_increment PRIMARY KEY, first_name VARCHAR (16), last_name VARCHAR (16), id_card VARCHAR (18), information text, KEY name (first_name, last_name), FULLTEXT KEY (information), UNIQUE KEY (id_card) ); insert into innodb1 (first_name,last_name,id_card,information) values ('张','三','1001','华山派'); 我们可以通过explain selelct来分析SQL语句执行前的执行计划： 由上图可看出此SQL语句是按照主键索引来检索的。 执行计划是：当执行SQL语句时，首先会分析、优化，形成执行计划，在按照执行计划执行。 6.5 索引使用场景（重点）6.5.1 where 上图中，根据id查询记录，因为id字段仅建立了主键索引，因此此SQL执行可选的索引只有主键索引，如果有多个，最终会选一个较优的作为检索的依据。 -- 增加一个没有建立索引的字段 alter table innodb1 add sex char(1); -- 按sex检索时可选的索引为null EXPLAIN SELECT * from innodb1 where sex='男'; 可以尝试在一个字段未建立索引时，根据该字段查询的效率，然后对该字段建立索引（alter table 表名 add index(字段名)），同样的SQL执行的效率，你会发现查询效率会有明显的提升（数据量越大越明显）。 6.5.2 order by当我们使用order by将查询结果按照某个字段排序时，如果该字段没有建立索引，那么执行计划会将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），这个操作是很影响性能的，因为需要将查询涉及到的所有数据从磁盘中读到内存（如果单条数据过大或者数据量过多都会降低效率），更无论读到内存之后的排序了。 但是如果我们对该字段建立索引alter table 表名 add index(字段名)，那么由于索引本身是有序的，因此直接按照索引的顺序和映射关系逐条取出数据即可。而且如果分页的，那么只用取出索引表某个范围内的索引对应的数据，而不用像上述那取出所有数据进行排序再返回某个范围内的数据。（从磁盘取数据是最影响性能的） 6.5.3 join 对join语句匹配关系（on）涉及的字段建立索引能够提高效率 6.5.4 索引覆盖如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后==只写必要的查询字段==，以增加索引覆盖的几率。 这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。 6.6 语法细节（要点） 在满足索引使用的场景下（where/order by/join on或索引覆盖），索引也不一定被使用 6.6.1 字段要独立出现比如下面两条SQL语句在语义上相同，但是第一条会使用主键索引而第二条不会。 select * from user where id = 20-1; select * from user where id+1 = 20; 6.6.2 like查询，不能以通配符开头比如搜索标题包含mysql的文章： select * from article where title like '%mysql%'; 这种SQL的执行计划用不了索引（like语句匹配表达式以通配符开头），因此只能做全表扫描，效率极低，在实际工程中几乎不被采用。而一般会使用第三方提供的支持中文的全文索引来做。 但是 关键字查询 热搜提醒功能还是可以做的，比如键入mysql之后提醒mysql 教程、mysql 下载、mysql 安装步骤等。用到的语句是： select * from article where title like 'mysql%'; 这种like是可以利用索引的（当然前提是title字段建立过索引）。 6.6.3 复合索引只对第一个字段有效建立复合索引： alter table person add index(first_name,last_name); 其原理就是将索引先按照从first_name中提取的关键字排序，如果无法确定先后再按照从last_name提取的关键字排序，也就是说该索引表只是按照记录的first_name字段值有序。 因此select * from person where first_name = ?是可以利用索引的，而select * from person where last_name = ?无法利用索引。 那么该复合索引的应用场景是什么？组合查询 比如对于select * person from first_name = ? and last_name = ?，复合索引就比对first_name和last_name单独建立索引要高效些。很好理解，复合索引首先二分查找与first_name = ?匹配的记录，再在这些记录中二分查找与last_name匹配的记录，只涉及到一张索引表。而分别单独建立索引则是在first_name索引表中二分找出与first_name = ?匹配的记录，再在last_name索引表中二分找出与last_name = ?的记录，两者取交集。 6.6.4 or，两边条件都有索引可用 一但有一边无索引可用就会导致整个SQL语句的全表扫描 6.6.5 状态值，不容易使用到索引如性别、支付状态等状态值字段往往只有极少的几种取值可能，这种字段即使建立索引，也往往利用不上。这是因为，一个状态值可能匹配大量的记录，这种情况MySQL会认为利用索引比全表扫描的效率低，从而弃用索引。索引是随机访问磁盘，而全表扫描是顺序访问磁盘，这就好比有一栋20层楼的写字楼，楼底下的索引牌上写着某个公司对应不相邻的几层楼，你去公司找人，与其按照索引牌的提示去其中一层楼没找到再下来看索引牌再上楼，不如从1楼挨个往上找到顶楼。 6.7 如何创建索引 建立基础索引：在where、order by、join字段上建立索引。 优化，组合索引：基于业务逻辑 如果条件经常性出现在一起，那么可以考虑将多字段索引升级为复合索引 如果通过增加个别字段的索引，就可以出现索引覆盖，那么可以考虑为该字段建立索引 查询时，不常用到的索引，应该删除掉 6.8 前缀索引语法：index(field(10))，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。 前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。 实操的难度：在于前缀截取的长度。 我们可以利用select count(*)/count(distinct left(password,prefixLen));，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录） 6.9 索引的存储结构6.9.1 BTreebtree（多路平衡查找树）是一种广泛应用于==磁盘上实现索引功能==的一种数据结构，也是大多数数据库索引表的实现。 以add index(first_name,last_name)为例： BTree的一个node可以存储多个关键字，node的大小取决于计算机的文件系统，因此我们可以通过减小索引字段的长度使结点存储更多的关键字。如果node中的关键字已满，那么可以通过每个关键字之间的子节点指针来拓展索引表，但是不能破坏结构的有序性，比如按照first_name第一有序、last_name第二有序的规则，新添加的韩香就可以插到韩康之后。白起 &lt; 韩飞 &lt; 韩康 &lt; 李世民 &lt; 赵奢 &lt; 李寻欢 &lt; 王语嫣 &lt; 杨不悔。这与二叉搜索树的思想是一样的，只不过二叉搜索树的查找效率是log(2,N)（以2为底N的对数），而BTree的查找效率是log(x,N)（其中x为node的关键字数量，可以达到1000以上）。 从log(1000+,N)可以看出，少量的磁盘读取即可做到大量数据的遍历，这也是btree的设计目的。 6.9.2 B+Tree聚簇结构聚簇结构（也是在BTree上升级改造的）中，关键字和记录是存放在一起的。 在MySQL中，仅仅只有Innodb的==主键索引为聚簇结构==，其它的索引包括Innodb的非主键索引都是典型的BTree结构。 6.9.3 哈希索引在索引被载入内存时，使用哈希结构来存储。 7. 查询缓存 缓存select语句的查询结果 7.1 在配置文件中开启缓存windows上是my.ini，linux上是my.cnf 在[mysqld]段中配置query_cache_type： 0：不开启 1：开启，默认缓存所有，需要在SQL语句中增加select sql-no-cache提示来放弃缓存 2：开启，默认都不缓存，需要在SQL语句中增加select sql-cache来主动缓存（==常用==） 更改配置后需要重启以使配置生效，重启后可通过show variables like ‘query_cache_type’;来查看： show variables like 'query_cache_type'; query_cache_type DEMAND 7.2 在客户端设置缓存大小通过配置项query_cache_size来设置： show variables like 'query_cache_size'; query_cache_size 0 set global query_cache_size=64*1024*1024; show variables like 'query_cache_size'; query_cache_size 67108864 7.2 将查询结果缓存select sql_cache * from user; 7.3 重置缓存reset query cache; 7.4 缓存失效问题（大问题）当数据表改动时，基于该数据表的任何缓存都会被删除。（表层面的管理，不是记录层面的管理，因此失效率较高） 7.5 注意事项 应用程序，不应该关心query cache的使用情况。可以尝试使用，但不能由query cache决定业务逻辑，因为query cache由DBA来管理。 缓存是以SQL语句为key存储的，因此即使SQL语句功能相同，但如果多了一个空格或者大小写有差异都会导致匹配不到缓存。 8. 分区一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。 当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，==保证其单个文件的执行效率==。 最常见的分区方案是按id分区，如下将id的哈希值对10取模将数据均匀分散到10个.ibd存储文件中： create table article( id int auto_increment PRIMARY KEY, title varchar(64), content text )PARTITION by HASH(id) PARTITIONS 10 查看data目录： 服务端的表分区对于客户端是透明的，客户端还是照常插入数据，但服务端会按照分区算法分散存储数据。 8.1 MySQL提供的分区算法 分区依据的字段必须是主键的一部分，分区是为了快速定位数据，因此该字段的搜索频次较高应作为强检索字段，否则依照该字段分区毫无意义 8.1.1 hash(field)相同的输入得到相同的输出。输出的结果跟输入是否具有规律无关。==仅适用于整型字段== 8.1.2 key(field)和hash(field)的性质一样，只不过key是==处理字符串==的，比hash()多了一步从字符串中计算出一个整型在做取模操作。 create table article_key( id int auto_increment, title varchar(64), content text, PRIMARY KEY (id,title) -- 要求分区依据字段必须是主键的一部分 )PARTITION by KEY(title) PARTITIONS 10 8.1.3 range算法是一种条件分区算法，按照数据大小范围分区（将数据使用某种条件，分散到不同的分区中）。 如下，按文章的发布时间将数据按照2018年8月、9月、10月分区存放： create table article_range( id int auto_increment, title varchar(64), content text, created_time int, -- 发布时间到1970-1-1的毫秒数 PRIMARY KEY (id,created_time) -- 要求分区依据字段必须是主键的一部分 )charset=utf8 PARTITION BY RANGE(created_time)( PARTITION p201808 VALUES less than (1535731199), -- select UNIX_TIMESTAMP('2018-8-31 23:59:59') PARTITION p201809 VALUES less than (1538323199), -- 2018-9-30 23:59:59 PARTITION p201810 VALUES less than (1541001599) -- 2018-10-31 23:59:59 ); 注意：条件运算符只能使用==less than==，这以为着较小的范围要放在前面，比如上述p201808,p201819,p201810分区的定义顺序依照created_time数值范围从小到大，不能颠倒。 insert into article_range values(null,'MySQL优化','内容示例',1535731180); flush tables; -- 使操作立即刷新到磁盘文件 由于插入的文章的发布时间1535731180小于1535731199（2018-8-31 23:59:59），因此被存储到p201808分区中，这种算法的存储到哪个分区取决于数据状况。 8.1.4 list算法也是一种条件分区，按照列表值分区（in (值列表)）。 create table article_list( id int auto_increment, title varchar(64), content text, status TINYINT(1), -- 文章状态：0-草稿，1-完成但未发布，2-已发布 PRIMARY KEY (id,status) -- 要求分区依据字段必须是主键的一部分 )charset=utf8 PARTITION BY list(status)( PARTITION writing values in(0,1), -- 未发布的放在一个分区 PARTITION published values in (2) -- 已发布的放在一个分区 ); insert into article_list values(null,'mysql优化','内容示例',0); flush tables; 8.2 分区管理语法8.2.1 range/list8.2.1.1增加分区前文中我们尝试使用range对文章按照月份归档，随着时间的增加，我们需要增加一个月份： alter table article_range add partition( partition p201811 values less than (1543593599) -- select UNIX_TIMESTAMP('2018-11-30 23:59:59') -- more ); 8.2.1.2删除分区alter table article_range drop PARTITION p201808 注意：删除分区后，分区中原有的数据也会随之删除！ 8.2.2key/hash8.2.2.1 新增分区alter table article_key add partition partitions 4 8.2.2.2 销毁分区alter table article_key coalesce partition 6 key/hash分区的管理不会删除数据，但是每一次调整（新增或销毁分区）都会将所有的数据重写分配到新的分区上。==效率极低==，最好在设计阶段就考虑好分区策略。 8.3 分区的使用当数据表中的数据量很大时，分区带来的效率提升才会显现出来。 只有检索字段为分区字段时，分区带来的效率提升才会比较明显。因此，==分区字段的选择很重要==，并且==业务逻辑要尽可能地根据分区字段做相应调整==（尽量使用分区字段作为查询条件）。 9. 水平分割和垂直分割 水平分割：通过建立结构相同的几张表分别存储数据 垂直分割：将经常一起使用的字段放在一个单独的表中，分割后的表记录之间是一一对应关系。 9.1 分表原因 为数据库减压 分区算法局限 数据库支持不完善（5.1之后mysql才支持分区操作） 9.2 id重复的解决方案 借用第三方应用如memcache、redis的id自增器 单独建一张只包含id一个字段的表，每次自增该字段作为数据记录的id 10. 集群 横向扩展：从根本上（单机的硬件处理能力有限）提升数据库性能 。由此而生的相关技术：读写分离、负载均衡 10.1 安装和配置主从复制10.1.1 环境 Red Hat Enterprise Linux Server release 7.0 (Maipo)（虚拟机） mysql5.7（下载地址） 10.1.2 安装和配置 解压到对外提供的服务的目录（我自己专门创建了一个/export/server来存放） tar xzvf mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz -C /export/server cd /export/server mv mysql-5.7.23-linux-glibc2.12-x86_64 mysql 添加mysql目录的所属组和所属者： groupadd mysql useradd -r -g mysql mysql cd /export/server chown -R mysql:mysql mysql/ chmod -R 755 mysql/ 创建mysql数据存放目录（其中/export/data是我创建专门用来为各种服务存放数据的目录） mkdir /export/data/mysql 初始化mysql服务 cd /export/server/mysql ./bin/mysqld --basedir=/export/server/mysql --datadir=/export/data/mysql --user=mysql --pid-file=/export/data/mysql/mysql.pid --initialize 如果成功会显示mysql的root账户的初始密码，记下来以备后续登录。如果报错缺少依赖，则使用yum instally依次安装即可 配置my.cnf vim /etc/my.cnf [mysqld] basedir=/export/server/mysql datadir=/export/data/mysql socket=/tmp/mysql.sock user=mysql server-id=10 # 服务id，在集群时必须唯一，建议设置为IP的第四段 port=3306 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd [mysqld_safe] log-error=/export/data/mysql/error.log pid-file=/export/data/mysql/mysql.pid # # include all files from the config directory # !includedir /etc/my.cnf.d 将服务添加到开机自动启动 cp /export/server/mysql/support-files/mysql.server /etc/init.d/mysqld 启动服务 service mysqld start 配置环境变量，在/etc/profile中添加如下内容 # mysql env MYSQL_HOME=/export/server/mysql MYSQL_PATH=$MYSQL_HOME/bin PATH=$PATH:$MYSQL_PATH export PATH 使配置即可生效 source /etc/profile 使用root登录 mysql -uroot -p # 这里填写之前初始化服务时提供的密码 登录上去之后，更改root账户密码（我为了方便将密码改为root），否则操作数据库会报错 set password=password('root'); flush privileges; 设置服务可被所有远程客户端访问 use mysql; update user set host='%' where user='root'; flush privileges; 这样就可以在宿主机使用navicat远程连接虚拟机linux上的mysql了 10.1.3配置主从节点10.1.3.1 配置master 以linux（192.168.10.10）上的mysql为master，宿主机（192.168.10.1）上的mysql为slave配置主从复制。 修改master的my.cnf如下 [mysqld] basedir=/export/server/mysql datadir=/export/data/mysql socket=/tmp/mysql.sock user=mysql server-id=10 port=3306 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin # 开启二进制日志 expire-logs-days=7 # 设置日志过期时间，避免占满磁盘 binlog-ignore-db=mysql # 不使用主从复制的数据库 binlog-ignore-db=information_schema binlog-ignore-db=performation_schema binlog-ignore-db=sys binlog-do-db=test #使用主从复制的数据库 [mysqld_safe] log-error=/export/data/mysql/error.log pid-file=/export/data/mysql/mysql.pid # # include all files from the config directory # !includedir /etc/my.cnf.d 重启master service mysqld restart 登录master查看配置是否生效（ON即为开启，默认为OFF）： mysql> show variables like 'log_bin'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_bin | ON | +---------------+-------+ 在master的数据库中建立备份账号：backup为用户名，%表示任何远程地址，用户back可以使用密码1234通过任何远程客户端连接master grant replication slave on *.* to 'backup'@'%' identified by '1234' 查看user表可以看到我们刚创建的用户： mysql> use mysql mysql> select user,authentication_string,host from user; +---------------+-------------------------------------------+-----------+ | user | authentication_string | host | +---------------+-------------------------------------------+-----------+ | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | % | | mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost | | mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost | | backup | *A4B6157319038724E3560894F7F932C8886EBFCF | % | +---------------+-------------------------------------------+-----------+ 新建test数据库，创建一个article表以备后续测试 CREATE TABLE `article` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` varchar(64) DEFAULT NULL, `content` text, PRIMARY KEY (`id`) ) CHARSET=utf8; 重启服务并刷新数据库状态到存储文件中（with read lock表示在此过程中，客户端只能读数据，以便获得一个一致性的快照） [root@zhenganwen ~]# service mysqld restart Shutting down MySQL.... SUCCESS! Starting MySQL. SUCCESS! [root@zhenganwen mysql]# mysql -uroot -proot mysql> flush tables with read lock; Query OK, 0 rows affected (0.00 sec) 查看master上当前的二进制日志和偏移量（记一下其中的File和Position） mysql> show master status \\G *************************** 1. row *************************** File: mysql-bin.000002 Position: 154 Binlog_Do_DB: test Binlog_Ignore_DB: mysql,information_schema,performation_schema,sys Executed_Gtid_Set: 1 row in set (0.00 sec) File表示实现复制功能的日志，即上图中的Binary log；Position则表示Binary log日志文件的偏移量之后的都会同步到slave中，那么在偏移量之前的则需要我们手动导入。 主服务器上面的任何修改都会保存在二进制日志Binary log里面，从服务器上面启动一个I/O thread（实际上就是一个主服务器的客户端进程），连接到主服务器上面请求读取二进制日志，然后把读取到的二进制日志写到本地的一个Realy log里面。从服务器上面开启一个SQL thread定时检查Realy log，如果发现有更改立即把更改的内容在本机上面执行一遍。 如果一主多从的话，这时主库既要负责写又要负责为几个从库提供二进制日志。此时可以稍做调整，将二进制日志只给某一从，这一从再开启二进制日志并将自己的二进制日志再发给其它从。或者是干脆这个从不记录只负责将二进制日志转发给其它从，这样架构起来性能可能要好得多，而且数据之间的延时应该也稍微要好一些 手动导入，从master中导出数据 mysqldump -uroot -proot -hlocalhost test > /export/data/test.sql 将test.sql中的内容在slave上执行一遍。 10.1.3.2 配置slave 修改slave的my.ini文件中的[mysqld]部分 log-bin=mysql server-id=1 #192.168.10.1 保存修改后重启slave，WIN+R-&gt;services.msc-&gt;MySQL5.7-&gt;重新启动 登录slave检查log_bin是否以被开启： show VARIABLES like 'log_bin'; 配置与master的同步复制： stop slave; change master to master_host='192.168.10.10', -- master的IP master_user='backup', -- 之前在master上创建的用户 master_password='1234', master_log_file='mysql-bin.000002', -- master上 show master status \\G 提供的信息 master_log_pos=154; 启用slave节点并查看状态 mysql> start slave; mysql> show slave status \\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.10.10 Master_User: backup Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 154 Relay_Log_File: DESKTOP-KUBSPE0-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 537 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 10 Master_UUID: f68774b7-0b28-11e9-a925-000c290abe05 Master_Info_File: C:\\ProgramData\\MySQL\\MySQL Server 5.7\\Data\\master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec) 注意查看第4、14、15三行，若与我一致，表示slave配置成功 10.1.4 测试 关闭master的读取锁定 mysql> unlock tables; Query OK, 0 rows affected (0.00 sec) 向master中插入一条数据 mysql> use test mysql> insert into article (title,content) values ('mysql master and slave','record the cluster building succeed!:)'); Query OK, 1 row affected (0.00 sec) 查看slave是否自动同步了数据 mysql> insert into article (title,content) values ('mysql master and slave','record the cluster building succeed!:)'); Query OK, 1 row affected (0.00 sec) 至此，主从复制的配置成功！：) 使用mysqlreplicate命令快速搭建 Mysql 主从复制 10.2 读写分离读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。 10.2.1 方案一、定义两种连接就像我们在学JDBC时定义的DataBase一样，我们可以抽取出ReadDataBase,WriteDataBase implements DataBase，但是这种方式无法利用优秀的线程池技术如DruidDataSource帮我们管理连接，也无法利用Spring AOP让连接对DAO层透明。 10.2.2 方案二、使用Spring AOP如果能够使用Spring AOP解决数据源切换的问题，那么就可以和Mybatis、Druid整合到一起了。 我们在整合Spring1和Mybatis时，我们只需写DAO接口和对应的SQL语句，那么DAO实例是由谁创建的呢？实际上就是Spring帮我们创建的，它通过我们注入的数据源，帮我们完成从中获取数据库连接、使用连接执行 SQL 语句的过程以及最后归还连接给数据源的过程。 如果我们能在调用DAO接口时根据接口方法命名规范（增addXXX/createXXX、删deleteXX/removeXXX、改updateXXXX、查selectXX/findXXX/getXX/queryXXX）动态地选择数据源（读数据源对应连接master而写数据源对应连接slave），那么就可以做到读写分离了。 10.2.2.1 项目结构 10.2.2.2引入依赖其中，为了方便访问数据库引入了mybatis和druid，实现数据源动态切换主要依赖spring-aop和spring-aspects &lt;dependencies> &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>1.3.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis&lt;/artifactId> &lt;version>3.4.6&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-core&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-aop&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-jdbc&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>druid&lt;/artifactId> &lt;version>1.1.6&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>6.0.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-context&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-aspects&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.16.22&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-test&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactId>junit&lt;/artifactId> &lt;version>4.12&lt;/version> &lt;/dependency> &lt;/dependencies> 10.2.2.3 数据类package top.zhenganwen.mysqloptimize.entity; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class Article { private int id; private String title; private String content; } 10.2.2.4 spring配置文件其中RoutingDataSourceImpl是实现动态切换功能的核心类，稍后介绍。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"> &lt;context:property-placeholder location=\"db.properties\">&lt;/context:property-placeholder> &lt;context:component-scan base-package=\"top.zhenganwen.mysqloptimize\"/> &lt;bean id=\"slaveDataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"> &lt;property name=\"driverClassName\" value=\"${db.driverClass}\"/> &lt;property name=\"url\" value=\"${master.db.url}\">&lt;/property> &lt;property name=\"username\" value=\"${master.db.username}\">&lt;/property> &lt;property name=\"password\" value=\"${master.db.password}\">&lt;/property> &lt;/bean> &lt;bean id=\"masterDataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"> &lt;property name=\"driverClassName\" value=\"${db.driverClass}\"/> &lt;property name=\"url\" value=\"${slave.db.url}\">&lt;/property> &lt;property name=\"username\" value=\"${slave.db.username}\">&lt;/property> &lt;property name=\"password\" value=\"${slave.db.password}\">&lt;/property> &lt;/bean> &lt;bean id=\"dataSourceRouting\" class=\"top.zhenganwen.mysqloptimize.dataSource.RoutingDataSourceImpl\"> &lt;property name=\"defaultTargetDataSource\" ref=\"masterDataSource\">&lt;/property> &lt;property name=\"targetDataSources\"> &lt;map key-type=\"java.lang.String\" value-type=\"javax.sql.DataSource\"> &lt;entry key=\"read\" value-ref=\"slaveDataSource\"/> &lt;entry key=\"write\" value-ref=\"masterDataSource\"/> &lt;/map> &lt;/property> &lt;property name=\"methodType\"> &lt;map key-type=\"java.lang.String\" value-type=\"java.lang.String\"> &lt;entry key=\"read\" value=\"query,find,select,get,load,\">&lt;/entry> &lt;entry key=\"write\" value=\"update,add,create,delete,remove,modify\"/> &lt;/map> &lt;/property> &lt;/bean> &lt;!-- Mybatis文件 --> &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"> &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\" /> &lt;property name=\"dataSource\" ref=\"dataSourceRouting\" /> &lt;property name=\"mapperLocations\" value=\"mapper/*.xml\"/> &lt;/bean> &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"> &lt;property name=\"basePackage\" value=\"top.zhenganwen.mysqloptimize.mapper\" /> &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\" /> &lt;/bean> &lt;/beans> dp.properties dp.properties master.db.url=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC master.db.username=root master.db.password=root slave.db.url=jdbc:mysql://192.168.10.10:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC slave.db.username=root slave.db.password=root db.driverClass=com.mysql.jdbc.Driver mybatis-config.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"> &lt;configuration> &lt;typeAliases> &lt;typeAlias type=\"top.zhenganwen.mysqloptimize.entity.Article\" alias=\"Article\"/> &lt;/typeAliases> &lt;/configuration> 10.2.2.5 mapper接口和配置文件ArticleMapper.java package top.zhenganwen.mysqloptimize.mapper; import org.springframework.stereotype.Repository; import top.zhenganwen.mysqloptimize.entity.Article; import java.util.List; @Repository public interface ArticleMapper { List&lt;Article> findAll(); void add(Article article); void delete(int id); } ArticleMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" > &lt;mapper namespace=\"top.zhenganwen.mysqloptimize.mapper.ArticleMapper\"> &lt;select id=\"findAll\" resultType=\"Article\"> select * from article &lt;/select> &lt;insert id=\"add\" parameterType=\"Article\"> insert into article (title,content) values (#{title},#{content}) &lt;/insert> &lt;delete id=\"delete\" parameterType=\"int\"> delete from article where id=#{id} &lt;/delete> &lt;/mapper> 10.2.2.6 核心类 RoutingDataSourceImpl package top.zhenganwen.mysqloptimize.dataSource; import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource; import java.util.*; /** * RoutingDataSourceImpl class * 数据源路由 * * @author zhenganwen, blog:zhenganwen.top * @date 2018/12/29 */ public class RoutingDataSourceImpl extends AbstractRoutingDataSource { /** * key为read或write * value为DAO方法的前缀 * 什么前缀开头的方法使用读数据员，什么开头的方法使用写数据源 */ public static final Map&lt;String, List&lt;String>> METHOD_TYPE_MAP = new HashMap&lt;String, List&lt;String>>(); /** * 由我们指定数据源的id，由Spring切换数据源 * * @return */ @Override protected Object determineCurrentLookupKey() { System.out.println(\"数据源为：\"+DataSourceHandler.getDataSource()); return DataSourceHandler.getDataSource(); } public void setMethodType(Map&lt;String, String> map) { for (String type : map.keySet()) { String methodPrefixList = map.get(type); if (methodPrefixList != null) { METHOD_TYPE_MAP.put(type, Arrays.asList(methodPrefixList.split(\",\"))); } } } } 它的主要功能是，本来我们只配置一个数据源，因此Spring动态代理DAO接口时直接使用该数据源，现在我们有了读、写两个数据源，我们需要加入一些自己的逻辑来告诉调用哪个接口使用哪个数据源（读数据的接口使用slave，写数据的接口使用master。这个告诉Spring该使用哪个数据源的类就是AbstractRoutingDataSource，必须重写的方法determineCurrentLookupKey返回数据源的标识，结合spring配置文件（下段代码的5，6两行） &lt;bean id=\"dataSourceRouting\" class=\"top.zhenganwen.mysqloptimize.dataSource.RoutingDataSourceImpl\"> &lt;property name=\"defaultTargetDataSource\" ref=\"masterDataSource\">&lt;/property> &lt;property name=\"targetDataSources\"> &lt;map key-type=\"java.lang.String\" value-type=\"javax.sql.DataSource\"> &lt;entry key=\"read\" value-ref=\"slaveDataSource\"/> &lt;entry key=\"write\" value-ref=\"masterDataSource\"/> &lt;/map> &lt;/property> &lt;property name=\"methodType\"> &lt;map key-type=\"java.lang.String\" value-type=\"java.lang.String\"> &lt;entry key=\"read\" value=\"query,find,select,get,load,\">&lt;/entry> &lt;entry key=\"write\" value=\"update,add,create,delete,remove,modify\"/> &lt;/map> &lt;/property> &lt;/bean> 如果determineCurrentLookupKey返回read那么使用slaveDataSource，如果返回write就使用masterDataSource。 DataSourceHandler package top.zhenganwen.mysqloptimize.dataSource; /** * DataSourceHandler class * &lt;p> * 将数据源与线程绑定，需要时根据线程获取 * * @author zhenganwen, blog:zhenganwen.top * @date 2018/12/29 */ public class DataSourceHandler { /** * 绑定的是read或write，表示使用读或写数据源 */ private static final ThreadLocal&lt;String> holder = new ThreadLocal&lt;String>(); public static void setDataSource(String dataSource) { System.out.println(Thread.currentThread().getName()+\"设置了数据源类型\"); holder.set(dataSource); } public static String getDataSource() { System.out.println(Thread.currentThread().getName()+\"获取了数据源类型\"); return holder.get(); } } DataSourceAspect package top.zhenganwen.mysqloptimize.dataSource; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.context.annotation.EnableAspectJAutoProxy; import org.springframework.stereotype.Component; import java.util.List; import java.util.Set; import static top.zhenganwen.mysqloptimize.dataSource.RoutingDataSourceImpl.METHOD_TYPE_MAP; /** * DataSourceAspect class * * 配置切面，根据方法前缀设置读、写数据源 * 项目启动时会加载该bean，并按照配置的切面（哪些切入点、如何增强）确定动态代理逻辑 * @author zhenganwen,blog:zhenganwen.top * @date 2018/12/29 */ @Component //声明这是一个切面，这样Spring才会做相应的配置，否则只会当做简单的bean注入 @Aspect @EnableAspectJAutoProxy public class DataSourceAspect { /** * 配置切入点：DAO包下的所有类的所有方法 */ @Pointcut(\"execution(* top.zhenganwen.mysqloptimize.mapper.*.*(..))\") public void aspect() { } /** * 配置前置增强，对象是aspect()方法上配置的切入点 */ @Before(\"aspect()\") public void before(JoinPoint point) { String className = point.getTarget().getClass().getName(); String invokedMethod = point.getSignature().getName(); System.out.println(\"对 \"+className+\"$\"+invokedMethod+\" 做了前置增强，确定了要使用的数据源类型\"); Set&lt;String> dataSourceType = METHOD_TYPE_MAP.keySet(); for (String type : dataSourceType) { List&lt;String> prefixList = METHOD_TYPE_MAP.get(type); for (String prefix : prefixList) { if (invokedMethod.startsWith(prefix)) { DataSourceHandler.setDataSource(type); System.out.println(\"数据源为：\"+type); return; } } } } } 10.2.2.7 测试读写分离 如何测试读是从slave中读的呢？可以将写后复制到slave中的数据更改，再读该数据就知道是从slave中读了。注意，一但对slave做了写操作就要重新手动将slave与master同步一下，否则主从复制就会失效。 package top.zhenganwen.mysqloptimize.dataSource; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import top.zhenganwen.mysqloptimize.entity.Article; import top.zhenganwen.mysqloptimize.mapper.ArticleMapper; @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = \"classpath:spring-mybatis.xml\") public class RoutingDataSourceTest { @Autowired ArticleMapper articleMapper; @Test public void testRead() { System.out.println(articleMapper.findAll()); } @Test public void testAdd() { Article article = new Article(0, \"我是新插入的文章\", \"测试是否能够写到master并且复制到slave中\"); articleMapper.add(article); } @Test public void testDelete() { articleMapper.delete(2); } } 10.3 负载均衡10.3.1 负载均衡算法 轮询 加权轮询：按照处理能力来加权 负载分配：依据当前的空闲状态（但是测试每个节点的内存使用率、CPU利用率等，再做比较选出最闲的那个，效率太低） 10.4 高可用在服务器架构时，为了保证服务器7x24不宕机在线状态，需要为每台单点服务器（由一台服务器提供服务的服务器，如写服务器、数据库中间件）提供冗余机。 对于写服务器来说，需要提供一台同样的写-冗余服务器，当写服务器健康时（写-冗余通过心跳检测），写-冗余作为一个从机的角色复制写服务器的内容与其做一个同步；当写服务器宕机时，写-冗余服务器便顶上来作为写服务器继续提供服务。对外界来说这个处理过程是透明的，即外界仅通过一个IP访问服务。 11. 典型SQL11.1 线上DDLDDL(Database Definition Language)是指数据库表结构的定义（create table）和维护（alter table）的语言。在线上执行DDL，在低于MySQL5.6版本时会导致全表被独占锁定，此时表处于维护、不可操作状态，这会导致该期间对该表的所有访问无法响应。但是在MySQL5.6之后，支持Online DDL，大大缩短了锁定时间。 优化技巧是采用的维护表结构的DDL（比如增加一列，或者增加一个索引），是==copy==策略。思路：创建一个满足新结构的新表，将旧表数据==逐条==导入（复制）到新表中，以保证==一次性锁定的内容少==（锁定的是正在导入的数据），同时旧表上可以执行其他任务。导入的过程中，将对旧表的所有操作以日志的形式记录下来，导入完毕后，将更新日志在新表上再执行一遍（确保一致性）。最后，新表替换旧表（在应用程序中完成，或者是数据库的rename，视图完成）。 但随着MySQL的升级，这个问题几乎淡化了。 11.2 数据库导入语句在恢复数据时，可能会导入大量的数据。此时为了快速导入，需要掌握一些技巧： 导入时先禁用索引和约束： alter table table-name disable keys 待数据导入完成之后，再开启索引和约束，一次性创建索引 alter table table-name enable keys 数据库如果使用的引擎是Innodb，那么它默认会给每条写指令加上事务（这也会消耗一定的时间），因此建议先手动开启事务，再执行一定量的批量导入，最后手动提交事务。 如果批量导入的SQL指令格式相同只是数据不同，那么你应该先prepare==预编译==一下，这样也能节省很多重复编译的时间。 11.3 limit offset,rows尽量保证不要出现大的offset，比如limit 10000,10相当于对已查询出来的行数弃掉前10000行后再取10行，完全可以加一些条件过滤一下（完成筛选），而不应该使用limit跳过已查询到的数据。这是一个==offset做无用功==的问题。对应实际工程中，要避免出现大页码的情况，尽量引导用户做条件过滤。 11.4 select * 要少用即尽量选择自己需要的字段select，但这个影响不是很大，因为网络传输多了几十上百字节也没多少延时，并且现在流行的ORM框架都是用的select *，只是我们在设计表的时候注意将大数据量的字段分离，比如商品详情可以单独抽离出一张商品详情表，这样在查看商品简略页面时的加载速度就不会有影响了。 11.5 order by rand()不要用它的逻辑就是随机排序（为每条数据生成一个随机数，然后根据随机数大小进行排序）。如select * from student order by rand() limit 5的执行效率就很低，因为它为表中的每条数据都生成随机数并进行排序，而我们只要前5条。 解决思路：在应用程序中，将随机的主键生成好，去数据库中利用主键检索。 11.6 单表和多表查询多表查询：join、子查询都是涉及到多表的查询。如果你使用explain分析执行计划你会发现多表查询也是一个表一个表的处理，最后合并结果。因此可以说单表查询将计算压力放在了应用程序上，而多表查询将计算压力放在了数据库上。 现在有ORM框架帮我们解决了单表查询带来的对象映射问题（查询单表时，如果发现有外键自动再去查询关联表，是一个表一个表查的）。 11.7 count(*)在MyISAM存储引擎中，会自动记录表的行数，因此使用count(*)能够快速返回。而Innodb内部没有这样一个计数器，需要我们手动统计记录数量，解决思路就是单独使用一张表： id table count 1 student 100 11.8 limit 1如果可以确定仅仅检索一条，建议加上limit 1，其实ORM框架帮我们做到了这一点（查询单条的操作都会自动加上limit 1）。 12. 慢查询日志 用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。 12.1 开启慢查询日志配置项：slow_query_log 可以使用show variables like ‘slov_query_log’查看是否开启，如果状态值为OFF，可以使用set GLOBAL slow_query_log = on来开启，它会在datadir下产生一个xxx-slow.log的文件。 12.2 设置临界时间配置项：long_query_time 查看：show VARIABLES like 'long_query_time'，单位秒 设置：set long_query_time=0.5 实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉 12.3 查看日志一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中 13. profile信息配置项：profiling 13.1 开启profileset profiling=on 开启后，所有的SQL执行的详细信息都会被自动记录下来 mysql> show variables like 'profiling'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | profiling | OFF | +---------------+-------+ 1 row in set, 1 warning (0.00 sec) mysql> set profiling=on; Query OK, 0 rows affected, 1 warning (0.00 sec) 13.2 查看profile信息show profiles mysql> show variables like 'profiling'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | profiling | ON | +---------------+-------+ 1 row in set, 1 warning (0.00 sec) mysql> insert into article values (null,'test profile',':)'); Query OK, 1 row affected (0.15 sec) mysql> show profiles; +----------+------------+-------------------------------------------------------+ | Query_ID | Duration | Query | +----------+------------+-------------------------------------------------------+ | 1 | 0.00086150 | show variables like 'profiling' | | 2 | 0.15027550 | insert into article values (null,'test profile',':)') | +----------+------------+-------------------------------------------------------+ 13.3 通过Query_ID查看某条SQL所有详细步骤的时间show profile for query Query_ID 上面show profiles的结果中，每个SQL有一个Query_ID，可以通过它查看执行该SQL经过了哪些步骤，各消耗了多场时间 14. 典型的服务器配置 以下的配置全都取决于实际的运行环境 max_connections，最大客户端连接数 mysql> show variables like 'max_connections'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 151 | +-----------------+-------+ table_open_cache，表文件句柄缓存（表数据是存储在磁盘上的，缓存磁盘文件的句柄方便打开文件读取数据） mysql> show variables like 'table_open_cache'; +------------------+-------+ | Variable_name | Value | +------------------+-------+ | table_open_cache | 2000 | +------------------+-------+ key_buffer_size，索引缓存大小（将从磁盘上读取的索引缓存到内存，可以设置大一些，有利于快速检索） mysql> show variables like 'key_buffer_size'; +-----------------+---------+ | Variable_name | Value | +-----------------+---------+ | key_buffer_size | 8388608 | +-----------------+---------+ innodb_buffer_pool_size，Innodb存储引擎缓存池大小（对于Innodb来说最重要的一个配置，如果所有的表用的都是Innodb，那么甚至建议将该值设置到物理内存的80%，Innodb的很多性能提升如索引都是依靠这个） mysql> show variables like 'innodb_buffer_pool_size'; +-------------------------+---------+ | Variable_name | Value | +-------------------------+---------+ | innodb_buffer_pool_size | 8388608 | +-------------------------+---------+ innodb_file_per_table（innodb中，表数据存放在.ibd文件中，如果将该配置项设置为ON，那么一个表对应一个ibd文件，否则所有innodb共享表空间） 15. 压测工具mysqlslap安装MySQL时附带了一个压力测试工具mysqlslap（位于bin目录下） 15.1 自动生成sql测试C:\\Users\\zaw>mysqlslap --auto-generate-sql -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 1.219 seconds Minimum number of seconds to run all queries: 1.219 seconds Maximum number of seconds to run all queries: 1.219 seconds Number of clients running queries: 1 Average number of queries per client: 0 15.2 并发测试C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=100 -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 3.578 seconds Minimum number of seconds to run all queries: 3.578 seconds Maximum number of seconds to run all queries: 3.578 seconds Number of clients running queries: 100 Average number of queries per client: 0 C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 5.718 seconds Minimum number of seconds to run all queries: 5.718 seconds Maximum number of seconds to run all queries: 5.718 seconds Number of clients running queries: 150 Average number of queries per client: 0 15.3 多轮测试C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 --iterations=10 -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 5.398 seconds Minimum number of seconds to run all queries: 4.313 seconds Maximum number of seconds to run all queries: 6.265 seconds Number of clients running queries: 150 Average number of queries per client: 0 15.4 存储引擎测试C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 --iterations=3 --engine=innodb -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Running for engine innodb Average number of seconds to run all queries: 5.911 seconds Minimum number of seconds to run all queries: 5.485 seconds Maximum number of seconds to run all queries: 6.703 seconds Number of clients running queries: 150 Average number of queries per client: 0 C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 --iterations=3 --engine=myisam -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Running for engine myisam Average number of seconds to run all queries: 53.104 seconds Minimum number of seconds to run all queries: 46.843 seconds Maximum number of seconds to run all queries: 60.781 seconds Number of clients running queries: 150 Average number of queries per client: 0 转载自：掘金-程序员乔戈里 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://fyvan.github.io/tags/MySql/"}],"author":"fyang"},{"title":"SpringMVC运行流程","slug":"SpringMVC-2020-05-25-run","date":"2020-05-25T00:51:16.453Z","updated":"2020-06-18T08:23:05.325Z","comments":true,"path":"undefined/2bdb.html","link":"","permalink":"http://fyvan.github.io/undefined/2bdb.html","excerpt":"","text":"1. SpringMVC执行流程图解 2. 组件说明 DispatcherServlet：前端控制器。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性,系统扩展性提高。由框架实现 HandlerMapping：处理器映射器。HandlerMapping负责根据用户请求的url找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，根据一定的规则去查找,例如：xml配置方式，实现接口方式，注解方式等。由框架实现 Handler：处理器。Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。 HandlAdapter：处理器适配器。通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。由框架实现。 ModelAndView是springmvc的封装对象，将model和view封装在一起。 ViewResolver：视图解析器。ViewResolver负责将处理结果生成View视图，ViewResolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 View:是springmvc的封装对象，是一个接口, springmvc框架提供了很多的View视图类型，包括：jspview，pdfview,jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 3. Springmvc执行流程 用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求转发给处理器映射器HandlerMapping。 处理器映射器根据url请求找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。 DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作 执行处理器Handler(Controller，也叫页面控制器)。 Handler执行完成返回ModelAndView HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。 DispatcherServlet响应用户。 4. 执行流程代码4.1 用户发送url请求至前端控制器DispatcherServlet/** * Exposes the DispatcherServlet-specific request attributes and delegates to {@link #doDispatch} * for the actual dispatching. */ @Override protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { if (logger.isDebugEnabled()) { String requestUri = urlPathHelper.getRequestUri(request); logger.debug(\"DispatcherServlet with name '\" + getServletName() + \"' processing \" + request.getMethod() + \" request for [\" + requestUri + \"]\"); } //保护现场 // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object> attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) { logger.debug(\"Taking snapshot of request attributes before include\"); attributesSnapshot = new HashMap&lt;String, Object>(); Enumeration&lt;?> attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) { String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(\"org.springframework.web.servlet\")) { attributesSnapshot.put(attrName, request.getAttribute(attrName)); } } } //将框架相关信息存储至request，方便后面的处理器和视图用到 // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) { request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); } request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); //请求分发 try { doDispatch(request, response); } finally { // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) { restoreAttributesAfterInclude(request, attributesSnapshot); } } } 4.2 开始处理请求 通过url查找HandlerMap中最相近的key(url)，然后由key获取HandlerMapping对象 通过处理器映射器获取处理器 通过查询处理器适配器获得 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; int interceptorIndex = -1; try { ModelAndView mv; boolean errorView = false; try { processedRequest = checkMultipart(request); // Determine handler for the current request //步骤4.3.1~4.3.4用于获取包含处理器Handler和拦截器AdapterIntercepters的处理器执行链HandlerExecutionChain mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) { noHandlerFound(processedRequest, response); return; } // Determine handler adapter for the current request. //步骤4.4.1~4.4.2,根据HandlerExecutionChain中的处理器Handler获取处理器适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) { String requestUri = urlPathHelper.getRequestUri(request); logger.debug(\"Last-Modified value for [\" + requestUri + \"] is: \" + lastModified); } if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) { return; } } // Apply preHandle methods of registered interceptors. HandlerInterceptor[] interceptors = mappedHandler.getInterceptors(); if (interceptors != null) { for (int i = 0; i &lt; interceptors.length; i++) { HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(processedRequest, response, mappedHandler.getHandler())) { triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); return; } interceptorIndex = i; } } // Actually invoke the handler. //4.5.1~4.5.3通过处理器适配器HandlerApapter来调用处理器完成对请求的处理 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // Do we need view name translation? if (mv != null &amp;&amp; !mv.hasView()) { mv.setViewName(getDefaultViewName(request)); } // Apply postHandle methods of registered interceptors. if (interceptors != null) { for (int i = interceptors.length - 1; i >= 0; i--) { HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(processedRequest, response, mappedHandler.getHandler(), mv); } } } catch (ModelAndViewDefiningException ex) { logger.debug(\"ModelAndViewDefiningException encountered\", ex); mv = ex.getModelAndView(); } catch (Exception ex) { Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(processedRequest, response, handler, ex); errorView = (mv != null); } // Did the handler return a view to render? if (mv != null &amp;&amp; !mv.wasCleared()) { render(mv, processedRequest, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request); } } else { if (logger.isDebugEnabled()) { logger.debug(\"Null ModelAndView returned to DispatcherServlet with name '\" + getServletName() + \"': assuming HandlerAdapter completed request handling\"); } } // Trigger after-completion for successful outcome. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); } catch (Exception ex) { // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; } catch (Error err) { ServletException ex = new NestedServletException(\"Handler processing failed\", err); // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; } finally { // Clean up any resources used by a multipart request. if (processedRequest != request) { cleanupMultipart(processedRequest); } } } 4.3.1 getHandler(HttpServletRequest request)，经由HandlerMapping对象获取HandlerExecutionChain(处理器和拦截器)/** * Return the HandlerExecutionChain for this request. * &lt;p>Tries all handler mappings in order. * @param request current HTTP request * @return the HandlerExecutionChain, or &lt;code>null&lt;/code> if no handler could be found */ protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { for (HandlerMapping hm : this.handlerMappings) { if (logger.isTraceEnabled()) { logger.trace( \"Testing handler map [\" + hm + \"] in DispatcherServlet with name '\" + getServletName() + \"'\"); } HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) { return handler; } } return null; } 4.3.2.1 getHandler(HttpServletRequest request)，经由request获取处理器，获取处理器Handler后，再获取拦截器，最后组成HandlerExecutionChain/** * Look up a handler for the given request, falling back to the default * handler if no specific one is found. * @param request current HTTP request * @return the corresponding handler instance, or the default handler * @see #getHandlerInternal */ public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { Object handler = getHandlerInternal(request); if (handler == null) { handler = getDefaultHandler(); } if (handler == null) { return null; } // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } return getHandlerExecutionChain(handler, request); } 4.3.2.2 根据查找到的处理器Handler和request获取包含Handler和AdaptedInterceptors的HandlerExecutionChainprotected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) { HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain) ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler); chain.addInterceptors(getAdaptedInterceptors()); String lookupPath = urlPathHelper.getLookupPathForRequest(request); for (MappedInterceptor mappedInterceptor : mappedInterceptors) { if (mappedInterceptor.matches(lookupPath, pathMatcher)) { chain.addInterceptor(mappedInterceptor.getInterceptor()); } } return chain; } /** * Return the adapted interceptors as HandlerInterceptor array. * @return the array of HandlerInterceptors, or &lt;code>null&lt;/code> if none */ protected final HandlerInterceptor[] getAdaptedInterceptors() { int count = adaptedInterceptors.size(); return (count > 0) ? adaptedInterceptors.toArray(new HandlerInterceptor[count]) : null; } 4.3.3 getHandlerInternal(HttpServletRequest request)获取Handler/** * Look up a handler for the URL path of the given request. * @param request current HTTP request * @return the handler instance, or &lt;code>null&lt;/code> if none found */ @Override protected Object getHandlerInternal(HttpServletRequest request) throws Exception { String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); Object handler = lookupHandler(lookupPath, request); if (handler == null) { // We need to care for the default handler directly, since we need to // expose the PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE for it as well. Object rawHandler = null; if (\"/\".equals(lookupPath)) { rawHandler = getRootHandler(); } if (rawHandler == null) { rawHandler = getDefaultHandler(); } if (rawHandler != null) { // Bean name or resolved handler? if (rawHandler instanceof String) { String handlerName = (String) rawHandler; rawHandler = getApplicationContext().getBean(handlerName); } validateHandler(rawHandler, request); handler = buildPathExposingHandler(rawHandler, lookupPath, lookupPath, null); } } if (handler != null &amp;&amp; logger.isDebugEnabled()) { logger.debug(\"Mapping [\" + lookupPath + \"] to \" + handler); } else if (handler == null &amp;&amp; logger.isTraceEnabled()) { logger.trace(\"No handler mapping found for [\" + lookupPath + \"]\"); } return handler; } 4.3.4 lookupHandler(lookupPath, request)根据给定url path和request获取Handlerprotected Object lookupHandler(String urlPath, HttpServletRequest request) throws Exception { // Direct match? Object handler = this.handlerMap.get(urlPath); if (handler != null) { // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } validateHandler(handler, request); return buildPathExposingHandler(handler, urlPath, urlPath, null); } // Pattern match? List&lt;String> matchingPatterns = new ArrayList&lt;String>(); for (String registeredPattern : this.handlerMap.keySet()) { if (getPathMatcher().match(registeredPattern, urlPath)) { matchingPatterns.add(registeredPattern); } } String bestPatternMatch = null; Comparator&lt;String> patternComparator = getPathMatcher().getPatternComparator(urlPath); if (!matchingPatterns.isEmpty()) { Collections.sort(matchingPatterns, patternComparator); if (logger.isDebugEnabled()) { logger.debug(\"Matching patterns for request [\" + urlPath + \"] are \" + matchingPatterns); } bestPatternMatch = matchingPatterns.get(0); } if (bestPatternMatch != null) { handler = this.handlerMap.get(bestPatternMatch); // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } validateHandler(handler, request); String pathWithinMapping = getPathMatcher().extractPathWithinPattern(bestPatternMatch, urlPath); // There might be multiple 'best patterns', let's make sure we have the correct URI template variables // for all of them Map&lt;String, String> uriTemplateVariables = new LinkedHashMap&lt;String, String>(); for (String matchingPattern : matchingPatterns) { if (patternComparator.compare(bestPatternMatch, matchingPattern) == 0) { uriTemplateVariables .putAll(getPathMatcher().extractUriTemplateVariables(matchingPattern, urlPath)); } } if (logger.isDebugEnabled()) { logger.debug(\"URI Template variables for request [\" + urlPath + \"] are \" + uriTemplateVariables); } return buildPathExposingHandler(handler, bestPatternMatch, pathWithinMapping, uriTemplateVariables); } // No handler found... return null; } 4.4.1 HandlerAdapter getHandlerAdapter(Object handler)根据Handler获取HandlerAdapter/** * Return the HandlerAdapter for this handler object. * @param handler the handler object to find an adapter for * @throws ServletException if no HandlerAdapter can be found for the handler. This is a fatal error. */ protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException { for (HandlerAdapter ha : this.handlerAdapters) { if (logger.isTraceEnabled()) { logger.trace(\"Testing handler adapter [\" + ha + \"]\"); } if (ha.supports(handler)) { return ha; } } throw new ServletException(\"No adapter for handler [\" + handler + \"]: Does your handler implement a supported interface like Controller?\"); } 4.4.2 supports(Object handler)public boolean supports(Object handler) { return (handler instanceof Controller); } 4.5.1 使用处理器完成对请求的处理public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { ((Servlet) handler).service(request, response); return null; } public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { HttpServletRequest request; HttpServletResponse response; if (!(req instanceof HttpServletRequest &amp;&amp; res instanceof HttpServletResponse)) { throw new ServletException(\"non-HTTP request or response\"); } request = (HttpServletRequest) req; response = (HttpServletResponse) res; service(request, response); } 4.5.2 service(HttpServletRequest req, HttpServletResponse resp)protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { long lastModified = getLastModified(req); if (lastModified == -1) { // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); } else { long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) { // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); } else { resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } } } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); } } 4.5.3 doGet(HttpServletRequest req, HttpServletResponse resp)protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String protocol = req.getProtocol(); String msg = lStrings.getString(\"http.method_get_not_supported\"); if (protocol.endsWith(\"1.1\")) { resp.sendError(HttpServletResponse.SC_METHOD_NOT_ALLOWED, msg); } else { resp.sendError(HttpServletResponse.SC_BAD_REQUEST, msg); } } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"框架,spring","slug":"框架-spring","permalink":"http://fyvan.github.io/categories/%E6%A1%86%E6%9E%B6-spring/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://fyvan.github.io/tags/SpringMVC/"}],"author":"fyang"},{"title":"Docker 安装 MongoDB","slug":"SoftwareInstall-2020-05-24-use-docker-install-mongodb","date":"2020-05-24T13:28:05.303Z","updated":"2020-06-18T08:18:52.586Z","comments":true,"path":"undefined/b285.html","link":"","permalink":"http://fyvan.github.io/undefined/b285.html","excerpt":"","text":"1. 搜索镜像查找Docker Hub上的mongo镜像。 root@Aspire:~# docker search mongo NAME DESCRIPTION STARS OFFICIAL AUTOMATED mongo MongoDB document databases provide high avai… 6877 [OK] mongo-express Web-based MongoDB admin interface, written w… 692 [OK] tutum/mongodb MongoDB Docker image – listens in port 27017… 230 [OK] 2. 拉取MongoDB镜像拉取Docker Hub上的mongo镜像。 root@Aspire:~# docker pull mongo Using default tag: latest latest: Pulling from library/mongo 23884877105a: Downloading [============> ] 6.626MB/26.69MB bc38caa0f5b9: Download complete 2910811b6c42: Download complete 36505266dcc6: Download complete a4d269900d94: Download complete 5e2526abb80a: Download complete d3eece1f39ec: Download complete 358ed78d3204: Download complete 1a878b8604ae: Download complete dde03a2883d0: Download complete 4ffe534daa34: Downloading [=======> ] 19.36MB/129.1MB f164ba21e17c: Download complete 6494c387442c: Download complete 3. 查看本地镜像列表查看MongoDB镜像是否拉取成功。 root@Aspire:~# docker images | grep mongo mongo latest 3f3daf863757 4 weeks ago 388MB 4. 创建存储目录创建MongoDB持久化文件目录。 mkdir -p /home/data/mongo/data 5. 启动容器options说明: –restart=always: 重启策略 -d: 后台运行容器，并返回容器ID -p: 端口映射，格式为：主机(宿主)端口:容器端口 –name: 为容器指定一个名称 -v: 给容器挂载存储卷，挂载到容器的某个目录 root@Aspire:~# docker run --restart=always -p 27017:27017 --name mongo -v /home/data/mongo/data:/data/db -d mongo --auth #启动后的信息 96e65e736ef5fa393b0b04bad17f955cb94bc6b1b378b534166ccba87e003366 6. 查看容器信息查看容器ID信息 root@Aspire:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 96e65e736ef5 mongo \"docker-entrypoint.s…\" 4 minutes ago Up 4 minutes 0.0.0.0:27017->27017/tcp mongo 7. 配置MongoDB权限以admin用户身份进入mongo 命令: docker exec -it 容器ID mongo admin root@Aspire:~# docker exec -it 96e65e736ef5 mongo admin > db.createUser({user: 'admin', pwd: 'admin', roles: [{role: \"root\", db: \"admin\"}]}); Successfully added user: { \"user\" : \"admin\", \"roles\" : [ { \"role\" : \"root\", \"db\" : \"admin\" } ] } > exit;MongoDB shell version v4.2.6 connecting to: mongodb://127.0.0.1:27017/admin?compressors=disabled&amp;gssapiServiceName=mongodb Implicit session: session { \"id\" : UUID(\"ed34651c-15c1-4b1a-8074-c44976f7b48f\") } MongoDB server version: 4.2.6 Welcome to the MongoDB shell. For interactive help, type \"help\". For more comprehensive documentation, see http://docs.mongodb.org/ Questions? Try the support group http://groups.google.com/group/mongodb-user > > db.createUser({user: 'admin', pwd: 'admin', roles: [{role: \"root\", db: \"admin\"}]}); 2020-05-24T15:43:19.449+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > Successfully added user: { ... \"user\" : \"admin\", ... \"roles\" : [ ... { ... \"role\" : \"root\", ... \"db\" : \"admin\" ... } ... ] ... } 2020-05-24T15:43:19.452+0000 E QUERY [js] uncaught exception: SyntaxError: unexpected token: identifier : @(shell):1:13 > > exit; 2020-05-24T15:43:27.456+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > 8. 测试测试否OK, MongoDB身份认证 root@Aspire:~# docker exec -it 96e65e736ef5 mongo admin > db.auth(\"admin\", \"admin\"); 1 > exit;MongoDB shell version v4.2.6 connecting to: mongodb://127.0.0.1:27017/admin?compressors=disabled&amp;gssapiServiceName=mongodb Implicit session: session { \"id\" : UUID(\"d2573daf-38b0-430e-aed3-e36187e8c800\") } MongoDB server version: 4.2.6 > > db.auth(\"admin\", \"admin\"); 2020-05-24T15:45:54.154+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > 1 1 > > exit; 2020-05-24T15:45:58.341+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > > document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"Ubantu,MongoDB","slug":"Ubantu-MongoDB","permalink":"http://fyvan.github.io/tags/Ubantu-MongoDB/"}],"author":"fyang"},{"title":"hello hexo","slug":"hello-world","date":"2020-05-24T03:24:07.081Z","updated":"2020-05-24T07:50:33.460Z","comments":true,"path":"undefined/b659.html","link":"","permalink":"http://fyvan.github.io/undefined/b659.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[],"tags":[]}],"categories":[{"name":"多线程与高并发","slug":"多线程与高并发","permalink":"http://fyvan.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/categories/JVM/"},{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"software","slug":"software","permalink":"http://fyvan.github.io/categories/software/"},{"name":"多线程","slug":"多线程","permalink":"http://fyvan.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"API","slug":"API","permalink":"http://fyvan.github.io/categories/API/"},{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"},{"name":"框架,spring","slug":"框架-spring","permalink":"http://fyvan.github.io/categories/%E6%A1%86%E6%9E%B6-spring/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"http://fyvan.github.io/tags/Thread/"},{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/tags/JVM/"},{"name":"redis","slug":"redis","permalink":"http://fyvan.github.io/tags/redis/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://fyvan.github.io/tags/Zookeeper/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"http://fyvan.github.io/tags/IntelliJ-IDEA/"},{"name":"synchronized","slug":"synchronized","permalink":"http://fyvan.github.io/tags/synchronized/"},{"name":"ObjectMapper","slug":"ObjectMapper","permalink":"http://fyvan.github.io/tags/ObjectMapper/"},{"name":"Docker","slug":"Docker","permalink":"http://fyvan.github.io/tags/Docker/"},{"name":"CentOS7, Redis","slug":"CentOS7-Redis","permalink":"http://fyvan.github.io/tags/CentOS7-Redis/"},{"name":"CentOS7, mariadb","slug":"CentOS7-mariadb","permalink":"http://fyvan.github.io/tags/CentOS7-mariadb/"},{"name":"CentOS7, Nginx","slug":"CentOS7-Nginx","permalink":"http://fyvan.github.io/tags/CentOS7-Nginx/"},{"name":"CentOS7, jdk1.8","slug":"CentOS7-jdk1-8","permalink":"http://fyvan.github.io/tags/CentOS7-jdk1-8/"},{"name":"MySql","slug":"MySql","permalink":"http://fyvan.github.io/tags/MySql/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://fyvan.github.io/tags/SpringMVC/"},{"name":"Ubantu,MongoDB","slug":"Ubantu-MongoDB","permalink":"http://fyvan.github.io/tags/Ubantu-MongoDB/"}]}