{"meta":{"title":"Yvan Blog","subtitle":"Schrödinger","description":"","author":"Yvan Yang","url":"http://fyvan.github.io","root":"/"},"pages":[{"title":"404","date":"2019-10-28T08:41:10.000Z","updated":"2020-05-24T07:27:31.413Z","comments":true,"path":"404.html","permalink":"http://fyvan.github.io/404.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"关于","date":"2018-09-30T09:25:30.000Z","updated":"2020-05-24T05:30:21.600Z","comments":true,"path":"about/index.html","permalink":"http://fyvan.github.io/about/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"分类","date":"2018-09-30T09:25:30.000Z","updated":"2020-05-24T05:30:34.255Z","comments":true,"path":"categories/index.html","permalink":"http://fyvan.github.io/categories/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"标签","date":"2018-09-30T10:23:38.000Z","updated":"2020-05-24T05:31:27.006Z","comments":true,"path":"tags/index.html","permalink":"http://fyvan.github.io/tags/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"留言板","date":"2018-09-30T09:25:30.000Z","updated":"2020-05-24T05:30:51.841Z","comments":true,"path":"contact/index.html","permalink":"http://fyvan.github.io/contact/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"友情链接","date":"2018-12-12T13:25:30.000Z","updated":"2020-05-24T05:31:13.584Z","comments":true,"path":"friends/index.html","permalink":"http://fyvan.github.io/friends/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"}],"posts":[{"title":"JVM垃圾回收器","slug":"Java-JVM-垃圾回收算法","date":"2020-06-18T08:39:34.863Z","updated":"2020-06-18T14:56:28.058Z","comments":true,"path":"undefined/86cc.html","link":"","permalink":"http://fyvan.github.io/undefined/86cc.html","excerpt":"","text":"JVM垃圾收集器的前世今生1. JVM垃圾收集器的发展历程HotSpot的垃圾收集器从Serial发展到CMS再到G1，经历了逾二十年时间，经过了数百上千万台服务器上的应用实践。从JDK1.3开始，直到最近的JDK13，从Serial收集器到Paralle收集器，再到Concurrent Mark Sweep和 Garbage First收集器，直到现在垃圾收集器的最前成果 Shenandoah 和ZGC，用户线程的停顿时间在持续缩短，但是仍然无法彻底消除，探索更优秀的垃圾收集器的工作，任重而道远。 Serial 串行收集器 新生代收集器、最基本、发展历史最久（jdk1.3之前）、单线程、基于复制算法 Serial Old 串行老年代收集器 老年代版本的Serial收集器、单线程、基于标记-整理算法 ParNew 收集器 Serial的多线程版本、新生代收集器、多线程、基于复制算法、关注用户停顿时间 Parallel Scavenge 收集器 新生代收集器，基于复制算法，并行的多线程、关注吞吐量 Parallel Old收集器 Parallel Scavenge的老年代版本，使用多线程和“标记-整理”算法 CMS（Conturrent Mark Sweep）收集器 并发、基于标记-清除算法 G1（Garbage-First）收集器 并行与并 发、分代收集、空间整合 Shenandoah 支持并发的整理算法、基于读写屏障、旋转指针 ZGC 支持并发收集、基于动态Region、染色指针、虚拟内存映射 Epsilon垃圾收集器 没有操作的垃圾收集器、处理内存分配但不实现任何实际内存回收机制的GC 2. JVM垃圾回收算法判断Java中对象存活的算法 引用计数法 可达性分析算法 垃圾回收算法 标记-清除算法 标记-复制算法 标记-整理算法 分代收集算法 3. 引用计数法一个比较普通的方法就是当对象在创建的时候,就给对象创建一个对象计数器,每当有一个地方引用到这个对象的时候,计数器加一;当引用失效的时候,计数器减一;任何时候计数器为0的对象就是不可能被引用的,就是我们所认知的 —死亡对象. 引用计数算法的实现比较简单,判定效率也较高,在大部分情况下它都是一个不错的算法,也有一些比较著名的应用案例,例如微软公司的COM(Component Object Mode)技术,使用ActionScript3的FlashPlayer等技术都引用了计数算法进行内存呢管理. 主流的Java虚拟机里面没有用到引用计数算法来管理内存,其中最主要的问题就是它很难解决对象之间相互循环引用的问题. 4. 对象可达性分析根搜索方式是通过一些GC Roots对象作为起点, 从这些节点开始往下搜索, 搜索通过的路径成为引用链(ReferenceChain), 当一个对象没有被GC Roots的引用链连接的时候, 说明这个对象是不可用的 5. JVM垃圾回收算法之–标记-清除算法清除算法是第一种使用和比较完善的垃圾回收算法, 算法分为两个过程: 标记正所有需要回收的对象 标记完成后清除被标记的对象 其标记的过程就是判断对象有效性, 执行可达性分析的过程. 6. JVM垃圾回收算法之–分代回收JVM对象的生存周期总体可分为三种: 新生代、老年代和永久代.(JDK1.8废弃永久代,由元空间代替) 根据各个年代的特点采用适当的垃圾回收算法 新生代的对象在每次垃圾回收时,都会有大量的对象死去,只有很少一部分存活,那就可以选择标记-复制算法. 在新生代中每次死亡对象约占98%, 那么在标记-复制算法中就不需要按照1:1的比例来划分内存区域, 而是将新生代细分为了一块较大的Eden和两块较小的Survivor区域,HotSpot中默认这两块区域的大小比例为8:2. 每次新生代可用区域为Eden加上其中一块Survivor区域,共90%的内存空间,这样就只有10%的内存空间处于被闲置状态. 在进行垃圾回收时, 存活的对象被转移到原本处在”空闲的”Eden区域. 如果某次垃圾回收之后,存活的对象所占空间远大于这10%的内存空间时, 也就是Survivor空间不够时,需要额外的空间来担保,通常是将这些对象转移到老年代. 对于老年代来说,大部分对象都处于存活状态.同时,如果一个大对象需要在该区域进行分配,而内存空间又不足,那么在没有外部内存空间担保的情况下,就必须选用标记-清除或者标记-整理算法来进行垃圾回收. 7. JVM垃圾回收算法之–分代划分Eden区 Eden区位于Java堆的年轻代，是新对象分配内存的地方，由于堆是所有线程共享的，因此在堆上分配内存需要加锁。而Sun JDK为提升效率，会为每个新建的线程在Eden上分配一块独立的空间由该线程独享，这块空间称为TLAB（Thread Local Allocation Buffer）。在TLAB上分配内存不需要加锁，因此JVM在给线程中的对象分配内存时会尽量在TLAB上分配。如果对象过大或TLAB用完，则仍然在堆上进行分配。如果Eden区内存也用完了，则会进行一次Minor GC（young GC）。 Survival from to Survival区与Eden区相同都在Java堆的年轻代。Survival区有两块，一块称为from区，另一块为to区，这两个区是相对的，在发生一次Minor GC后，from区就会和to区互换。在发生Minor GC时，Eden区和Survivalfrom区会把一些仍然存活的对象复制进Survival to区，并清除内存。Survival to区会把一些存活得足够旧的对象移至年老代。 GC有两种类型: MinorGC和Full GC MinorGC 一般情况下, 当新对象生成, 并且在Eden申请空间失败时, 就会触发MinorGC, 对Eden区域进行GC, 清除非存活对象, 并且把尚且存活的对象移动到Survivor区. 然后整理Survivor的两个区. 这种方式的GC是对年轻代的Eden区进行,不会影响到老年代. 因为大部分对象都是从Eden区开始的, 同时Eden区不会分配的很大,所以Eden区的GC会频繁进行. 因而, 一般在这里需要使用速度快、效率高的算法, 使Eden区能尽快空闲出来. Full GC 对整个堆进行整理, 包括Young、Tenured和Perm. Full GC因为需要对整个堆进行回收, 所以比Scavenge GC要慢, 因此应该尽可能减少Full GC的次数. 在堆JVM调优的过程中,很大一部分工作就是对于Full GC的调节. 8. 垃圾回收器8.1 Serial收集器 Serial收集器是最基本、发展历史最悠久的收集器,JDK1.3.1之前虚拟机新生代收集的唯一选择 Serial收集器是一个单线程的收集器. “单线程”的意义不仅仅是它只会用一个CPU或者一条收集器线程去完成垃圾收集工作,更重要的是它在垃圾收集的时候, 必须暂停其它所有工作的线程,直到它收集结束 Serial收集器是HotSpot虚拟机运行在Client模式下的默认新生代收集器 Serial收集器具有简单而搞笑, 由于没有线程交互的开销, 可以获得最高的但像成收集效率(单CPU环境) 开启参数 : --XX:+UseSerialGC 8.2 ParNew收集器 ParNew收集器是Serial收集器的多线程版本, 除了使用多线程进行垃圾收集之外, 其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The Word、对象分配规则、回收策略等斗鱼Serial收集器一致 ParNew收集器是许多运行在Server模式下的虚拟机首选的新生代收集器,其中一个原因是,除了Serial收集器之外, 目前只有ParNew收集器能与CMS收集器配合工作 并行(Parallel): 指多条垃圾收集线程并行工作,但此时用户线程处于仍然等待状态 并发(Concurrent): 指用户线程与垃圾收集线程同时执行(但不一定是并行,可能是交替执行), 用户线程继续工作, 而垃圾收集程序运行在另外一个CPU上 优点: 在多CPU时,比Serial效率高 缺点: 收集过程暂停所有应用程序线程, 单CPU时比Serial效率差 使用算法: 复制算法 使用范围: 新生代 应用: 运行在Server模式下的虚拟机中首选的新生代收集器 开启参数: 8.3 Serial Old收集器 Serial Old收集器是Serial收集器的老年代版本, 它同样是一个单线程收集器,使用”标记-整理”算法 Serial Old收集器主要用于Client模式下的虚拟机使用 Server模式下的两大用途 : 在JDK1.5及之前的版本与Parallel Scavenge收集器搭配使用 作为CMS收集器的后被方案,在并发收集发生Conturrent Mode Failure时使用 8.4 Parallel Scavenge收集器 Parallel Scavenge收集器也是一个新生代收集器, 它也是使用复制算法的收集器,有实并行的多线程收集器, 和 ParNew类似, 但是关注点不同 Parallel Scavenge收集器的目标是达到一个可控制的吞吐量. 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值, 即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间), 如果虚拟机总共运行需要100分钟, 其中垃圾收集花掉1分钟, 那么吞吐量就是99%. 适用场景: 高吞吐量则可用最高效率地利用CPU时间, 尽快地完成程序的运算任务, 主要适合在受台运算而不需要太多交互的任务 Parallel Scavenge收集器提供了两个参数用户精确控制吞吐量,分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数及直接设置吞吐量大小的-XX:GCTimeRatio参数 8.5 Parallel Old收集器 是Parallel Scavenge收集器的老年代版本，用于老年代的垃圾回收，但与Parallel Scavenge不同的是，它使用的是“标记-整理算法”。 适用于注重于吞吐量及CPU资源敏感的场合 8.6 CMS收集器 CMS收集器是一种以获取最短回收停顿时间为目标的收集器 CMS收集器是基于标记-清除算法实现的,他的整个运行过程可以分为: 初始登记 (标记以下GC Roots能直接关联到的对象,这个过程速度很快) 并发标记(进行GCRoots Tracing的过程) 重新标记(修正并发标记期因用户线程继续运作而导致标记产生变动的那一部分对象的标记记录,速度稍慢) 并发清除(清除死亡的对象) 4个步骤;其中,初始标记和重新标记仍然需要Stop The World CMS收集器运行的整个过程中,最耗费时间的是并发标记和并发清除过程, 收集器线程和用户线程是一起工作的,所以总体来说,CMS收集器的内存回收过程是与用户线程一起来并发执行的 开启参数 : -XX:+UseParNewGC , -XX:+UseConcMarkSweepGC 优点: 并发是收集、低停顿 缺点: CMS收集器堆CPU资源非常敏感.虽然在两个阶段并发阶段不会导致用户线程停顿, 但是会因为占用了一部分线程而导致应用程序变慢,总吞吐量下降. CMS,默认启动的回收线程数(CPU数量+3)/4 CMS收集器无法处理浮动垃圾, 可能出现”Conturrent Mode Failure”失败而导致另一次Full FC产生. 由于CMS并发清除阶段用户线程还在运行, 伴随着程序还在产生新的垃圾, 这一部分垃圾出现在标记之后, CMS无法在档次收集中处理掉它们, 只能留到下次再清理, 这一部分垃圾成为浮动垃圾. 也正是由于再垃圾收集阶段用户线程还在运行, 那么也就需要预留有足够的内存空间给用户线程使用, 因此CMS收集器不能像其他收集器那样等待老年代填满之后再进行收集, 需要预留一部分空间给并发收集时用户程序使用, 可以通过-XX:CMSInitiatingOccupancyFraction参数设置老年代内存使用达到多少时启动收集. 由于CMS收集器是一个基于标记-清除算法的收集器, 那么意味着收集结束会产生大量碎片, 有时候往往还有很多内存未使用, 可是没有一块连续的空间来分配一个对象, 导致不得不提前触发一次Full GC. CMS收集器提供了一个-XX: UseCMSCompactAtFullCollection参数(默认是开启的)用户在CMS收集器顶不住要FullGC是开启内存碎片整理(内存碎片整理意味着无法并发执行不得不停顿用户线程). 参数-XX:CMSFullGCsBeforeCompaction来设置执行多少次不压缩的Full GC后,跟着来一次带压缩的(默认值是0,意味着每次进入Full GC时都要进行碎片整理). 8.7 G1收集器 G1收集器的运作大致可分为 初始标记: 需要停顿, 耗时短 并发标记 最终标记: 需要停顿, 可并发执行 筛选标记 G1收集器是当今收集器技术发展的最前沿成果之一 相比其它收集器, 具有如下特点: 并行与并发: G1能够重发利用多CPU、多核环境下的有实,使用多个CPU来缩短Stop -The-World停顿时间 分代收集: 与其他收集器一样,分代概念在G1中依然存在 空间整合: 与CMS的标记-清除算法不同,G1从整体来看是基于标记-整理来实现的收集器,从局部(两个Region之间)上来看是基于复制算法实现的,着两种算法都意味着G1运作期间不会产生内存空间碎片,收集后能够提供整体的可用内存 可预测停顿: G1除了追求低停顿之外,还能简历可预测的停顿时间模型,能让使用者明确指定在一个长度为M毫秒的时间片段内,小号在垃圾收集上的时间不得超过N毫秒 使用G1收集器时,Java堆内的内存布局与其它收集器有很大的却别,它将整个Java堆划分为多个大小相等的独立区域(Region), 虽然还保留着新生代和老年代的概念, 但新生代和老年代不再是物理隔离的了,他们都是一部分Region(不需要连续)的集合. G1收集器之所以能够建立可预测的停顿时间模型,是因为它可以有计划的避免在整个Java堆中进行全区域的垃圾收集. G1跟踪各个Region里面垃圾堆积的价值大小(回收所获得的空间大小以及回收所需要时间的经验值), 在后台维护一个优先列表,每次根据允许的收集时间,优先回收价值最大的Region(这也是Garbage First名称的又来) 开启参数: -XX:+useG1GC 8.8 ZGC收集器 一款由Oracle公司研发的, 以低延迟为首要目标的一款垃圾收集器. 它是基于动态Region内存布局,(暂时)不设年龄分代, 使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记整理算法的收集器. 在JDK11新加入,还在实验阶段, 主要特点是: 回收TB级内存(最大4T),停顿时间不超过10ms 优点: 低停顿,高吞吐量,ZGC收集过程中额外耗费的内存小 缺点: 浮动垃圾 ZGC目前只在Linux/64上可用,如果有足够的需求,将来可能会增加对其他平台的支持 启动参数: -XX:+UnlockExperimentalVMOption, -XX:+Use ZGC,-Xmx10g,-Xlog:gc 8.8.1 ZGC收集器之动态Region 小型Region（Small Region）：容量固定为2MB，用于放置小于256KB的小对象 中型Region（Medium Region）：容量固定为32MB，用于放置大于等于256KB但小于4MB的对象 大型Region（Large Region）：容量不固定，可以动态变化，但必须为2MB的整数倍，用于放置4MB或以上的大对象。每个大型Region中只会存放一个大对象，最小容量可低至4MB，所有大型Region可能小于中型Region 大型Region在ZGC的实现中是不会被重分配的，因为复制一个大对象的代价非常高昂 8.8.2 ZGC收集器之染色指针 HotSpot虚拟机的标记实现方案有如下几种： 把标记直接记录在对象头上（如Serial收集器）； 把标记记录在与对象相互独立的数据结构上（如G1、Shenandoah使用了一种相当于堆内存的1/64大小的，称为BitMap的结构来记录标记信息） 直接把标记信息记在引用对象的指针上（如ZGC） 染色指针是一种直接将少量额外的信息存储在指针上的技术 目前在Linux下64位的操作系统中高18位是不能用来寻址的，但是剩余的46位却可以支持64T的空间，到目前为止我们几乎还用不到这么多内存。于是ZGC将46位中的高4位取出，用来存储4个标志位，剩余的42位可以支持4T的内存 8.8.3 ZGC收集器之三色标记在并发的可达性分析算法中我们使用三色标记（Tri-color Marking）来标记对象是否被收集器访问过 白色：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达 黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接（不经过灰色对象）指向某个白色对象。 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 8.8.4 ZGC收集器之读屏障当对象从堆中加载的时候，就会使用到读屏障（Load Barrier）。这里使用读屏障的主要作用就是检查指针上的三色标记位，根据标记位判断出对象是否被移动过，如果没有可以直接访问，如果移动过就需要进行“自愈”（对象访问会变慢，但也只会有一次变慢），当“自愈”完成后，后续访问就不会变慢 读写屏障可以理解成对象访问的“AOP”操作 8.8.5 ZGC收集器之内存多重映射ZGC使用了内存多重映射（Multi-Mapping）将多个不同的虚拟内存地址映射到同一个物理内存地址上，这是一种多对一映射，意味着ZGC在虚拟内存中看到的地址空间要比实际的堆内存容量来得更大。把染色指针中的标志位看作是地址的分段符，那只要将这些不同的地址段都映射到同一个物理内存空间，经过多重映射转换后，就可以使用染色指针正常进行寻址了. ZGC的多重映射只是它采用染色指针技术的伴生产物 8.8.6 ZGC收集器运作过程并发标记：与G1、Shenandoah一样，并发标记是遍历对象图做可达性分析的阶段，它的初始标记和最终标记也会出现短暂的停顿，整个标记阶段只会更新染色指针中的Marked 0、Marked 1标志位 并发预备重分配：这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集（Relocation Set）。ZGC每次回收都会扫描所有的Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本 并发重分配：重分配是ZGC执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表（Forward Table），记录从旧对象到新对象的转向关系。ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”（Self-Healing）能力 并发重映射（Concurrent Remap）：重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，但是ZGC中对象引用存在“自愈”功能，所以这个重映射操作并不是很迫切。ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里去完成，反正它们都是要遍历所有对象的，这样合并就节省了一次遍历对象图的开销 8.9 Epsilon 收集器Epsilon（A No-Op Garbage Collector）垃圾回收器控制内存分配，但是不执行任何垃圾回收工作。一旦java的堆被耗尽，jvm就直接关闭。设计的目的是提供一个完全消极的GC实现，分配有限的内存分配，最大限度降低消费内存占用量和内存吞吐时的延迟时间。一个好的实现是隔离代码变化，不影响其他GC，最小限度的改变其他的JVM代码 适用场景: Performance testing,什么都不执行的GC非常适合用于差异性分析 在测试java代码时，确定分配内存的阈值有助于设置内存压力常量值。这时no-op就很有用，它可以简单地接受一个分配的内存分配上限，当内存超限时就失败。例如：测试需要分配小于1G的内存，就使用-Xmx1g参数来配置no-op GC，然后当内存耗尽的时候就直接crash 相关启动参数 UnlockExperimentalVMOptions：解锁隐藏的虚拟机参数 -XX:+UnlockExperimentalVMOptions, -XX:+UseEpsilonGC, -Xms100m, -Xmx100m 8.10 Shenandoah 收集器一款只有OpenJDK才会包含的收集器，最开始由RedHat公司独立发展后来贡献给了OpenJDK Shenandoah与G1类似，也是使用基于Region的堆内存布局，同样有着用于存放大对象的Humongous Region，默认的回收策略也同样是优先处理回收价值最大的Region 但是管理堆内存方面，与G1至少有三个明显的不同之处： Shenandoah 支持并发的整理算法;G1支持并行整理算法。 Shenandoah（目前）是默认不使用分代收集的；G1 有专门的新生代Region或者老年代Region的存在; Shenandoah摒弃了在G1中耗费大量内存和计算资源去维护的记忆集，改用名为连接矩阵（Connection Matrix）的全局数据结构来记录跨Region的引用关系，降低了处理跨代指针时的记忆集维护消耗，也降低了伪共享问题的发生概率 优点：延迟低 缺点：高运行负担使得吞吐量下降；使用大量的读写屏障，尤其是读屏障，增大了系统的性能开销； 开启参数: -XX:+UnlockExperimentalVMOptions, -XX:+UseShenandoahGC 8.10.1 Shenandoah 收集器之连接矩阵 连接矩阵可以简单理解为一张二维表格，如果Region N有对象指向RegionM，就在表格的N行M列中打上一个标记，如右图所示，如果Region 5中的对象Baz引用了Region 3的Foo，Foo又引用了Region 1的Bar，那连接矩阵中的5行3列、3行1列就应该被打上标记。在回收时通过这张表格就可以得出哪些Region之间产生了跨代引用 8.10.2 Shenandoah 收集器之转发指针 转发指针（Forwarding Pointer，也常被称为Indirection Pointer）来实现对象移动与用户程序并发的一种解决方案 Brooks提出的新方案不需要用到内存保护陷阱，而是在原有对象布局结构的最前面统一增加一个新的引用字段，在正常不处于并发移动的情况下，该引用指向对象自己。从结构上来看，Brooks提出的转发指针与某些早期Java虚拟机使用过的句柄定位，有一些相似之处，两者都是一种间接性的对象访问方式，差别是句柄通常会统一存储在专门的句柄池中，而转发指针是分散存放在每一个对象头前面 8.10.3 Shenandoah 收集器之读写屏障 Brooks形式的转发指针在设计上决定了它是必然会出现多线程竞争问题的，如果收集器线程与用户线程发生的只是并发读取，那无论读到旧对象还是新对象上的字段，返回的结果都应该是一样的，这个场景还可以有一些“偷懒”的处理余地；但如果发生的是并发写入，就一定必须保证写操作只能发生在新复制的对象上，而不是写入旧对象的内存中 解决方案: Shenandoah不得不同时设置读、写屏障去拦截 9. 如何评估一款GC的性能 吞吐量: 程序运行时间(程序运行时间 + 内存回收的时间) 垃圾收集开销: 吞吐量的补救,垃圾收集器所占时间与总时间的比例 暂停时间: 执行垃圾收集,程序的工作线程被暂停的时间 收集频率: 相对于应用程序的执行,收集操作发生的频率 堆空间: Java堆区所栈的内存大小 快速: 一个对象从诞生到被回收所经历的时间 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/tags/JVM/"}],"author":"fyang"},{"title":"Spring面试整理","slug":"spring面试整理","date":"2020-06-15T02:08:06.870Z","updated":"2020-06-18T08:21:32.491Z","comments":true,"path":"undefined/e999.html","link":"","permalink":"http://fyvan.github.io/undefined/e999.html","excerpt":"","text":"spring面试整理1. Spring框架概述1.1 什么是spring框架？Spring框架有哪些主要模块？Spring框架是一个为 Java应用程序的开发提供了综合、广泛的基础性支持的Java平台。Spring帮助开发者解决了开发中基础性的问题，使得开发人员专注于应用程序的开发。 Spring框架本身亦是按照设计模式精心打造，这使得我们可以 在开发环境中安心I的集成Spring框架，不必担心Spring是如何在后台进行工作的。Spring框架至今已经集成了20多个模块。这些模块主要被分为如下图所示的核心容器、数据访问/集成、Web、AOP（面向切面编程）、工具、消息、和测试模块。 1.1.1 Data Access/Integration(数据访问/集成）数据访问/集成层包括JDBC、ORM、OXM、JMS、和Transaction模块，具体介绍如下： JDBC模块：提供了一个JDBC的抽象层，大幅度减少了在开发过程中能够对数据库操作的编码。 ORM模块：对流行的对象关系 映射API，包括JPA、JDO、Hibernate和iBatis提供了集成层。 OXM模块：提供了一个支持对象/XML 映射的抽象层实现，如 JAXB、Castor、XMLBeans、JiBX 和 XStream。 JMS模块：指 Java 消息服务，包含的功能为生产和消费的信息。 Transactions事务模块：支持编程和声明式事务管理实现特殊接口类，并为所有的 POJO。 1.1.2 Web 模块Spring 的 Web 层包括 Web、Servlet、Struts 和 Portlet 组件，具体介绍如下。 Web 模块：提供了基本的 Web 开发集成特性，例如多文件上传功能、使用的 Servlet 监听器的 IoC 容器初始化以及 Web 应用上下文。 Servlet模块：包括 Spring 模型—视图—控制器（MVC）实现 Web 应用程序。 Struts 模块：包含支持类内的 Spring 应用程序，集成了经典的 Struts Web 层。 Portlet 模块：提供了在 Portlet 环境中使用 MV C实现，类似 Web-Servlet 模块的功能。 1.1.3 Core Container（核心容器）Spring 的核心容器是其他模块建立的基础，由 Beans 模块、Core 核心模块、Context 上下文模块和 Expression Language 表达式语言模块组成，具体介绍如下。 Beans 模块：提供了 BeanFactory，是工厂模式的经典实现，Spring 将管理对象称为 Bean。 Core 核心模块：提供了 Spring 框架的基本组成部分，包括 IoC 和 DI 功能。 Context 上下文模块：建立在核心和 Beans 模块的基础之上，它是访问定义和配置任何对象的媒介。ApplicationContext 接口是上下文模块的焦点。 Expression Language 模块：是运行时查询和操作对象图的强大的表达式语言。 1.1.4 其他模块Spring的其他模块还有 AOP、Aspects、Instrumentation 以及 Test 模块，具体介绍如下。 AOP 模块：提供了面向切面编程实现，允许定义方法拦截器和切入点，将代码按照功能进行分离，以降低耦合性。 Aspects 模块：提供与 AspectJ 的集成，是一个功能强大且成熟的面向切面编程（AOP）框架。 Instrumentation 模块：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用。 Test 模块：支持 Spring 组件，使用 JUnit 或 TestNG 框架的测试。 1.2 使用Spring框架能带来哪些好处？下面列举一些使用Spring框架带来的主要好处： Dependency Injection（DI）方法使得构造器和JavaBean properties文件 中的依赖关系一目了然。 与EJB容器相比较，IoC同期更加趋向于轻量级。这样一来IoC容器在有限的内存和CPU资源的情况下进行应用程序的开发和发布就变得十分有利。 Spring并没有闭门造车，Spring利用了已有的技术比如ORM框架、logging框架、J2EE、Quartz和JDK Timer,以及 其他视图技术。 Spring框架是按照模块的形式来组织的。又包和类的编号就可以看出其所属的模块，开发者仅仅需要选用他们需要的模块即可。 要测试一项用Spring开发的应用程序十分简单，因为测试相关的环境代码都已经囊括在框架中了。更加简单的是，利用JavaBean形式的POJO类，可以很方便的利用依赖注入来写入测试数据。 SPring的Web框架亦是一个精心设计的Web MVC框架，为开发者们在web框架的选择上提供了一个除了主流框架比如Struts、过度设计的、不流行web框架以外的有力选项。 Spring提供了一个便捷的事务管理接口，适用于小型的本地事务处理（比如在单DB的环境下）和复杂的共同事务处理（比如利用JTA的复杂DB环境）。 1.3 Spring框架的设计目标，设计理念，和核心是什么？Spring设计目标：spring为开发者提供一个一站式情况及应用开发平台。 Spring设计理念：在JavaEE开发中，支持POJO和JavaBean开发 方式，使应用面向接口开发，充分支持OO（面向对象）设计方法；Spring通过IoC同期实现对象耦合关系的管理，并实现依赖反转，将对象之间的依赖关系交给IoC容器，实现解耦。 Spring框架的核心：IoC容器和AOP模块。通过IoC同期关机POJO对象以及他们之间的耦合关系；通过AOP以动态非侵入的方式增强服务。 IoC让相互协作的组件保持松散的耦合，而AOP编程允许你把遍布于应用各层的功能分离出来形成可重用的功能组件。 1.4 Spring的优缺点是什么？优点： 方便解耦，简化开发 Spring就是一个大工厂，可以将所有对象的创建和依赖关系的维护，交给Spring管理。 AOP编程的支持 Spring提供面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等功能。 声明式事务的支持 只需要通过配置就可以完成对事务的管理，而无需手动编程。 方便程序的测试 Spring对Junit4/5支持，可以通过注解方便的测试Spring程序。 方便集成各种优秀框架 Spring不排斥各种优秀的开源框架，其内部提供了对各种优秀框架直接支持（如：Struts、Hibernate、MyBatista等）。 降低JavaEE API的使用难度 Spring对JavaEE开发中非常刊用的一些API（JDBC、JavaMail、远程调用等），都提供了封装，使用 这些API应用难度大大降低。 缺点： Spring明明是一个很轻量级的框架，却给人感觉很大而全 Spring依赖反射，反射影响性能 使用门槛升高，入门Spring需要较长时间 1.5 Spring有哪些应用场景应用场景：JavaEE企业应用开发，包括SSH、SSM等 Spring价值： Spring是一个非侵入式的框架，目标是使应用程序代码对框架依赖最小化。 Spring提供一个一致的编程模型，使应用直接使用 POJO开发，于运行环境隔离开来。 Spring推动应用设计风格面向对象和面向接口开发转变，提高了代码的重用性和可测试性。 1.6 Spring框架中都用到了哪些设计模式？ 工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例 单利模式：Bean默认为单利模式 代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术 模板方法：用来解决代码重复的问题。比如：RestTemplate，JmsTemplate,JpaTemplate 观察者模式：定义对象键一种一对多的 依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被自动更新，如Spring种listener的实现–ApplicationListener。 1.7 详细讲解一下核心容器（Spring context应用上下文）模块这是基本的Spring模块，提供Spring框架的基础功能，BeanFactory是任何以Spring为基础的应用的核心。Spring框架建立在此模块之上，它使Spring成为一个容器。 Bean工厂是工厂模式的一个实现，提供弄个了控制反转功能，用来把应用的配置和依赖从真正的应用代码中分离。最常用的就是org.springframework.beans.factory.xml.XmlBeanFactory，它根据 XML文件总定义加载beans。该同期从XML文件读取配置元数据并用它去创建一个完全配置的系统或应用。 1.8 Spring框架中有哪些不同类型的事件Spring提供了一下5中标准的事件： 上下文更新事件(ContextRefreshedEvent)：在 调用ConfigurableApplicationContext接口中的refresh（）方法时被触发。 上下文开始事件（ContextStartedEvent）：当容器调用ConfigurableApplicationContext的Start（）方法开始/重新开始容器时触发该事件。 上下文停止事件（ContextStoppedEvent）：当容器调用ConfigurableApplicationContext的Stop（）方法停止容器时触发该事件。 上下文关闭事件(ContextClosedEvent)：当ApplicationContext被关闭时触发该事件。容器被关闭时，其管理的所有单利Bean都被销毁。 请求处理事件(RequestHandledEvent)：在 Web应用中，当HTTP请求（request）结束触发该事件。如果一个bean实现了ApplicationListener接口，当一个ApplicationEvent被发布以后，bean会自动被通知。 1.9 Spring应用程序有哪些不同组件？Spring应用一般有以下组件： 接口 - 定义功能 Bean类 - 它包含属性，setter和getter方法，函数等 Bean配置文件 - 包含类的信息以及如何配置他们。 Spring面向切面编程(AOP) - 提供面向切面编程的功能 用户程序 - 它使用接口 1.10 使用Spring有哪些方式？使用Spring有以下方式： 作为一个成熟的Spring Web应用程序 作为第三方Web框架，使用Spring Frameworks中间层 最为企业级Java Bean，他可以保障现有的POJO（Plain Old Java Object） 用于远程使用 2. Spring控制反转(IoC)和依赖注入(DI)2.1 什么是 Spring IoC容器控制反转即IoC(Inversion of Control),它把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的“控制反转”概念就是对组件对象控制权的转移，从程序代码本身转移到了外部容器。 Spring IoC负责创建对象，管理对象(通过依赖注入 DI)，装配对象，配置对象，并且管理这些对象的整个生命周期。 2.2 控制反转(IoC)有什么作用？ 管理对象的创建和依赖关系的维护。对象的创建并不是一件简单的事情，在对象关系比较复杂时，如果依赖关系需要程序员来维护的话，那是相当头疼的 解耦，由容器去维护具体的对象 托管了类的生产过程，比如我们需要在类的产生过程中做一些处理，最直接的例子就是代理，如果有容器程序可以把这部分处理交给容器，应用程序则无需去关心类是如何完成代理的 2.3 IoC的优点是什么？ IoC或依赖注入把应用的代码量降低到最低 它使应用程序容易测试，单元测试不再需要单例和JNDI查找机制 最小的代价阿和最小的侵入性使松散耦合得以实现。 IoC容器支持加载服务时的饿汉式初始化和懒加载。 2.4 Spring IoC的实现机制Spring 中的IoC的实现原理就是工厂模式和反射机制** 示例： interface Fruit{ public abstract void eat(); } class Apple implements Fruit{ public void eat(){ System.out.println(\"Apple\"); } } class Orange implements Fruit{ public void eat(){ System.out.println(\"Orange\"); } } class Factory{ public static Fruit getInstance(String ClassName){ Furit f = null; try{ f = (Fruit)Class.forName(ClassName).newInstance(); }catch(Exception e){ e.printStackTrace(); } return f; } } class Client{ public static void main(String[] a){ Furit f = Factory.getIntence(\"io.github.dunwu.spring.Apple\"); if(f != null){ f.eat(); } } } 2.5 Spring 的IoC支持哪些功能？Spring的IoC设计支持以下功能： 依赖注入 依赖检查 自动装配 支持集合 指定初始化方法和销毁方法 支持回调某些方法（但是需要实现Spring接口，略有侵入） 其中，最重要的就是依赖注入，从XML的配置上说，即ref标签。对应Spring RuntimeBeanReference对象。 对于IoC来说，最重要就是容器。容器管理着Bean的生命周期，控制着Bean的依赖注入。 2.6 BeanFactory和ApplicationContext有什么区别？BeanFactory和ApplicationContext是Spring的两大核心接口，都可以当做Spring的容器。其中ApplicationCont是BeanFactory的子接口。 依赖关系 BeanFactory：是Spring里面最底层的接口，包含了各种Bean的定义，读取bean配置文档，管理bean的加载、实例化、控制bean的生命周期，维护bean之间的依赖关系。 ApplicationContext接口 作为BeanFactory的派生，除了提供BeanFactory所具有的功能外，还提供了更完整的框架功能： 集成MessageSource，因此支持国际化 同意的资源文件访问当时 提供在监听器中注册bean的事件 同时加载多个配置 文件 载入多个（有继承关系 ）上下文，使得每一个上下文都专注于一个特定的层次，比如应用的web层 加载方式 BeanFactory采用的是延迟加载形式来注入Bean的，即只有在 使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化。这样，我们就不能发现一些存在的Spring的配置问题。如果Bean的某一个属性没有注入，BeanFactory加载后，直至第一次使用掉哦弄getBean方法才会抛出异常。 ApplicationContext，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误，这样有利于检查所依赖的属性是否注入。ApplicationContext启动后预载入所有的单实例Bean，通过预载入单实例bean，确保当你需要的时候，你就不用等待，因为他们已经创建好了。 相对于基本的BeanFactory，ApplicationContext唯一的不足时占用内存空间。当应用程序配置Bean较多时，程序启动较慢。 创建方式 BeanFactory通常以编程的方式被创建，ApplicationContext还能以声明的方式创建，如使用ContextLoader。 注册方式 BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册。 2.7 Spring如何设计容器的，BeanFactory和ApplicationContext的关系详解Spring作者Rod Johnson设计了两届接口用以表示容器 BeanFactory ApplicationContext BeanFactory简单粗暴，可以理解为就是个HashMap，key是BeanName，value是Bean实例。通常只提供注册(put)，获取(get)这两个功能。我们介意称之为“低级容器”。 ApplicationContext可以称之为“高级容器”。应为他比BeanFactory多了更多的功能。它继承了多个接口。因此具备了更多的功能。例如资源的获取，支持多种消息(例如JSP tag的支持)，对BeanFactory多了工具界别的支持等待。所以你看他的名字已经不是BeanFactory之类的工厂了，而是“应用上下文”，代表着整个大容器的所有功能。该接口定义了一个refresh方法，此方法是所有阅读Spring源码的人的最熟悉的方法，用于刷新整个容器，即重新加载/刷新所有的Bean。 当然，除了这两个大接口，还有其他的辅助接口，这里就不介绍他们了。 BeanFactory和ApplicationContext的关系 为了更直观的展示 “低级容器” 和 “高级容器” 的关系，这里通过常用的 ClassPathXmlApplicationContext 类来展示整个容器的层级 UML 关系。 最上面的是 BeanFactory，下面的 3 个绿色的，都是功能扩展接口，这里就不展开讲。 看下面的隶属 ApplicationContext 粉红色的 “高级容器”，依赖着 “低级容器”，这里说的是依赖，不是继承哦。他依赖着 “低级容器” 的 getBean 功能。而高级容器有更多的功能：支持不同的信息源头，可以访问文件资源，支持应用事件（Observer 模式）。 通常用户看到的就是 “高级容器”。 但 BeanFactory 也非常够用啦！ 左边灰色区域的是 “低级容器”， 只负载加载 Bean，获取 Bean。容器其他的高级功能是没有的。例如上图画的 refresh 刷新 Bean 工厂所有配置，生命周期事件回调等。 小结 说了这么多，不知道你有没有理解Spring IoC？ 这里小结一下：IoC 在 Spring 里，只需要低级容器就可以实现，2 个步骤： 加载配置文件，解析成 BeanDefinition 放在 Map 里。 调用 getBean 的时候，从 BeanDefinition 所属的 Map 里，拿出 Class 对象进行实例化，同时，如果有依赖关系，将递归调用 getBean 方法 —— 完成依赖注入。 上面就是 Spring 低级容器（BeanFactory）的 IoC。 至于高级容器 ApplicationContext，他包含了低级容器的功能，当他执行 refresh 模板方法的时候，将刷新整个容器的 Bean。同时其作为高级容器，包含了太多的功能。一句话，他不仅仅是 IoC。他支持不同信息源头，支持 BeanFactory 工具类，支持层级容器，支持访问文件资源，支持事件发布通知，支持接口回调等等。 #3# 2.8 ApplicationContext通常的实现是什么？ FileSystemXmlApplicationContext ：此容器从一个XML文件中加载beans的定义，XML Bean配置文件的全路径名必须提供给它的构造函数。 ClassPathXmlApplicationContext：此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置。 WebXmlApplicationContext：此容器加载一个XML文件，此文件定义了一个WEB应用的所有bean。 2.9 什么是Spring的依赖注入？控制反转IoC是一个很大的概念，可以用不同的方式来实现。其主要实现方式有两种：依赖注入和依赖查找 依赖注入：相对于IoC而言，依赖注入(DI)更加准确的描述了IoC的设计理念。所谓依赖注入(Dependency Injection),即组件之间的依赖关系由容器在应用系统运行期来决定，也就是由容器动态地讲 某种依赖关系的目标对象实例注入到应用系统中的各个关联的组件之中。组件不做定位查询，只提供普通的Java方法让容器去决定依赖关系。 2.10 依赖注入的基本原则依赖注入的基本原则是：应用组件不应该负责朝招资源或者其他依赖的协作对象。配置对象的工作应该由IoC容器负责，“查找资源”的逻辑应该从应用组件的代码中抽取出来，交给IoC容器负责。容器全权负责组件的装配，它会把符合依赖关系对象通过属性(JavaBean中的setter)或者构造器传递给需要的对象。 2.11 依赖注入有什么优势依赖注入之所以更流行是因为它是一种更可取的方式：让容器全权负责依赖查询，受管组件只需要暴露JavaBean的setter方法或者带参数的构造器或者接口，使容器可以在初始化时组装对象 的依赖关系。其与依赖查找方式相比，主要优势为： 查找定位操作与应用代码完全无关 不依赖于容器的API，可以很容易地在任何容器以外使用应用对象 不需要 特殊的接口，绝大多数对象可以做到完全不必依赖容器 2.12 依赖注入的实现方式依赖注入是时下 最流行的IoC实现方式，依赖注入分为接口注入(Interface Injection)，Setter方法注入(Setter Injection)和构造器注入(Constructor Injection)三种方式。其中接口注入由于在灵活性和易用性比较差，现在从Spring4开始已经被废弃。 构造器依赖注入：构造器依赖注入通过容器触发一个类的构造器来实现的，该类有一系列参数，每个参数代表一个对其他类的依赖。 Setter方法注入：Setter方法注入是容器通过调用无参构造器或无参static工厂方法实例化bean之后，调用该bean的setter方法，即实现了基于setter的依赖注入。 2.13 构造器依赖注入和 Setter方法注入的区别 构造函数注入 setter 注入 没有部分注入 有部分注入 不会覆盖 setter 属性 会覆盖 setter 属性 任意修改都会创建一个新实例 任意修改不会创建一个新实例 适用于设置很多属性 适用于设置少量属性 两种依赖方式都可以使用，构造器注入和Setter方法注入。最好的解决方案是用构造器参数实现强制依赖，setter方法实现可选依赖 3. Spring Beans3.1 什么是Spring Beans?Spring Beans是那些形成Spring应用的主干的java对象。它们被Spring IoC容器初始化，装配，和管理。这些beans通过容器中配置的元数据创建。比如，以XML文件中的形式定义。 3.2 一个Spring Bean定义包含什么？一个Spring Bean的定义包含容器必知的所有配置元数据，包括如何创建一个bean，它的生命周期详情及它的依赖。 3.3 如何给Spring容器提供配置元数据？Spring有几种配置方式？这里有三种重要的方法给Spring容器提供配置元数据。 XML配置文件 基于注解的配置 基于java的配置 3.4 Spring配置文件中包含了哪些信息Spring配置文件是个XML文件，这个文件包含了类信息，描述了如何配置他们，以及如何相互调用 3.5 Spring基于xml注入bean的几种方式 Set方法注入 构造器注入：通过index设置参数的位置；通过type设置参数类型 静态工厂注入 实例工厂 3.6 你怎样定义类的作用域？当定义一个在Spring里，我们还能给这个bean声明一个作用域。他可以通过bean定义中的scope属性来定义。如，当Spring要在需要的时候每次生产一个新的beam实例，bean的scope属性被制定为prototype。另外一方面，一个bean每次使用时候必须返回同一个实例，这个bean的scope属性必须设置为singleton。 3.7 解释Spring支持的几种bean的作用域Spring框架支持以下五种bean的作用域： singleton：bean在每个Spring IoC容器中只有一个实例 prototype：一个bean的定义可以有多个实例 request：每次http请求都会创建一个bean，该作用域仅在基于 web的Spring ApplicationContext情形下有效 session：在一个http session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效 global-session：在一个全局的http session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效 注意： 缺省的Spring bean 的作用域是Singleton。使用 prototype 作用域需要慎重的思考，因为频繁创建和销毁 bean 会带来很大的性能开销。 3.8 Spring框架中能够的单利bean是线程安全的吗？不是，Spring框架中的案例bean不是县城内安全的 Spring中的bean默认是单例模式，spring框架并没有对单例bean进行多线程的封装处理。 实际上大部分时候spring bean是无状态的(比如dao类)，所以某种程度上来说bean也是线程安全的，但如果bean有状态的话(比如view model对象)，那就要求开发者自己去保证线程安全了，最简单的就是改变bean的作用域，把“singleton”变更为”prototype“，这样请求bean相当于new Bean()了，所以可以保证线程安全了。 有状态就是有数据存储功能 无状态就是不会保存数据 3.9 Spring如何处理线程并发问题？在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域，因为Spring对一些Bean中非线程安全状态采用ThreadLocal进行处理，解决线程安全问题。 ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。同步机制采用了“时间换空间”的方式，仅提供一份变量，不同的线程在访问前需要获取锁，没获得锁的线程则需要排队。而ThreadLocal才用了“空间换时间”的方式。 ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 3.10 解释Spring框架中bean的生命周期在传统的Java应用中，bean的生命 周期很简单。使用Java关键字new进行bean实例化，然后该bean就可以使用了。一旦该bean不再被使用，则由Java自动进行垃圾回收，相比之下，Spring容器中的bean的生命周期就显得相对复杂多了。正确理解Spring bean的生命周期非常重要，因为你或许要利用Spring提供的扩展点来自定义bean的创建过程。 下图展示了bean装载到Spring应用上下文的一个典型的生命周期过程。 bean在spring容器中从创建到销毁经历了若干阶段，每一个阶段都可以针对Spring如何管理bean济宁个性化定制。 正如你所见，在bean准备就绪之前，bean工厂执行了若干启动步骤： Spring对bean进行实例化； Spring将值和bean的引用注入到bean对应的属性中； 如果bean实现了BeanNameAware接口，Spring将bean的ID传递setBean-Name()方法； 如果bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory()方法，将BeanFactory容器 实例传入； 如果Bean实现了ApplicationContextAware接口，Spring将调用setApplicationContext()方法，将bean所在的应用上下文的引用 传入进行； 如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessBeforeInitialization()方法； 如果bean实现了InitializingBean接口，Spring将调用它们的after-PropertiesSet()方法。类似地，如果bean使用initmethod声明了初始化方法，该方法也会被调用； 如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessAfterInitialization()方法； 此时，bean已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁； 如果bean实现了DisposableBean接口，Spring将调用它的destroy()接口方法。同样，如果bean使用destroy-method声明了销毁方法，该方法也会被调用。 现在你已经了解了如何创建和加载一个Spring容器。但是一个空的容器并没有太大的价值，在你把东西放进去之前，它里面什么都没有。为了从Spring的DI(依赖注入)中受益，我们必须将应用对象装配进Spring容器中。 3.11 哪些是重要的bean生命周期方法？你能重载它们吗？有两个重要的bean生命周期方法，第一个setup，它是在容器加载bean的时候被调用。第二个方法时teardown，它是在容器卸载类的时候被调用。 bean标签有两个重要的属性(init-method和destroy-method)。用它们你可以自己定制初始化和注销方法。它们也有相应的注解@PostConstruct和@PreDestroy。 3.12 什么是Spring的内部bean？什么是Spring inner beans？在Spring矿浆中，当一个bean仅被用作另一个bean的属性时，它能被声明为一个内部bean。内部bean可以用setter注入“属性”和构造方法注入“构造参数”的方式来实现，内部bean通常是匿名的。它们的Scope一般是prototype。 比如，在 我们的应用程序中，一个Customer类引用了一个Person类，我们要做的是创建一个Person的实例，然后在Customer内部使用。 public class Customer{ private Person person; //Setters and Getters } public class Person{ private String name; private String address; private int age; //Setters and Getters } 内部bean的声明方式如下： &lt;bean id=\"CustomerBean\" class=\"com.somnus.common.Customer\"> &lt;property name=\"person\"> &lt;!-- This is inner bean --> &lt;bean class=\"com.howtodoinjava.common.Person\"> &lt;property name=\"name\" value=\"lokesh\" /> &lt;property name=\"address\" value=\"India\" /> &lt;property name=\"age\" value=\"34\" /> &lt;/bean> &lt;/property> &lt;/bean> 3.12 在Spring中如何注入一个java集合？Spring提供以下及中欧冠集合的配置元素： 类型用于注入一列值，允许有相同的值。 类型用于注入一组值，不允许有相同的值。 类型用于注入一组键值对，键和值都可以为任意类型。 类型用于注入一组键值对，键和值都只能为String类型。 3.13 什么是bean装配？装配，或bean装配是指在Spring容器中把bean组装到一起，前提是容器需要知道bean的依赖关系，如何通过依赖注入来把它们装配到一起。 3.14 什么是bean的自动装配？在Spring框架中，在配置文件中设定bean的依赖关系 是一个很好的机制，Spring容器能够自动装配相互合作的bean，这意味着容器不需要和配置，能通过Bean工厂自动处理bean之间的协作。这意味着SPring可以通过向BeanFactory中注入的方式自动搞定bean之间的依赖关系。自动装配可以设置在每个bean上，也可以设定在特定的bean上。 3.15 解释不通方式的自动装配，Spring自动 装配bean有哪些方式？在Spring中，对象无需自己查找或创建与其关联的其他对象，由容器负责把需要相互协作的对象引用赋予各个对象，使用autowire来配置自动装载模式。 在Spring框架xml中共有5种自动装配： no：默认的方式是不进行自动装配，通过手工设置ref属性来进行装配bean。 byName：通过bean的名称进行自动装配，如果一个bean的property与另一bean的name相同，就进行自动装配。 byType：通过参数的数据类型进行自动装配。 constructor：利用构造函数进行装配，并且构造函数的参数通过byType进行装配。 autodetect：自动探测，如果有构造 方法，通过construct的方式自动转配，否则使用byTyre的方式自动装配。 3.16 使用@Autowired注解自动装配的过程是怎样的？使用@Autowired注解来自动装配制定的bean。在使用@Autowired注解之前需要在Spring配置文件中进行配置，&lt;context:annotation-config/&gt;。 在启动spring IoC时，容器自动装载了一个AutowiredAnnotationBeanPostProcessor后置处理器，当容器扫描到@Autowied、@Resource或@Inject时，就会在IoC容器自动查找需要的bean，并装配给该对象的属性。在使用@Autowired时，首先在容器中查询对应类型的bean： 如果查询结果刚好为一个，就讲该bean装配给@Autowired制定的数据 如果查询的结果不止一个，那么@Autowired会根据名称来查找 如果上述查找的结果为空，那么会抛出异常。解决方法是，使用required=false 3.17 自动装配有哪些局限性？自动装配的局限性是： 重写：你仍需用配置来定义依赖，意味着总要重写自动装配 基本数据类型：不能 自动装配简单的属性，如基本数据类型、String字符串和类 模糊特性：自动装配不如显示装配精确，如果有可能，建议使用显示装配 3.18 可以在Spring中注入一个null和一个空字符串吗？可以 4. Spring 注解4.1 什么是基于java的Spring注解配置？给一些注解的例子基于Java的配置，允许我们在少量的Java注解的帮助下，进行你的大部分SPring配置而非通过XML文件。 以@Configuration注解为例，它用来标记类可以当做一个bean的定义，被Spring IoC容器使用 另外一个例子是@Bean注解，它表示此方法将要返回一个对象，作为一个bean注册进Spring应用上下文中。 @Configuration public class StudentConfig { @Bean public StudentBean myStudent() { return new StudentBean(); } } 4.2 怎样开启注解装配？注解装配在默认情况下是不开启的，为了使用注解装配，我们必须在Spring配置文件中配置&lt;context:annotation-config/&gt;元素。 4.3 @Component, @Controller, @Repository, @Service 有何区别？@Component：它将java类标记为bean。它是任何Spring管理组件的通用构造性。Spring的组件扫描机制现在可以将其拾取并将其拉入应用程序环境中。 @Controller：这将一个类标记为Spring Web MVC控制器。标有它的bean会自动导入到IoC容器中。 @Repository：这个注解是具有类似用途和功能的@Component注解的特化。它为DAO提供了额外的好处。它将DAO导入IoC容器，并使未经检查的异常有资格转换为Spring DataAccessException。 @Service：此注解是组件注解的特化。它不会对@Component注解提供任何其他行为。可以在服务层类中使用@Service 而不是@Component，因为它以更好的方式指定了意图。 4.4 @Required 注解有什么作用？这个注解表明bean的属性必须在配置的时候设置，通过一个bean定义的显式的属性值或通过自动装配，若@Required注解的bean属性未被设置，容器将抛出BeanInitializationException。 示例： public class Employee { private String name; @Required public void setName(String name){ this.name=name; } public string getName(){ return name; } } 4.5 @Autowired 注解有什么作用?@Autowired默认是按照类型装配注入的，默认情况下它要求依赖对象必须存在（可以设置它required属性为false）。@Autowired 注解提供了更细粒度的控制，包括在何处以及如何完成自动装配。它的用法和@Required一样，修饰setter方法、构造器、属性或者具有任意名称和/或多个参数的PN方法。 public class Employee { private String name; @Autowired public void setName(String name) { this.name=name; } public string getName(){ return name; } } 4.6 @Autowired和@Resource之间的区别@Autowired可用于：构造函数、成员变量、Setter方法 @Autowired和@Resource之间的区别 @Autowired默认是按照类型装配注入的，默认情况下它要求依赖对象必须存在（可以设置它required属性为false）。 @Resource默认是按照名称来装配注入的，只有当找不到与名称匹配的bean才会按照类型来装配注入。 4.7 @Qualifier 注解有什么作用当您创建多个相同类型的 bean 并希望仅使用属性装配其中一个 bean 时，您可以使用@Qualifier 注解和 @Autowired 通过指定应该装配哪个确切的 bean 来消除歧义。 4.8 @RequestMapping 注解有什么用？@RequestMapping 注解用于将特定 HTTP 请求方法映射到将处理相应请求的控制器中的特定类/方法。此注释可应用于两个级别： 类级别：映射请求的 URL 方法级别：映射 URL 以及 HTTP 请求方法 5. Spring数据访问5.1 请解释对象/关系映射集成模块Spring 通过提供ORM模块，支持我们在直接JDBC之上使用一个对象/关系映射映射(ORM)工具，Spring 支持集成主流的ORM框架，如Hiberate，JDO和 iBATIS，JPA，TopLink，JDO，OJB 。Spring的事务管理同样支持以上所有ORM框架及JDBC。 5.2 在Spring框架中如何更有效地使用JDBC？使用Spring JDBC 框架，资源管理和错误处理的代价都会被减轻。所以开发者只需写statements 和 queries从数据存取数据，JDBC也可以在Spring框架提供的模板类的帮助下更有效地被使用，这个模板叫JdbcTemplate。 5.3 解释JDBC抽象和DAO模块通过使用JDBC抽象和DAO模块，保证数据库代码的简洁，并能避免数据库资源错误关闭导致的问题，它在各种不同的数据库的错误信息之上，提供了一个统一的异常访问层。它还利用Spring的AOP 模块给Spring应用中的对象提供事务管理服务。 5.4 spring DAO 有什么用？Spring DAO（数据访问对象） 使得 JDBC，Hibernate 或 JDO 这样的数据访问技术更容易以一种统一的方式工作。这使得用户容易在持久性技术之间切换。它还允许您在编写代码时，无需考虑捕获每种技术不同的异常。 5.5 spring JDBC API 中存在哪些类？JdbcTemplate SimpleJdbcTemplate NamedParameterJdbcTemplate SimpleJdbcInsert SimpleJdbcCall 5.6 JdbcTemplate是什么JdbcTemplate 类提供了很多便利的方法解决诸如把数据库数据转变成基本数据类型或对象，执行写好的或可调用的数据库操作语句，提供自定义的数据错误处理。 5.7 使用Spring通过什么方式访问Hibernate？使用 Spring 访问 Hibernate 的方法有哪些？在Spring中有两种方式访问Hibernate： 使用 Hibernate 模板和回调进行控制反转 扩展 HibernateDAOSupport 并应用 AOP 拦截器节点 5.8 如何通过HibernateDaoSupport将Spring和Hibernate结合起来？用Spring的 SessionFactory 调用 LocalSessionFactory。集成过程分三步： 配置the Hibernate SessionFactory 继承HibernateDaoSupport实现一个DAO 在AOP支持的事务中装配 5.9 Spring支持的事务管理类型， spring 事务实现方式有哪些？Spring支持两种类型的事务管理：编程式事务管理：这意味你通过编程的方式管理事务，给你带来极大的灵活性，但是难维护。声明式事务管理：这意味着你可以将业务代码和事务管理分离，你只需用注解和XML配置来管理事务。 5.10 Spring事务的实现方式和实现原理Spring事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。真正的数据库层的事务提交和回滚是通过binlog或者redo log实现的。 5.11 说一下Spring的事务传播行为spring事务的传播行为说的是，当多个事务同时存在的时候，spring如何处理这些事务的行为。 PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。 PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。 PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 OPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 OPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。 5.12 说一下 spring 的事务隔离？spring 有五大隔离级别，默认值为ISOLATION_DEFAULT（使用数据库的设置），其他四个隔离级别和数据库的隔离级别一致： ISOLATION_DEFAULT：用底层数据库的设置隔离级别，数据库设置的是什么我就用什么； ISOLATION_READ_UNCOMMITTED：未提交读，最低隔离级别、事务未提交前，就可被其他事务读取（会出现幻读、脏读、不可重复读）； ISOLATION_READ_COMMITTED：提交读，一个事务提交后才能被其他事务读取到（会造成幻读、不可重复读），SQL server 的默认级别； ISOLATION_REPEATABLE_READ：可重复读，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止读取到别的事务未提交的数据（会造成幻读），MySQL 的默认级别； ISOLATION_SERIALIZABLE：序列化，代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。 脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。比如，某个事务尝试插入记录 A，此时该事务还未提交，然后另一个事务尝试读取到了记录 A。 *不可重复读 *：是指在一个事务内，多次读同一数据。 幻读 ：指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了。 5.13 Spring框架的事务管理有哪些优点？ 为不同的事务API 如 JTA，JDBC，Hibernate，JPA 和JDO，提供一个不变的编程模式。 为编程式事务管理提供了一套简单的API而不是一些复杂的事务API 支持声明式事务管理。 和Spring各种数据访问抽象层很好得集成。 5.14 你更倾向用那种事务管理类型？大多数Spring框架的用户选择声明式事务管理，因为它对应用代码的影响最小，因此更符合一个无侵入的轻量级容器的思想。声明式事务管理要优于编程式事务管理，虽然比编程式事务管理（这种方式允许你通过代码控制事务）少了一点灵活性。唯一不足地方是，最细粒度只能作用到方法级别，无法做到像编程式事务那样可以作用到代码块级别。 6. Spring面向切面编程(AOP)6.1 什么是AOPOOP(Object-Oriented Programming)面向对象编程，允许开发者定义纵向的关系，但并适用于定义横向的关系，导致了大量代码的重复，而不利于各个模块的重用。 AOP(Aspect-Oriented Programming)，一般称为面向切面编程，作为面向对象的一种补充，用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，这个模块被命名为“切面”（Aspect），减少系统中的重复代码，降低了模块间的耦合度，同时提高了系统的可维护性。可用于权限认证、日志、事务处理等。 6.2 Spring AOP and AspectJ AOP 有什么区别？AOP 有哪些实现方式？AOP实现的关键在于 代理模式，AOP代理主要分为静态代理和动态代理。静态代理的代表为AspectJ；动态代理则以Spring AOP为代表。 （1）AspectJ是静态代理的增强，所谓静态代理，就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强，他会在编译阶段将AspectJ(切面)织入到Java字节码中，运行的时候就是增强之后的AOP对象。 （2）Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是每次运行时在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 6.3 JDK动态代理和CGLIB动态代理的区别Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理： JDK动态代理只提供接口的代理，不支持类的代理。核心InvocationHandler接口和Proxy类，InvocationHandler 通过invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；接着，Proxy利用 InvocationHandler动态创建一个符合某一接口的的实例, 生成目标类的代理对象。 如果代理类没有实现 InvocationHandler 接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现AOP。CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 静态代理与动态代理区别在于生成AOP代理对象的时机不同，相对来说AspectJ的静态代理方式具有更好的性能，但是AspectJ需要特定的编译器进行处理，而Spring AOP则无需特定的编译器处理。 InvocationHandler 的 invoke(Object proxy,Method method,Object[] args)：proxy是最终生成的代理实例; method 是被代理目标实例的某个具体方法; args 是被代理目标实例某个方法的具体入参, 在方法反射调用时使用。 6.4 如何理解 Spring 中的代理？将 Advice 应用于目标对象后创建的对象称为代理。在客户端对象的情况下，目标对象和代理对象是相同的。 Advice + Target Object = Proxy 6.5 解释一下Spring AOP里面的几个名词（1）切面（Aspect）：切面是通知和切点的结合。通知和切点共同定义了切面的全部内容。 在Spring AOP中，切面可以使用通用类（基于模式的风格） 或者在普通类中以 @AspectJ 注解来实现。 （2）连接点（Join point）：指方法，在Spring AOP中，一个连接点 总是 代表一个方法的执行。 应用可能有数以千计的时机应用通知。这些时机被称为连接点。连接点是在应用执行过程中能够插入切面的一个点。这个点可以是调用方法时、抛出异常时、甚至修改一个字段时。切面代码可以利用这些点插入到应用的正常流程之中，并添加新的行为。 （3）通知（Advice）：在AOP术语中，切面的工作被称为通知。 （4）切入点（Pointcut）：切点的定义会匹配通知所要织入的一个或多个连接点。我们通常使用明确的类和方法名称，或是利用正则表达式定义所匹配的类和方法名称来指定这些切点。 （5）引入（Introduction）：引入允许我们向现有类添加新方法或属性。 （6）目标对象（Target Object）： 被一个或者多个切面（aspect）所通知（advise）的对象。它通常是一个代理对象。也有人把它叫做 被通知（adviced） 对象。 既然Spring AOP是通过运行时代理实现的，这个对象永远是一个 被代理（proxied） 对象。 （7）织入（Weaving）：织入是把切面应用到目标对象并创建新的代理对象的过程。在目标对象的生命周期里有多少个点可以进行织入： 编译期：切面在目标类编译时被织入。AspectJ的织入编译器是以这种方式织入切面的。 类加载期：切面在目标类加载到JVM时被织入。需要特殊的类加载器，它可以在目标类被引入应 用之前增强该目标类的字节码。AspectJ5的加载时织入就支持以这种方式织入切面。 运行期：切面在应用运行的某个时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象动态地创建一个代理对象。SpringAOP就是以这种方式织入切面。 6.6 Spring在运行时通知对象通过在代理类中包裹切面，Spring在运行期把切面织入到Spring管理的bean中。代理封装了目标类，并拦截被通知方法的调用，再把调用转发给真正的目标bean。当代理拦截到方法调用时，在调用目标bean方法之前，会执行切面逻辑。 直到应用需要被代理的bean时，Spring才创建代理对象。如果使用的是ApplicationContext的话，在ApplicationContext从BeanFactory中加载所有bean的时候，Spring才会创建被代理的对象。因为Spring运行时才创建代理对象，所以我们不需要特殊的编译器来织入SpringAOP的切面。 6.7 Spring只支持方法级别的连接点因为Spring基于动态代理，所以Spring只支持方法连接点。Spring缺少对字段连接点的支持，而且它不支持构造器连接点。方法之外的连接点拦截功能，我们可以利用Aspect来补充。 6.8 在Spring AOP 中，关注点和横切关注的区别是什么？在 spring aop 中 concern 和 cross-cutting concern 的不同之处关注点（concern）是应用中一个模块的行为，一个关注点可能会被定义成一个我们想实现的一个功能。 横切关注点（cross-cutting concern）是一个关注点，此关注点是整个应用都会使用的功能，并影响整个应用，比如日志，安全和数据传输，几乎应用的每个模块都需要的功能。因此这些都属于横切关注点。 6.9 Spring通知有哪些类型？在AOP术语中，切面的工作被称为通知，实际上是程序执行时要通过SpringAOP框架触发的代码段。 Spring切面可以应用5种类型的通知： 前置通知（Before）：在目标方法被调用之前调用通知功能； 后置通知（After）：在目标方法完成之后调用通知，此时不会关心方法的输出是什么； 返回通知（After-returning ）：在目标方法成功执行之后调用通知； 异常通知（After-throwing）：在目标方法抛出异常后调用通知； 环绕通知（Around）：通知包裹了被通知的方法，在被通知的方法调用之前和调用之后执行自定义的行为。 同一个aspect，不同advice的执行顺序：没有异常情况下的执行顺序：around before advicebefore advicetarget method 执行around after adviceafter adviceafterReturning 有异常情况下的执行顺序： around before advicebefore advicetarget method 执行around after adviceafter adviceafterThrowing:异常发生java.lang.RuntimeException: 异常发生 6.10 什么是切面 Aspect？aspect 由 pointcount 和 advice 组成，切面是通知和切点的结合。 它既包含了横切逻辑的定义, 也包括了连接点的定义. Spring AOP 就是负责实施切面的框架, 它将切面所定义的横切逻辑编织到切面所指定的连接点中.AOP 的工作重心在于如何将增强编织目标对象的连接点上, 这里包含两个工作: 如何通过 pointcut 和 advice 定位到特定的 joinpoint 上 如何在 advice 中编写切面代码. 可以简单地认为, 使用 @Aspect 注解的类就是切面. 6.11 解释基于XML Schema方式的切面实现在这种情况下，切面由常规类以及基于XML的配置实现。 6.12 解释基于注解的切面实现在这种情况下(基于@AspectJ的实现)，涉及到的切面声明的风格与带有java5标注的普通java类一致。 6.13 有几种不同类型的自动代理？BeanNameAutoProxyCreator DefaultAdvisorAutoProxyCreator Metadata autoproxying document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://fyvan.github.io/tags/Spring/"}],"author":"fyang"},{"title":"Tomcat面试整理","slug":"Interview-性能优化专题-Tomcat","date":"2020-06-13T00:46:31.457Z","updated":"2020-06-18T08:16:14.061Z","comments":true,"path":"undefined/1529.html","link":"","permalink":"http://fyvan.github.io/undefined/1529.html","excerpt":"","text":"性能优化专题1 tomcat性能优化1.1 你怎样给tomcat调优 JVM参数调优 JVM中-Xms&lt;size&gt;表示JVM初始化堆的大小,-Xmx&lt;size&gt;表示JVM堆的最大值.这两和值的大小一般根据需要进行设置.当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存移除,并且导致应用服务崩溃.因此一般建议堆的最大值设置为可用内存的最大值的80%.在catalina.bat中,设置JAVA_OPTS='-Xms256m-Xmx512m',表示初始化内存为256MB,可以使用的最大内存为512MB. 禁用DNS查询 当web应用程序想要记录客户端的信息时,它也会记录客户端的IP地址或者通过域名服务器查找机器名转换为IP地址.DNS查询需要占用网络,并且包括可能从很多很远的服务器或者不起作用的服务器上去获取对应的IP的过程,这样会消耗颐堤港的时间.为了消除DNS查询对性能的影响,我们可以关闭DNS查询,方式时修改server.xml文件中的enableLookups参数值: &lt;Connector className=\"org.apache.coyote.tomcat4.CoyoteConnector\"port=\"80\" minProcessors=\"5\"maxProcessors=\"75\"enableLookups=\"false\"redire ctPort=\"8443\" acceptCount=\"100\"debug=\"0\"connectionTimeout=\"20000\" useURIValidationHack=\"false\"disableUploadTimeout=\"true\"/> Tomcat5 &lt;Connectorport=\"80\"maxThreads=\"150\"minSpareThreads=\"25\" maxSpareThreads=\"75\"enableLookups=\"false\"redirectPort=\"8443\" acceptCount=\"100\"debug=\"0\"connectionTimeout=\"20000\" disableUploadTimeout=\"true\"/> 调整线程数 通过应用程序的连接器(Connector)进行性能控制的参数是创建的处理请求的线程数.Tomcat使用线程池加速响应速度来处理请求. 在Java中线程是程序运行时的路径, 是在一个程序中与其他控制线程无关的, 能够独立运行的代码段. 他们共享相同的地址空间. 多线程帮助程序员写出CPU最大利用率的高效程序,使空闲时间保持最低,从而接受更多的请求. Tomcat4中可以通过修改minProcessors和maxProcessors的值来控制线程数. 这些值在安装后就已经设定为默认值并且是足够使用的, 但是随着站点的扩容而改大这些值. minProCessors服务器启动时创建的处理请求的线程数应该足够处理一个小量的负载. 也就是说, 如果一天内每秒仅发生5次单击时间, 并且每个请求任务处理需要1秒中, 那么预先设置线程数为5就足够了. 但在你的站点访问量较大时就需要设置更大的线程数, 指定为参数maxProcessors的值.maxProcessors的值也是有上限的, 应防止流量不可控制(或者恶意的服务攻击),应同时加大这两盒参数. web server允许的最大连接数还受制于操作徐通的内核参数设置,通常Windows是2000个左右,Linux是1000个左右. 在 Tomcat5 对这些参数进行了调整，请看下面属性: maxThreads Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程数。 acceptCount指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。 connnection Timeout 网络连接超时，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。 minSpareThreadsTomcat 初始化时创建的线程数。 maxSpareThreads 一旦创建的线程超过这个值，Tomcat 就会关闭不再需要的 socket线程。 最好的方式是多设置几次并且进行测试，观察响应时间和内存使用情况。在不同的机器、操作系统或虚拟机组合的情况下可能会不同，而且并不是所有人的web站点的流量都是一样的，因此没有一刀切的方案来确定线程数的值。 1.2 如何加大Tomcat连接数在tomcat配置文件 server.xml中的＜Connector/&gt;配置中，和连接数相关的参数有： minProcessors:最小空闲连接线程数，用于提高系统处理性能，默认值为10 maxProcessors:最大连接线程数，即：并发处理的最大请求数，默认值为75 acceptCount:允许的最大连接数，应大于等于maxprocessors,默认值为100 enableLookups:是否反查域名，取值为：true或false.为了提高处理能 力，应设置为false connectionTimeout:网络连接超时，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000 毫秒。 其中和最大连接数相关的参数为maxProcessors和acceptCount.如果要加大并发连接数，应同时加大这两个参数。web server允许的最大连接数还受制于操作系统的内核参数设置，通常Windows是2000个左右，Linux是1000个左右。 tomcat5中的配置示例： &lt;Connectorport=\"8080\" maxThreads=\"150\"minSpareThreads=\"25\"maxSpareThreads=\"75\" enableLookups=\"false\"redirectPort=\"8443\"acceptCount=\"100\" debug=\"0\"connectionTimeout=\"20000\" disableUploadTimeout=\"true\"/> 对于其他端口的侦听配置，以此类推。 1.3、怎样加大tomcat的内存首先检查程序有没有限入死循环,这个问题主要还是由这个问题 java.lang.Out0fMemoryError:Java heap space引起的。第一次出现这样的的问题以后，引发了其他的问题。在网上一查可能是JAVA的堆栈设置太小的原因。 跟据网上的答案大致有这两种解决方法： 1、设置环境变量 解决方法：手动设置 Heap size 修改`` TOMCAT_ HOME/bin/catalina.shsetJAVA OPTS=-Xms32m-Xmx512m` 可以根据自己机器的内存进行更改。 2、``java-Xms32m-Xmx800m className` 就是在执行JAVA类文件时加上这个参数，其中className是需要执行的确类名。（包括包名）这个解决问题了。而且执行的速度比没有设置的时候快很多。如果在测试的时候可能会用Eclispe这时候就需要在 Eclipse-&gt;run-arguments中的VM arguments 中输入－Xms32m-Xmx800m 这个参数就可以了。 后来在Eclilpse中修改了启动参数，在VMarguments加入了－Xms32m-Xmx800m, 问题解决。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://fyvan.github.io/tags/Tomcat/"}],"author":"fyang"},{"title":"JVM面试整理","slug":"Interview-性能优化专题-JVM","date":"2020-06-10T11:30:08.440Z","updated":"2020-06-18T14:57:12.168Z","comments":true,"path":"undefined/1529.html","link":"","permalink":"http://fyvan.github.io/undefined/1529.html","excerpt":"","text":"JVM性能优化1 Java类加载过程Java类加载需要经历以下7个过程: 加载 加载是类加载的第一个过程,在这个阶段,将完成以下三件事情: 通过一个类的全限定名获取该类的二进制流 将该二进制流中的静态存储结构转化为方法去运行时的数据结构 在内存中生成该类的Class对象,作为该类的数据访问入口 验证 验证的目的是为了确保Class文件的字节流中的信息不会危害到虚拟机, 在该阶段主要完成以下四种验证: 文件格式验证验证字节流是否符合Class文件规范,如主次版本号是否在当前虚拟机范围内,常量池中的常量是否有不被支持的类型. 元数据验证对字节码描述的信息进行语义分析,如这个类是否有父类,是否继承了不被继承的类等 字节码验证是整个验证过程中最复杂的一个阶段,通过验证数据流和控制流的分析,确定程序语义是否正确, 主要针对方法体的验证. 如: 方法中的类型转换是否正确,跳转指令是否正确等. 符号引用验证 这个动作在后面的解析过程中发生, 主要是为了确保解析动作能正确执行 准备 准备阶段是为类的静态变量分配内存并将其初始化为默认值,这些内存都将在方法区中进行分配. 准备阶段不分配类中的实例变量的内存,实例变量将会在对象实例化时随着对象一起分配在Java堆中. public static int value=123;//在初始化阶段才会变为123 解析 该阶段主要完成符号引用到直接引用的转换动作. 解析动作并不一定在初始化动作完成之前, 也有可能在初始化之后. 初始化 初始化时类加载的最后一步, 前面的类加载过程, 除了在加载阶段用户应用程序可以通过自定义类加载器参与之外, 其余动作完全由虚拟机主导和控制. 到了初始化阶段, 才真正开始执行类中的定义的java程序代码. 使用 卸载 2 Java内存分配 寄存器: 我们无法控制 静态域: static定义的静态成员 常量池: 编译时被确定保存在.class文件中的(final)常量值和一些文本修饰的符号引用(类和接口的全限定名, 字段的名称和描述符, 方法的名称和描述符) 非RAM存储: 硬盘等永久存储空间 堆内存: new创建的对象和数组, 由Java虚拟机自动垃圾回收器管理,存取速度慢. 栈内存: 基本类型的变量和对象的引用变量(堆内存空间的访问地址), 速度快,可以共享, 但是大小与生命周期必须确定,缺乏灵活性. Java堆的结构是什么样子的? 什么是堆中的永久代(Perm Genspace)? JVM的堆是运行时数据区, 所有类的实例和数组都是在堆上分配内存. 它在JVM启动的时候被创建. 对象所占的堆内存是由自动内存管理系统也就是垃圾收集器回收. 堆内存是由存活和死亡的对象组成的.存活的对象是应用可以访问的,不会被垃圾回收.死亡的对象是应用不可访问尚且还没有被垃圾收集器回收掉的对象. 一直到垃圾收集器把这些对象回收掉之前,他们会一直占据堆内存空间. 3 描述以下JVM加载Class文件的原理机制?Java语言是一种具有动态性的解释型语言,类(Class)只有被加载到JVM后才能运行. 当运行指定程序时, JVM会将编译生成的.class文件按照需求和一定的规则加载到内存中,并组织成为一个完整的Java应用程序.这个加载过程是由类加载器完成,具体来说,就是由ClassLoader和它的子类来实现的. 类加载器本身也是一个类, 其实质是把类文件从硬盘读取到内存中. 类的加载方式分为隐式加载和显示加载. 隐式加载指的是程序在使用new 等方式创建对象时, 会隐式的调用类的加载器把对应的类加载到JVM中. 显示加载指的是通过直接调用class.forName()方法来把所需的类加载到JVM中. 任何一个工程项目都是由许多类组成的,当程序启动时, 只把需要的类加载到JVM中, 其他类只有被使用到的时候才会被加载, 采用这种方法一方面可以加快加载速度, 另一方面可以节约程序运行时对内存的开销. 此外, 在Java语言中, 每个类或接口都对应一个.class文件,这些文件可以堪称是一个个可以被动态加载的单元, 因此当只有部分类被修改时, 只需要重新编译变化的类即可, 而不需要重新编译所有文件, 因此加快了编译速度. 在Java语言中, 类的加载是动态的, 它并不会一次性将所有的类全部加载后再运行, 而是保证程序运行的基础类(例如基类)完成加载到JVM中, 至于其他类, 则再需要的时候才加载. 类加载的主要步骤: 装载: 根据查找路径找到响应的class文件, 然后导入 链接: 链接又可分为3个小步: 检查: 检查待加载的class文件的正确性 准备: 给类中的静态变量分配存储空间 解析: 将符号引用转换为直接引用(可选) 初始化: 对静态变量和静态代码块执行初始化从左. 4 GC是什么? 为什么要有GC?GC是垃圾收集的意思(GabageCollection), 内存处理是编程人员容易出现问题的地方, 忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃, Java提供的GC功能可以自动检测对象是否超过作用域从而达到自动回收内存的目的,Java语言没有提供释放已分配内存的显示操作方法. 5 简述Java垃圾回收机制在Java中, 程序员是不需要显示的去释放一个对象的内存的, 而是由虚拟机自行执行. 在JVM中, 只有一个垃圾回收线程, 它是低优先级的, 在正常情况下是不会执行的, 只有在虚拟机空闲或者当前堆内存不足时,才会触发执行, 扫描哪些没有被任何引用的对象, 并将它们添加到要回收的集合中, 进行回收. 6 如何判断一个对象是否存活?(或者GC对象的判定方法)判断一个对象是否存活有两种方法: 引用计数法 所谓引用技术法就是给每一个对象设置一个引用技术器, 每当有一个地方引用这个对象时, 就将计数器+1,引用失效时, 计数器就-1. 当一个对下那个的引用计数器为零时,说明此对象没有被引用, 也就是”死对象”, 将会进行垃圾回收. 引用计数法有一个缺陷就是无法解决循环引用问题, 也就是说当对象A引用对象B, 对象B又引用着对象A,那么此时A , B对象的引用计数器都不为零, 也就法务完成垃圾回收, 所以主流的虚拟机都没有采用这种算法. 可达性算法(引用链法) 该算法的思想是: 从一个被称为GC Roots的对象开始向下搜索, 如果一个对象到GC Roots没有任何引用链相连时,则说明此对象不可用. 在Java中可以作为GC Roots的对象有以下几种: 虚拟机栈引用的对象 方法区类静态属性引用的对象 方法区常量池引用的对象 本地方法栈JNI引用的对象 虽然这些算法可以判定一个对象是否能被回收, 但是当满足上述条件时,一个对象并不一定会被回收. 当一个对象不可达 GC Roots时, 这个对象并不会被立即回收, 而是出于一个死缓的阶段, 若要被真正的回收需要经历两次标记. 如果对象在可达性分析中没有与GC Roots的引用链, 那么此时就会被第一次标记并且进行一次筛选, 筛选的条件是: 是否有必要执行finalize()方法. 当对象没有覆盖finalize()方法或者已经被虚拟机调用过,那么就认为是没必要的; 如果该对象有必要执行finalize()方法, 那么这个对象将会放在一个成为F-Queue的队列中, 虚拟机会触发一个Finalize()线程去执行, 此线程是低优先级的, 并且虚拟机不会承诺一直等待它运行完, 这是因为如果finalize()执行缓慢或者发生了死锁, 那么就会造成F-Queue中的队形进行第二次被标记,这是该对象将被移出”即将回收”集合, 等待回收. 7 垃圾回收的优点和原理. 并考虑2种回收机制Java语言中一个显著的特点就是引入了垃圾回收机制, 使C++程序员最头疼的内存管理问题迎刃而解, 它使得Java程序员在编写程序的时候不需要再考虑内存管理. 由于有个垃圾回收机制, Java肿的对象不再有”作用域”的概念, 只有对象的引用才有”作用域”. 垃圾回收器通常是作为一个单独的低级别的线程运行, 不可预知的情况下对内存堆肿已经死亡的或者长时间没有使用的对象进行清除可回收, 程序员崩实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收. 回收机制有分代复制垃圾回收和标记垃圾回收, 增量垃圾回收 8 垃圾回收器的基本原理是什么?垃圾回收器可以马上回收内存码?有什么办法主动通知虚拟机进行垃圾回收?对于GC来说, 当程序员创建对象时, GC 就开始监控这个对象的地址\\大小以及使用哦个情况. 通常GC采用有向图的方式记录和管理堆(heap)中的所有对象. 通过这种方式确定哪些对象是”可达的”, 哪些对象是”不可达的”. 当GC确定一些对象为”不可达”时,GC就有责任回收这些内存空间. 可以. 通过手动执行System.gc(), 通知GC运行, 但是Java语言规范并不保证GC一定会执行. 9 Java中会存在内存泄漏吗,请简单描述所谓的内存泄露就是指一个不再被程序使用的对象或变量一直被占据再内存中.Java中的有垃圾回收机制,它可以保证一对象不再被引用的时候即对象编程孤儿的时候,对象将自动被垃圾回收器从内存中清除掉. 由于Java使用有向图的方式进行垃圾回收管理, 可以消除引用循环的问题,例如有两盒对象,相互引用,值要他们和根进行是不可达的,那么GC也是可以回收它们的,例如下面的代码可以看到这种情况的内存回收: import java.io.IOException; public class GarbageTest { /** * @param args * @throws IOException */ public static void main(String[] args) throws IOException { // TODO Auto-generated method stub try { gcTest(); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } System.out.println(\"has exited gcTest!\"); System.in.read(); System.in.read(); System.out.println(\"out begin gc!\"); for(inti=0;i { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/tags/JVM/"}],"author":"fyang"},{"title":"项目业务实现","slug":"JT-项目业务实现","date":"2020-06-09T11:07:05.370Z","updated":"2020-06-18T08:17:41.766Z","comments":true,"path":"undefined/af36.html","link":"","permalink":"http://fyvan.github.io/undefined/af36.html","excerpt":"","text":"1. 项目结构:1.1 项目模块: 模块名称 模块功能 打包类型 端口 jt 提供子模块jar包依赖 pom #N/A jt-common 提供子模块需要的工具API jar #N/A jt-manage 提供项目后台管理功能,涉及jsp页面展现 war 8091 jt-web 提供项目前台页面访问 war 8092 jt-sso 主要为jt-web提供用户数据 jar 8093 jt-cart 主要为jt-web提供购物车数据 jar 8094 jt-order 主要为jt-web提供订单数据 jar 8095 1.2 添加公共jar包在jt中的pom.xml文件中添加包依赖: &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.jt.vip&lt;/groupId> &lt;artifactId>jt&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;packaging>pom&lt;/packaging> &lt;!-- Parent标签定义了SpringBoot项目中所有依赖包的版本信息 SSM项目 jar包文件 都是由程序员自己手动添加 3要素,早期项目中版本依赖冲突问题 特别的严重. SpringBoot目的简化配置,实现\"开箱即用\" --> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.2.7.RELEASE&lt;/version> &lt;relativePath /> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;!--ctrl + a + i格式化 --> &lt;properties> &lt;!--指定JDK版本 --> &lt;java.version>1.8&lt;/java.version> &lt;!--指定maven插件版本 --> &lt;maven-jar-plugin.version>3.1.1&lt;/maven-jar-plugin.version> &lt;!--跳过测试类打包 --> &lt;skipTests>true&lt;/skipTests> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;exclusions> &lt;exclusion> &lt;groupId>org.junit.vintage&lt;/groupId> &lt;artifactId>junit-vintage-engine&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;!--添加属性注入依赖 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;/dependency> &lt;!--支持热部署 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-devtools&lt;/artifactId> &lt;/dependency> &lt;!--引入插件lombok 自动的set/get/构造方法插件 --> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;/dependency> &lt;!--引入数据库驱动 --> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;scope>runtime&lt;/scope> &lt;!-- &lt;version>5.1.32&lt;/version> --> &lt;/dependency> &lt;!--springBoot数据库连接 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId> &lt;/dependency> &lt;!--spring整合mybatis-plus --> &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;version>3.2.0&lt;/version> &lt;/dependency> &lt;!--springBoot整合JSP添加依赖 --> &lt;!--servlet依赖 --> &lt;dependency> &lt;groupId>javax.servlet&lt;/groupId> &lt;artifactId>javax.servlet-api&lt;/artifactId> &lt;/dependency> &lt;!--jstl依赖 --> &lt;dependency> &lt;groupId>javax.servlet&lt;/groupId> &lt;artifactId>jstl&lt;/artifactId> &lt;/dependency> &lt;!--使jsp页面生效 --> &lt;dependency> &lt;groupId>org.apache.tomcat.embed&lt;/groupId> &lt;artifactId>tomcat-embed-jasper&lt;/artifactId> &lt;/dependency> &lt;!-- 引入aop支持 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-aop&lt;/artifactId> &lt;/dependency> &lt;!--spring整合redis --> &lt;dependency> &lt;groupId>redis.clients&lt;/groupId> &lt;artifactId>jedis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.data&lt;/groupId> &lt;artifactId>spring-data-redis&lt;/artifactId> &lt;/dependency> &lt;!--添加httpClient jar包 --> &lt;dependency> &lt;groupId>org.apache.httpcomponents&lt;/groupId> &lt;artifactId>httpclient&lt;/artifactId> &lt;/dependency> &lt;!--引入dubbo配置 --> &lt;dependency> &lt;groupId>com.alibaba.boot&lt;/groupId> &lt;artifactId>dubbo-spring-boot-starter&lt;/artifactId> &lt;version>0.2.0&lt;/version> &lt;/dependency> &lt;!--添加Quartz的支持 --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-quartz&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;!--不要添加bulid插件 --> &lt;/project> 1.3 模块父子级关系维护 子级项目通过parent标签标识父子级关系 &lt;parent> &lt;groupId>com.jt.vip&lt;/groupId> &lt;artifactId>jt&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;/parent> 父级项目通过Modules标签委会 &lt;!--通过modules标签标识当前父级项目中有多少个子级工程 --> &lt;modules> &lt;module>jt-common&lt;/module> &lt;module>jt-manage&lt;/module> &lt;/modules> 2. 后台业务2.1 商品列表2.1.1 业务需求管理员点击商品查询时,要求动态跳转页面, 之后采用EasyUI中的表格实现数据的展现 2.1.2 编辑商品对(Item)象package com.jt.pojo; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import com.fasterxml.jackson.annotation.JsonIgnoreProperties; import lombok.Data; import lombok.experimental.Accessors; @JsonIgnoreProperties(ignoreUnknown=true) //表示JSON转化时忽略未知属性 @TableName(\"tb_item\") //指定表的名称 @Data @Accessors(chain=true) public class Item extends BasePojo{ @TableId(type=IdType.AUTO) //标识主键 private Long id; //商品id private String title; //商品标题 private String sellPoint; //商品卖点信息 private Long price; //商品价格 Long > dubbo private Integer num; //商品数量 private String barcode; //条形码 private String image; //商品图片信息 1.jpg,2.jpg,3.jpg private Long cid; //表示商品的分类id private Integer status; //1正常，2下架 //为了满足页面调用需求,添加get方法 public String[] getImages(){ return image.split(\",\"); } } 2.1.3 页面分析以及跳转过程 查询商品操作 查询商品 IndexController @RequestMapping(\"/page/{moduleName}\") public String toModule(@PathVariable(value = \"moduleName\") String moduleName) { return moduleName; //item-list页面 } 列表页面展现 URL:/item/query 商品ID 商品标题 叶子类目 卖点 价格 库存数量 条形码 状态 创建日期 更新日期 页面跳转地址 EasyUI表格数据返回值要求 { \"total\":2000, \"rows\":[ {\"code\":\"A\",\"name\":\"果汁\",\"price\":\"20\"}, {\"code\":\"B\",\"name\":\"汉堡\",\"price\":\"30\"}, {\"code\":\"C\",\"name\":\"鸡柳\",\"price\":\"40\"}, {\"code\":\"D\",\"name\":\"可乐\",\"price\":\"50\"}, {\"code\":\"E\",\"name\":\"薯条\",\"price\":\"10\"}, {\"code\":\"F\",\"name\":\"麦旋风\",\"price\":\"20\"}, {\"code\":\"G\",\"name\":\"套餐\",\"price\":\"100\"} ] } EasyUITable对象 由于EasyUI中的表格数据展现,需要返回特定的json串,所以需要通过VO对象的方式动态转化为JSON. JSON: {“total”:”总记录数”,”rows”:List} @Data @NoArgsConstructor //无参构造 @AllArgsConstructor //全参构造 public class EasyUITable { private Long total; //定义总记录数 private List rows; //定义集合信息 List集合中写的就是用户展现记录 //VO对象在进行数据转化时,必须调用对象的get/set方法 必须是public修饰 } 2.1.4 编辑ItemController@RestController @RequestMapping(\"/item\") public class ItemController { @Autowired private ItemService itemService; /** * 1.url地址:http://localhost:8091/item/query?page=1&amp;rows=50 * 2.参数: page=1&amp;rows=50 * 3.返回值: easyUI表格数据要求 EasyUITable VO对象 */ @RequestMapping(\"/query\") public EasyUITable findItemByPage(int page,int rows) { //在业务层,实现分页处理 return itemService.findItemByPage(page,rows); } } 2.1.5 编辑ItemService@Service public class ItemServiceImpl implements ItemService { @Autowired private ItemMapper itemMapper; /** * 分页sql语句 每页20条 * 第一页: * select * from tb_item limit 0,20; 21个数 取20个 [0,19]下标 * 第二页: * select * from tb_item limit 20,20; 21个数 取20个 [20,39]下标 * 第三页: * select * from tb_item limit 40,20; 21个数 取20个 [40,59]下标 * 第N页: * select * from tb_item limit (page-1)rows,rows; */ @Override public EasyUITable findItemByPage(int page, int rows) { //1.total 记录总数 Integer total = itemMapper.selectCount(null); //2.list 分页之后的结果 手写分页 int start = (page-1)*rows; List&lt;Item> itemList = itemMapper.findItemByPage(start,rows); return new EasyUITable(total, itemList); } } 2.1.5编辑ItemMapper接口public interface ItemMapper extends BaseMapper&lt;Item>{ @Select(\"select * from tb_item order by updated desc limit #{start},#{rows}\") List&lt;Item> findItemByPage(int start, int rows); } 2.1.6 MP方式实现分页-ItemService@Service public class ItemServiceImpl implements ItemService { @Autowired private ItemMapper itemMapper; /** * 原理:指定Page对象之后根据条件查询.返回Page对象. 包含了分页相关的全部数据. * 使用MP方式实现分页 * 1.current 查询页数 * 2.size 查询记录数 */ @Override public EasyUITable findItemByPage(int page, int rows) { //传递Page对象 之后可以动态的获取所有的分页数据 IPage iPage = new Page(page, rows); QueryWrapper queryWrapper = new QueryWrapper(); //降序排列 queryWrapper.orderByDesc(\"updated\"); iPage = itemMapper.selectPage(iPage, queryWrapper); //1.获取记录总数 int total = (int) iPage.getTotal(); List itemList = iPage.getRecords(); return new EasyUITable(total, itemList); } } 2.1.7 编辑MP配置类​ mybatisPlus中的分页,必须添加拦截器. @Configuration //标识配置类 public class MybatisPlusConfig { //将整合对象 ,交给spring容器管理 @Bean public PaginationInterceptor paginationInterceptor() { return new PaginationInterceptor(); } } 2.1.8 数据格式化 引入common.js 实现自己的业务逻辑 实现价格的格式化 1).页面元素分析 formatter是easyUI中特定的属性 价格 2).页面JS // 格式化价格 value是当前的元素信息 formatPrice : function(val,row){ //数据库中的数据缩小100倍 return (val/100).toFixed(2); }, 商品状态格式化 1).页面元素 状态 2).页面JS // 格式化商品的状态 formatItemStatus : function formatStatus(val,row){ if (val == 1){ return '&lt;span style=\"color:green;\">上架&lt;/span>'; } else if(val == 2){ return '&lt;span style=\"color:red;\">下架&lt;/span>'; } else { return '未知'; } }, 2.2 商品类目回显实现2.2.1 页面结构 页面标签定义 叶子类目 页面JS //格式化名称 findItemCatName : function(val,row){ var name; $.ajax({ type:\"get\", url:\"/item/cat/queryItemName\", data:{itemCatId:val}, //传递参数 cache:true, //缓存 async:false, //表示同步 默认的是异步的true dataType:\"text\",//表示返回值参数类型 success:function(data){ name = data; } }); return name; }, 2.2.2 编辑ItemCat@TableName(\"tb_item_cat\") @Data @Accessors(chain = true) public class ItemCat extends BasePojo{ //POJO属性定义全部采用包装类型 切记!!!! 以对象中不为null的属性充当where条件 @TableId(type = IdType.AUTO) private Long id; //主键 private Long parentId; //父级id private String name; //名称 private Integer status; //状态信息 private Integer sortOrder; //排序号 private Boolean isParent; //是否为父级 } 2.2.3编辑ItemCatController@RestController @RequestMapping(\"/item/cat\") public class ItemCatController { @Autowired private ItemCatService itemCatService; /** * 业务需求:根据Id查询商品分类的名称 * 1.url:/item/cat/queryItemName * 2.请求参数:itemCatId * 3.返回值类型: 商品分类名称 */ @RequestMapping(\"/queryItemName\") public String queryItemName(Long itemCatId) { ItemCat itemCat = itemCatService.findItemCatNameById(itemCatId); return itemCat.getName(); } } 2.2.4编辑ItemCatService@Service public class ItemCatServiceImpl implements ItemCatService { @Autowired private ItemCatMapper itemCatMapper; @Override public ItemCat findItemCatNameById(Long itemCatId) { return itemCatMapper.selectById(itemCatId); } } 2.2.5页面数据展现 2.2.6 ajax同步异步问题类目回显用到ajax嵌套请求,如果内层ajax设置为异步状态,会导致部分数据无法回显 所以在ajax嵌套问题,一般情况下会将内层的ajax设置为同步状态. 属性设置:async : false $.ajax({ type:\"get\", url:\"/item/cat/queryItemName\", data:{itemCatId:val}, //传递参数 cache:true, //缓存 async:false, //表示同步 默认的是异步的true dataType:\"text\",//表示返回值参数类型 success:function(data){ name = data; } }); 说明: 如果没有特殊的需求,一般采用默认值 异步操作. 更加友好主流 一般如果使用ajax嵌套内部ajax程序一般是同步状态. 一般条件下ajax的刷新需要直接操作dom元素. 2.3 商品分类实现分析-12.3.1 新增页面跳转流程 树形结构中新增跳转 新增商品 工具栏实现 /*定义工具栏 toolbar */ toolbar: [{ iconCls: 'icon-add', //定义图标样式 text: \"新增\", handler: function(){alert(\"点击工具栏\")} },{ iconCls: 'icon-help', handler: function(){alert('帮助工具栏')} },'-',{ iconCls: 'icon-save', handler: function(){alert('保存工具栏')} }] 列表页面的工具栏 var toolbar = [{ text:'新增', iconCls:'icon-add', //点击按钮的动作 handler:function(){ //类选择器 contains内容选择器 文本 .click()用户手动点击 $(\".tree-title:contains('新增商品')\").parent().click(); } } 页面结构要求 2.3.2 页面弹出框操作 弹出框介绍 $(\"#btn1\").bind(\"click\",function(){ $(\"#win1\").window({ title:\"弹出框\", width:400, height:400, modal:true //这是一个模式窗口，只能点击弹出框，不允许点击别处 }) }) 商品分类目录的弹出框操作 // common.js中的数据要求 .window({ width:'500', height:\"450\", modal:true, closed:true, iconCls:'icon-save', title:'选择类目', onOpen : function(){ ...} 2.3.3 弹出框操作数据结构要求​ 思考:商品分类目录如何展现? ​ 结论:商品分类信息一般分为3级菜单. 并且3级菜单是有父子级关系. 表设计: 通过数据表的创建如何确定父子级关系呢? 表设计解释: 通过父级字段,控制父子级关系. /*1.一级商品分类信息*/ SELECT * FROM tb_item_cat WHERE parent_id=0 /*1.二级商品分类信息*/ SELECT * FROM tb_item_cat WHERE parent_id=495 /*1.三级商品分类信息*/ SELECT * FROM tb_item_cat WHERE parent_id=543 2.4 商品分类实现分析-2-树形结构2.4.1 EasyUI中树形结构 ul标签 EasyUI-树形结构 页面JS创建 &lt;script type=\"text/javascript\"> /*通过js创建树形结构 */ $(function(){ //EasyUI中提供的tree树形函数 $(\"#tree\").tree({ url:\"tree.json\", //加载远程JSON数据 method:\"get\", //请求方式 POST animate:false, //表示显示折叠端口动画效果 checkbox:true, //表述复选框 lines:true, //表示显示连接线 dnd:true, //是否拖拽 onClick:function(node){ //添加点击事件 //控制台 console.info(node); } }); }) &lt;/script> EasyUI中树形结构的格式要求 List—-&gt; [{ \"id\":\"3\", //节点标识符 \"text\":\"吃鸡游戏\", //节点名称 \"state\":\"open\" //节点状态 open/closed } ] 编辑EasyUITree VO对象 @Data @Accessors @NoArgsConstructor @AllArgsConstructor public class EasyUITree { private Long id; //节点ID private String text; //节点名称 private String state; //打开 open/关闭 closed } 2.4.2 页面JS onOpen : function(){ //当窗口打开后执行 var _win = this; $(\"ul\",_win).tree({ url:'/item/cat/list', animate:true, onClick : function(node){ if($(this).tree(\"isLeaf\",node.target)){ // 填写到cid中 _ele.parent().find(\"[name=cid]\").val(node.id); _ele.next().text(node.text).attr(\"cid\",node.id); $(_win).window('close'); if(data &amp;&amp; data.fun){ data.fun.call(this,node); } } } }); }, 2.4.3 页面URL 2.4.4 关闭EasyUITree中异步数加载 2.4.5 编辑ItemCatController/** * url:http://localhost:8091/item/cat/list * 参数: 暂时没有参数 * 返回值: List&lt;EasyUITree>对象 * * 业务说明: * 1.用户第一次查询时展现的是全部的一级目录 没有携带数据 应该制定默认值 * 2.当用户查询子级目录时 ,会携带当前节点的id id=1 * 根据父级查询子级 * * 参数转化注解:@RequestParam * 作用:接收用户参数,并且可以实现数据的转化 * 参数说明: * value/name: 用户传递的参数名称 * boolean required() default true; 是否为必传项 * defaultValue: 设定默认值 * * 说明:如果用户没有传递参数则parentId默认为0,否则使用用户的参数查询子级信息. */ @RequestMapping(\"/list\") public List&lt;EasyUITree> findItemCatList( @RequestParam(value=\"id\",defaultValue=\"0\")Long parentId){ /* * Long parentId = id; if(parentId ==null) { parentId = 0L; } */ return itemCatService.findItemCatList(parentId); } 2.4.6 编辑ItemCatService/** * 数据转化: * List&lt;EasyUITree> VO对象 页面要求返回的数据结果 * List&lt;ItemCat> 数据库记录 * ItemCat对象转化EasyUITree对象 */ @Override public List&lt;EasyUITree> findItemCatList(Long parentId) { //1.根据parentId查询数据库记录 List&lt;ItemCat> catList = findItemCatListByParentId(parentId); List&lt;EasyUITree> treeList = new ArrayList&lt;EasyUITree>(); //2.利用循环的方式实现数据的遍历 for (ItemCat itemCat : catList) { //目的为了封装VO对象 Long id = itemCat.getId(); String text = itemCat.getName(); //获取节点名称 //如果是父级则默认closed,否则open 可以被选中 String state = itemCat.getIsParent() ? \"closed\" : \"open\"; EasyUITree tree = new EasyUITree(id, text, state); //将tree对象封装到List集合中 treeList.add(tree); } return treeList; } private List&lt;ItemCat> findItemCatListByParentId(Long parentId) { QueryWrapper&lt;ItemCat> queryWrapper = new QueryWrapper&lt;ItemCat>(); queryWrapper.eq(\"parent_id\", parentId); return itemCatMapper.selectList(queryWrapper); } 2.4.7 页面展现 2.5 商品后台管理–商品新增2.5.1 商品新增流程 表单提交中,需要进行数据的校验 将表单提交, ajax提交实现数据新增 后台服务器接收用户的请求,实现数据的入库 定义系统级别的返回值的VO对象.控制操作是否正确. 定义全局异常处理机制.实现VO对象的封装 2.5.2 表单页面分析 商品提交按钮 提交 重置 数据的校验 data-options=\"required:true\" 该项为必填项 validType:'length[0,150] 长度的有效性校验(内容描述) data-options=\"min:1,max:99999999,precision:2,required:true\" 取值范围,设定几位小数(价格) 页面JS校验 if(!$('#itemAddForm').form('validate')){ $.messager.alert('提示','表单还未填写完成!'); return ; //当前jS结束 } 2.5.3 数据转化$(\"#itemAddForm [name=price]\").val(XXXX); 赋值操作 $(\"#itemAddForm [name=priceView]\").val() 取值操作 eval(一般都是num) 主要是做算数运算.避免由于string类型导致异常 2.5.4 ajax提交关于ajax参数写法: {“key”:”value”,”key2”:”value2”} “key=value&amp;key2=value2” 常规参数拼接 $(“#itemAddForm”).serialize():该函数的作用就是将整个form表单中的参数实现key=value拼接. $.post(\"/item/save\",$(\"#itemAddForm\").serialize(), function(data){ if(data.status == 200){ $.messager.alert('提示','新增商品成功!'); }else{ $.messager.alert(\"提示\",\"新增商品失败!\"); } }); 2.5.5 系统级VO对象 SysResult@Data @Accessors(chain = true) @NoArgsConstructor @AllArgsConstructor public class SysResult { private Integer status; //标识状态信息 200成功 201失败 private String msg; //提示信息 private Object data; //服务器返回页面数据信息 //编辑公共的API,简化用户的调用 public static SysResult success() { return new SysResult(200, \"操作成功\", null); } public static SysResult success(Object data) { return new SysResult(200, \"操作成功\", data); } public static SysResult success(String msg,Object data) { return new SysResult(200, msg, data); } public static SysResult fail() { return new SysResult(201, \"业务调用失败\", null); } } 2.5.6 商品新增参数分析页面分析: 参数分析: 2.5.7 编辑ItemController/** * 1.url:http://localhost:8091/item/save * 2.参数: form表单提交 * 3.返回值: VO对象 */ @RequestMapping(\"/save\") public SysResult saveItem(Item item) { try { itemService.saveItem(item); return SysResult.success(); } catch (Exception e) { e.printStackTrace(); return SysResult.fail(); //try-catch 必然导致代码可读性差 优化 } } 2.5.8 编辑ItemService@Override @Transactional //控制事务 public void saveItem(Item item) { item.setStatus(1) .setCreated(new Date()) .setUpdated(item.getCreated()); itemMapper.insert(item); } 2.5.9 业务效果 2.6 商品后台管理–商品分类回显2.6.1 业务说明当用户选择商品点击修改按钮时,执行如下的操作流程 点击修改按钮时需要有效性校验 js 实现弹出框操作,并且展现商品修改页面 展现页面的同时,需要实现页面数据的回显. 将商品分类信息进行格式化处理. 修改商品信息之后,完成业务更新. 2.6.2 有效性校验function getSelectionsIds(){ var itemList = $(\"#itemList\"); //.datagrid(\"getSelections\"); easyUI提供的 筛选用户选中的数据 var sels = itemList.datagrid(\"getSelections\"); var ids = []; for(var i in sels){ ids.push(sels[i].id); //为数组添加id值 } ids = ids.join(\",\"); //将数组转化为字符串 1,2,3,4,5 return ids; } //获取用户选中的数据 var ids = getSelectionsIds(); //1,2,3,4,5 id字符串 if(ids.length == 0){ $.messager.alert('提示','必须选择一个商品才能编辑!'); return ; } if(ids.indexOf(',') > 0){ //100,200 $.messager.alert('提示','只能选择一个商品!'); return ; } 2.6.3 弹出框效果 $(\"#itemEditWindow\").window({onLoad :function(){ //回显数据 var data = $(\"#itemList\").datagrid(\"getSelections\")[0]; data.priceView = KindEditorUtil.formatPrice(data.price); $(\"#itemeEditForm\").form(\"load\",data); // 加载商品描述 //_data = SysResult.ok(itemDesc) $.getJSON('/item/query/item/desc/'+data.id,function(_data){ if(_data.status == 200){ //UM.getEditor('itemeEditDescEditor').setContent(_data.data.itemDesc, false); itemEditEditor.html(_data.data.itemDesc); } }); } 2.6.4 商品分类信息回显操作方式: 页面js编辑: /* 考点:jQuery用法 根据cid 动态查询数据,实现数据回显 利用F12开发者工具 选择标签,进行回显 */ var itemCatId = data.cid; $.get(\"/item/cat/queryItemName\",{\"itemCatId\":itemCatId},function(name){ $(\"#itemeEditForm [name=cid]\").siblings(\"span\").text(name); }); 页面效果展现: 2.7 商品后台管理–商品修改2.7.1 页面分析//alert($(\"#itemeEditForm\").serialize()); $.post(\"/item/update\",$(\"#itemeEditForm\").serialize(), function(data){ if(data.status == 200){ $.messager.alert('提示','修改商品成功!','info',function(){ $(\"#itemEditWindow\").window('close'); $(\"#itemList\").datagrid(\"reload\"); }); }else{ $.message.alert(\"提示\",data.msg); } }); 2.7.2 编辑ItemController/** * 商品更新 * 1.url:/item/update * 2.参数:form表单序列化 * 3.返回值:Sysresult对象 */ @RequestMapping(\"/update\") public SysResult updateItem(Item item) { itemService.updateItem(item); return SysResult.success(); } 2.7.3 编辑ItemService@Override public void updateItem(Item item) { //根据主键进行修改. item.setUpdated(new Date()); itemMapper.updateById(item); } 2.7.4 关于jQuery页面取值问题例子: &lt;html> &lt;div id=\"app\" > &lt;input id=\"username\" type=\"text\" value=\"abc\" name=\"username\"/> &lt;a id=\"urlAdd\" href=\"http://xxxxx\">访问地址&lt;/a> &lt;a id=\"urlAdd\" href=\"http://xxxxx\">替换文本信息&lt;/a> &lt;/div> &lt;/html> 1.html()取值; html(\"xxxxxx\")赋值 获取指定元素的html标签,如果元素信息必须由浏览器负责解析 $(\"#app\").html(\"&lt;a href=\"http://xxxxx\">测试地址&lt;/a>\") 2.text() 取值/text(xxxxx); 赋值 $(\"#urlAdd\").text(\"替换文本信息\") 3.val()/val(\"xxxxx\") val一般代表属性值 $(\"#username\").val(); //获取value属性的值 $(\"#username\").val(\"admin123\");//为input标签啊添加value属性值 2.8 商品后台管理–商品删除2.8.1 删除的页面分析页面名称:item-list.jsp { text:'删除', iconCls:'icon-cancel', handler:function(){ //动态获取商品id字符串信息 var ids = getSelectionsIds(); if(ids.length == 0){ $.messager.alert('提示','未选中商品!'); return ; } $.messager.confirm('确认','确定删除ID为 '+ids+' 的商品吗？',function(r){ if (r){ var params = {\"ids\":ids}; $.post(\"/item/delete\",params, function(data){ if(data.status == 200){ $.messager.alert('提示','删除商品成功!',undefined,function(){ $(\"#itemList\").datagrid(\"reload\"); }); }else{ $.messager.alert(\"提示\",data.msg); } }); } }); } 2.8.2 编辑ItemController/** * url:/item/delete * 参数: ids:1001,1002 如果中间有\",\"号 则可以使用数组/可变参数方式接收 * 返回值: SysResult */ @RequestMapping(\"/delete\") public SysResult deleteItems(Long[] ids) { itemService.deleteItems(ids); return SysResult.success(); } 2.8.3 编辑ItemService@Override public void deleteItems(Long[] ids) { List idList = Arrays.asList(ids); //MP方式实现数据删除 //itemMapper.deleteBatchIds(idList); //手动的实现数据删除操作 itemMapper.deleteItems(ids); } 2.8.4 编辑ItemMapper.xml配置文件&lt;mapper namespace=\"com.jt.mapper.ItemMapper\"> &lt;!--留着以后用 --> &lt;delete id=\"deleteItems\"> delete from tb_item where id in ( &lt;foreach collection=\"array\" item=\"id\" separator=\",\"> #{id} &lt;/foreach> ) &lt;/delete> &lt;/mapper> 2.9 商品后台管理–商品上架/下架2.9.1 业务说明如果使用上架 status=1 updated/ 下架 status=2 updated item-list页面分析 方式1:分别发起ajax请求实现业务操作 $.post(\"/item/instock\",params, function(data){ if(data.status == 200){ $.messager.alert('提示','下架商品成功!',undefined,function(){ $(\"#itemList\").datagrid(\"reload\"); }); } }); $.post(\"/item/reshelf\",params, function(data){ if(data.status == 200){ $.messager.alert('提示','上架商品成功!',undefined,function(){ $(\"#itemList\").datagrid(\"reload\"); }); } }); 方式二: 利用 restFul 风格实现上下架业务 $.post(\"/item/updateStatus/1\",params, function(data){ if(data.status == 200){ $.messager.alert('提示','上架商品成功!',undefined,function(){ $(\"#itemList\").datagrid(\"reload\"); }); } }); 2.9.2 编辑ItemController/** * 1.url:http://localhost:8091/item/updateStatus/2 * 2.参数:ids: 1474391963,1001,1002 * 3.返回值结果 SysResult * @return */ @RequestMapping(\"/updateStatus/{status}\") public SysResult updateStatus(@PathVariable int status,Long... ids) { itemService.updateStatus(status,ids); return SysResult.success(); } 2.9.3 编辑ItemService@Override public void updateStatus(int status, Long[] ids) { //1.使用MP的方式实现数据更新 entity 修改修改的数据,updateWrapper Item item = new Item(); item.setStatus(status) .setUpdated(new Date()); UpdateWrapper&lt;Item> updateWrapper = new UpdateWrapper&lt;Item>(); updateWrapper.in(\"id\", Arrays.asList(ids)); itemMapper.update(item, updateWrapper); //2.使用sql的方式进行数据更新 //&lt;update id=\"updateStatus\"> // update tb_item set status = #{status} where id in ( // &lt;foreach collection=\"ids\" item=\"id\" separator=\",\"> // #{id} // &lt;/foreach>) //&lt;/update> //itemMapper.updateStatus(status, new Date(), ids); } 2.9.4 业务效果 2.10 多表操作设计2.10.1 表设计商品进行定义时, tb_item,tb_itemDesc,为了让用户查询的速度更快将商品表数据进行分隔.将商品详情信息单独准备了一张表. 设计: 商品表的主键的值与商品描述表的值相同. 一对一关联 2.10.2 编辑ItemDesc POJO对象在jt-common中添加pojo @Data @Accessors(chain = true) @NoArgsConstructor @AllArgsConstructor @TableName(\"tb_item_desc\") public class ItemDesc extends BasePojo{ @TableId //只设定主键 不能自增 private Long itemId; private String itemDesc; } 2.10.3 编辑ItemMapper public interface ItemDescMapper extends BaseMapper{ } 2.11 富文本编辑器介绍2.11.1KindEditorhttp://kindeditor.net/down.php KindEditor 是一套开源的在线HTML编辑器，主要用于让用户在网站上获得所见即所得编辑效果，开发人员可以用 KindEditor 把传统的多行文本输入框(textarea)替换为可视化的富文本输入框。 KindEditor 使用 JavaScript 编写，可以无缝地与 Java、.NET、PHP、ASP 等程序集成，比较适合在 CMS、商城、论坛、博客、Wiki、电子邮件等互联网应用上使用。 2.11.2入门案例访问网址:http://localhost:8091/KindEditor.jsp &lt;link href=\"/js/kindeditor-4.1.10/themes/default/default.css\" type=\"text/css\" rel=\"stylesheet\"> &lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"/js/kindeditor-4.1.10/kindeditor-all-min.js\">&lt;/script> &lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"/js/kindeditor-4.1.10/lang/zh_CN.js\">&lt;/script> &lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"/js/jquery-easyui-1.4.1/jquery.min.js\">&lt;/script> &lt;script type=\"text/javascript\"> $(function(){ KindEditor.ready(function(){ KindEditor.create(\"#editor\") }) }) &lt;/script> &lt;/head> &lt;body> &lt;h1>富文本编辑器&lt;/h1> &lt;textarea style=\"width:700px;height:350px\" id=\"editor\">&lt;/textarea> &lt;/body> 2.11.3富文本效果 2.12 重构商品新增2.12.1 页面参数分析 页面url地址: 页面参数: 2.12.2 重构ItemController/** * 1.url:http://localhost:8091/item/save * 2.参数: form表单提交 * 3.返回值: VO对象 */ @RequestMapping(\"/save\") public SysResult saveItem(Item item,ItemDesc itemDesc) { /* * try { itemService.saveItem(item); return SysResult.success(); } catch * (Exception e) { e.printStackTrace(); return SysResult.fail(); //try-catch * 必然导致代码可读性差 优化 } */ itemService.saveItem(item,itemDesc); return SysResult.success(); } 2.12.3 重构ItemService说明:MybatisPlus中可以根据入库信息,自动实现映射.返回全部数据. 所以item.getId()才能有值. /** * 用户点击一次提交之后,实现2张表数据,同时入库 * tb_item,tb_itemDesc,id的值应该相同 */ @Override @Transactional //控制事务 public void saveItem(Item item,ItemDesc itemDesc){ //实现tb_item入库 item.setStatus(1) .setCreated(new Date()) .setUpdated(item.getCreated()); itemMapper.insert(item); //主键自增,入库之后,将所有字段自动映射!! //实现tb_itemDesc入库操作 itemDesc.setItemId(item.getId()) .setCreated(item.getCreated()) .setUpdated(item.getUpdated()); itemDescMapper.insert(itemDesc); } 2.12.4 Mybatis主键返回的说明如果没有使用MP,默认条件下Mybatis是不会返回任何信息.如果这时需要使用主键自动的返回,则需要 MP:号称是面向对象的开发,所以事先对象与字段自动映射,自动的回显. insert into 入库操作, 返回主键ID. select * from tb_item where id= #{id} 3. 前台业务 实现购物车商品的添加,以及购物车中商品列表的展现 2.1 构建jt-cart2.1.1 创建jt-cart项目 2.1.2 添加继承/依赖/插件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;parent> &lt;artifactId>jt&lt;/artifactId> &lt;groupId>com.jt.vip&lt;/groupId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;/parent> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>jt-cart&lt;/artifactId> &lt;dependencies> &lt;dependency> &lt;groupId>com.jt.vip&lt;/groupId> &lt;artifactId>jt-common&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;scope>compile&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;!--跳过测试类打包 --> &lt;plugin> &lt;groupId>org.apache.maven.plugins&lt;/groupId> &lt;artifactId>maven-surefire-plugin&lt;/artifactId> &lt;configuration> &lt;skip>true&lt;/skip> &lt;/configuration> &lt;/plugin> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 2.1.3 创建Cart POJO在jt-common中添加pojo对象 @Data @Accessors(chain=true) @TableName(\"tb_cart\") public class Cart extends BasePojo{ @TableId(type=IdType.AUTO) private Long id; //购物车主键 private Long userId; private Long itemId; private String itemTitle; //商品的标题 private String itemImage; //商品图片 private Long itemPrice; //商品价格 private Integer num; //商品数量 } 2.1.4 修改application.yml配置server: port: 8094 servlet: context-path: / spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/jtdb?serverTimezone=GMT%2B8&useUnicode=true&characterEncoding=utf8&autoReconnect=true&allowMultiQueries=true username: root password: root #mybatis-plush配置 mybatis-plus: type-aliases-package: com.jt.pojo mapper-locations: classpath:/mybatis/mappers/*.xml configuration: map-underscore-to-camel-case: true #引入日志信息 logging: level: com.jt.mapper: debug #关于Dubbo配置 dubbo: scan: basePackages: com.jt #扫描dubbo注解的包路径 application: #应用名称 name: provider-cart #一个接口对应一个服务名称, #如果一个接口有多个实现类,则名称也应该相同 registry: address: zookeeper://192.168.126.129:2181?backup=192.168.126.129:2182,192.168.126.129:2183 protocol: #指定协议 name: dubbo #使用dubbo协议(tcp-ip) web-controller直接调用sso-Service #port是dubbo协议内部的通信端口 port: 20881 #每一个服务都有自己特定的端口 不能重复. 2.1.5 构建代码结构 按照dubbo分别在消费者和生产者 在jt-common模块中提供业务接口 在jt-cart模块中提供业务实现–生产者 注意mybatis配置 在jt-cart模块中提供前台页面访问–消费者 2.2 JT-CART购物车展现2.2.1 业务需求当用户点击购物车按钮时,会跳转到购物车的展现页面.需要通过userId查询购物车记录.页面展现的名称为:cart.jsp并且通过${cartList}获取购物车列表信息. jsp代码 ...... 2.2.2编辑CartController(消费者)@Controller @RequestMapping(\"/cart\") public class CartController { @Reference private DubboCartService cartService; /** * 业务需求:展现购物车列表页面 * url: http://www.jt.com/cart/show.html * 参数:无 * 返回值: cart.jsp页面 * 页面取值: ${cartList} */ @RequestMapping(\"/show\") public String findCartList(Model model) { //通过cookie获取用户ID User user = (User) request.getAttribute(\"JT_USER\"); Long userId = user.getId(); List&lt;Cart> cartList = cartService.findCartListByUserId(userId); model.addAttribute(\"cartList\", cartList); return \"cart\"; } } 2.2.3编辑CartService@Service public class DubboCartServiceImpl implements DubboCartService { @Autowired private CartMapper cartMapper; @Override public List&lt;Cart> findCartListByUserId(Long userId) { QueryWrapper&lt;Cart> queryWrapper = new QueryWrapper&lt;Cart>(); queryWrapper.eq(\"user_id\", userId); return cartMapper.selectList(queryWrapper); } } 2.2.4 页面效果 2.3 购物车新增2.3.1 业务分析业务说明: 1.当点击加入购物车时,会将当前商品信息加入购物车.并且跳转到购物车列表页面.同时实现购物车数据的新增操作. 2.注意事项: ​ 如果用户加购的是同一件商品,则只做数量的更新. 2.3.2 页面分析 页面form表单 页面JS提交 //利用post传值 function addCart(){ var url = \"http://www.jt.com/cart/add/${item.id}.html\"; document.forms[0].action = url; //js设置提交链接 document.forms[0].submit(); //js表单提交 } 2.3.3 编辑CartController/** * 购物车新增 * 1.url:http://www.jt.com/cart/add/562379.html * 2.参数: form表单的形式提交 Cart对象接收 * 3.返回值: 重定向到购物车列表页面 * 注意事项:如果购物车中有记录,则更新数量. */ @RequestMapping(\"/add/{itemId}\") //可以自动的为属性赋值 public String saveCart(Cart cart) { //通过cookie获取用户ID User user = (User) request.getAttribute(\"JT_USER\"); Long userId = user.getId(); cart.setUserId(userId); cartService.saveCart(cart); return \"redirect:/cart/show.html\"; } 2.3.4 编辑CartService/** * 如果购物车中有记录,则更新数据 * 问题: 如何判断购物车中是否有记录 user_id/item_id */ @Override @Transactional //事务控制 public void saveCart(Cart cart) { QueryWrapper&lt;Cart> queryWrapper = new QueryWrapper&lt;Cart>(); //使用user_id和item_id作为联合主键进行查询 queryWrapper.eq(\"user_id\", cart.getUserId()) .eq(\"item_id\", cart.getItemId()); Cart cartDB = cartMapper.selectOne(queryWrapper); //应该购物车新增 if(cartDB == null) { cart.setCreated(new Date()) .setUpdated(cart.getCreated()); cartMapper.insert(cart); }else { //更新数据库的数量 int num = cart.getNum() + cartDB.getNum(); cartDB.setNum(num).setUpdated(new Date()); cartMapper.updateById(cartDB); } } 2.3.5 页面效果 2.4 购物车删除2.4.1 业务说明当用户点击购物车删除按钮时.执行删除业务,并且重定向到购物车列表页面. 2.4.2 编辑CartController/** * 购物车删除操作 * 1.url地址:http://www.jt.com/cart/delete/562379.html * 2.参数: 562379 商品id号 * 3.返回值: 重定向到购物车列表页面 */ @RequestMapping(\"/delete/{itemId}\") public String deleteCart(Cart cart) { Long userId = 7L; cart.setUserId(userId); cartService.deleteCart(cart); return \"redirect:/cart/show.html\"; } 2.3.3编辑CartService@Override public void deleteCart(Cart cart) { //MP规则: 根据对象中不为null的属性充当where条件 itemId/userId QueryWrapper&lt;Cart> queryWrapper = new QueryWrapper&lt;Cart>(cart); cartMapper.delete(queryWrapper); } 2.5 购物车商品数量增删4. 全局异常处理机制4.1 业务说明由于业务执行时不能保证程序不出错,所以写代码必须添加try-catch,但是如果频繁的添加try-catch则必然导致代码结构混乱.所以需要进行优化. 原则:如果出现了问题一般将检查异常,转化为运行时异常. 核心原理: 代理动态思想——-&gt;AOP操作 4.2 编辑全局异常处理@RestControllerAdvice //返回值结果都是json字符串 @Slf4j public class SysConfigExceptionAOP { /** * 1.拦截什么样的异常 运行时异常 * 2.返回值结果是什么 系统返回值VO对象 */ @ExceptionHandler(RuntimeException.class) public Object sysResult(Exception exception) { log.error(exception.getMessage()); exception.printStackTrace(); return SysResult.fail(); } } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Project","slug":"Project","permalink":"http://fyvan.github.io/categories/Project/"}],"tags":[{"name":"jt","slug":"jt","permalink":"http://fyvan.github.io/tags/jt/"}],"author":"fyang"},{"title":"Redis常见的性能问题","slug":"Redis常见性能问题","date":"2020-06-09T00:38:57.562Z","updated":"2020-06-18T08:18:32.971Z","comments":true,"path":"undefined/776d.html","link":"","permalink":"http://fyvan.github.io/undefined/776d.html","excerpt":"","text":"Redis 常见的性能问题都有哪些？如何解决？ Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://fyvan.github.io/tags/redis/"}],"author":"fyang"},{"title":"Zookeeper安装与单机集群","slug":"Zookeeper-install-2020-6-6","date":"2020-06-06T11:38:55.668Z","updated":"2020-06-18T08:14:08.565Z","comments":true,"path":"undefined/e6b7.html","link":"","permalink":"http://fyvan.github.io/undefined/e6b7.html","excerpt":"","text":"1 Zookeeper介绍ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 ZooKeeper包含一个简单的原语集,提供Java和C的接口。 ZooKeeper代码版本中，提供了分布式独享锁、选举、队列的接口，代码在zookeeper-3.4.3\\src\\recipes。其中分布锁和队列有Java和C两个版本，选举只有Java版本。 总结:Zookeeper负责服务的协调调度.当客户端发起请求时,返回正确的服务器地址. 2 Zookeeper下载网址: http://zookeeper.apache.org/releases.html;下载路径,点击download. 下载Zookeeper地址. http://mirrors.hust.edu.cn/apache/zookeeper/ 3 Zookeeper安装3.1 安装jdkZooKeeper是用Java编写的，运行在baiJava环境上，du因此，在部署zk的机器上zhi需要安装Java运行环境。dao为了正常运行zk，我们需要JRE1.6或者以上的版本。 将JDK1.8文件上传到Linux操作系统中/src/usr/local/java/文件下. 解压文件 # 解压上传的压缩包xxx.tar.gz tar -xvf jdk-8u51-linux-x64.tar.gz # 重命名 mv jdk.1.8.0_51 jdk.1.8 配置环境变量/etc/profile vim /etc/profile # 添加如下内容 export JAVA_HOME=/usr/local/src/jdk1.8 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib 检查安装是否成功 # 添加完环境变量后,执行下面命令使之生效 source /etc/profile # 查看JDK版本信息 java -version 3.2 安装Zookeeper 上传下载好的安装包到服务器 解压文件 # 解压上传的压缩包xxx.tar.gz tar -xvf apache-zookeeper-3.6.0-bin.tar.gz # 重命名 mv apache-zookeeper-3.6.0-bin zookeeper-3.6.0 修改配置文件 在zookeeper-3.6.0目录下面新建2个文件夹data和log mkdir data log 进入conf目录中修改配置文件zoo_sample.cfg # 复制配置文件并修改名称 cp zoo_sample.cfg zoo.cfg ​ 修改该下面图片中红框中的内容 启动Zookeeper 进入bin目录下, 执行下面命令进行测试 sh zkServer.sh start 或者 ./zkServer.sh start sh zkServer.sh stop sh zkServer.sh status 4. Zookeeper单机集群安装4.1 准备安装文件夹在zookeeper根目录中创建新的集群目录zkCluster. mkdir zkClusters 在集群目录zkCluster中创建节点目录zk1,zk2,zk3,并在每个目录里创建data/log文件夹 mkdir {zk1,zk2,zk3}/{data,log} 4.2 添加myid文件分别在zk1/zk2/zk3中的data文件夹中创建新的文件myid.其中的内容依次为1/2/3,与zk节点号对应. echo \"1\">/usr/local/src/zookeeper-3.6.0/zkClusters/zk1/data/myid echo \"2\">/usr/local/src/zookeeper-3.6.0/zkClusters/zk2/data/myid echo \"3\">/usr/local/src/zookeeper-3.6.0/zkClusters/zk3/data/myid 4.3 编辑配置文件将zoo_sample.cfg 复制为zoo1.cfg之后修改配置文件. dataDir=/usr/local/src/zookeeper-3.6.0/zkClusters/zk1/data dataLogDir=/usr/local/src/zookeeper-3.6.0/zkClusters/zk1/log # the port at which the clients will connect clientPort=2181 server.1=192.168.126.129:2887:3887 server.2=192.168.126.129:2888:3888 server.3=192.168.126.129:2889:3889 配置完成后将zoo1.cfg复制为zoo2.cfg和zoo3.cfg.修改与之对应的节点目录和端口号. 修改zoo2.cgf 修改zoo3.cgf 4.4 集群测试 启动集群 sh zkServer.sh start zoo1.cfg sh zkServer.sh start zoo2.cfg sh zkServer.sh start zoo3.cfg 启动后集群状态 sh zkServer.sh status zoo1.cfg sh zkServer.sh status zoo2.cfg sh zkServer.sh status zoo3.cfg document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"software","slug":"software","permalink":"http://fyvan.github.io/categories/software/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://fyvan.github.io/tags/Zookeeper/"}],"author":"fyang"},{"title":"IDEA使用","slug":"Tool-IDEA","date":"2020-06-03T02:43:43.803Z","updated":"2020-06-18T08:13:59.539Z","comments":true,"path":"undefined/91c5.html","link":"","permalink":"http://fyvan.github.io/undefined/91c5.html","excerpt":"","text":"IDEA开发使用异常处理1. springboot项目访问项目主页出现404 IDEA设置: 添加工作目录 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"software","slug":"software","permalink":"http://fyvan.github.io/categories/software/"}],"tags":[{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"http://fyvan.github.io/tags/IntelliJ-IDEA/"}],"author":"fyang"},{"title":"synchronized原理分析","slug":"Java-synchronized","date":"2020-06-01T11:30:33.608Z","updated":"2020-06-18T08:17:10.495Z","comments":true,"path":"undefined/7ebc.html","link":"","permalink":"http://fyvan.github.io/undefined/7ebc.html","excerpt":"","text":"1. 概念synchronized 是 Java 中的关键字，是利用锁的机制来实现同步的。 锁机制有如下两种特性： 互斥性：即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程中的协调机制，这样在同一时间只有一个线程对需同步的代码块(复合操作)进行访问。互斥性我们也往往称为操作的原子性。 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值），否则另一个线程可能是在本地缓存的某个副本上继续操作从而引起不一致。 2. 对象锁和类锁2.1 对象锁在 Java 中，每个对象都会有一个 monitor 对象，这个对象其实就是 Java 对象的锁，通常会被称为“内置锁”或“对象锁”。类的对象可以有多个，所以每个对象有其独立的对象锁，互不干扰。 2.2 类锁在 Java 中，针对每个类也有一个锁，可以称为“类锁”，类锁实际上是通过对象锁实现的，即类的 Class 对象锁。每个类只有一个 Class 对象，所以每个类只有一个类锁。 3. synchronized的三种应用方式3.1 同步普通方法锁的是当前对象, 进入同步代码块前要获得当前实例的锁 public class AccountingSync implements Runnable{ //共享资源(临界资源) static int i=0; /** * synchronized 修饰实例方法 */ public synchronized void increase(){ i++; } @Override public void run() { for(int j=0;j&lt;1000000;j++){ increase(); } } public static void main(String[] args) throws InterruptedException { AccountingSync instance=new AccountingSync(); Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); //join含义:当前线程A等待thread线程终止之后才能从thread.join()返回 t1.join(); t2.join(); System.out.println(i); } /** * 输出结果: * 2000000 */ } 上述代码中，我们开启两个线程操作同一个共享资源即变量i，由于i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全。此时我们应该注意到synchronized修饰的是实例方法increase，在这样的情况下，当前线程的锁便是实例对象instance，注意Java中的线程同步锁可以是任意对象。 3.2 同步静态方法锁的是当前 Class 对象, 进入同步代码前要获得当前类对象的锁. 由于静态成员不专属于任何一个实例对象，是类成员，因此通过class对象锁可以控制静态 成员的并发操作。 需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁，但我们应该意识到这种情况下可能会发现线程安全问题(操作了共享静态变量i)。 看如下代码 public class AccountingSyncClass implements Runnable{ static int i=0; /** * 作用于静态方法,锁是当前class对象,也就是 * AccountingSyncClass类对应的class对象 */ public static synchronized void increase(){ i++; } /** * 非静态,访问时锁不一样不会发生互斥 */ public synchronized void increase4Obj(){ i++; } @Override public void run() { for(int j=0;j&lt;1000000;j++){ increase(); } } public static void main(String[] args) throws InterruptedException { //new新实例 Thread t1=new Thread(new AccountingSyncClass()); //new新实例 Thread t2=new Thread(new AccountingSyncClass()); //启动线程 t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); } } 3.3 同步代码块指定加锁对象, 锁的是 ( ) 中的对象, 进入同步代码库前要获得给定对象的锁 在某些情况下，我们编写的方法体可能比较大，同时存在一些比较耗时的操作，而需要同步的代码又只有一小部分，如果直接对整个方法进行同步操作，可能会得不偿失，此时我们可以使用同步代码块的方式对需要同步的代码进行包裹，这样就无需对整个方法进行同步操作了，同步代码块的使用示例如下： public class AccountingSync implements Runnable{ static AccountingSync instance=new AccountingSync(); static int i=0; @Override public void run() { //省略其他耗时操作.... //使用同步代码块对变量i进行同步操作,锁对象为instance synchronized(instance){ for(int j=0;j&lt;1000000;j++){ i++; } } } public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); } } 从代码看出，将synchronized作用于一个给定的实例对象instance，即当前实例对象就是锁对象，每次当线程进入synchronized包裹的代码块时就会要求当前线程持有instance实例对象锁，如果当前有其他线程正持有该对象锁，那么新到的线程就必须等待，这样也就保证了每次只有一个线程执行i++;操作。当然除了instance作为对象外，我们还可以使用this对象(代表当前实例)或者当前类的class对象作为锁，如下代码： //this,当前实例对象锁 synchronized(this){ for(int j=0;j&lt;1000000;j++){ i++; } } //class对象锁 synchronized(AccountingSync.class){ for(int j=0;j&lt;1000000;j++){ i++; } } 4. synchronized底层语义原理4.1 JVM层级-synchronized底层语义原理（Hotspot）理解Java对象头与Monitor 在JVM中，对象(new Object())在内存中的布局分为四块区域：对象头、实例数据和对齐填充。如下： mark word和 class pointer表示Java头对象 实例变量: 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。 填充数据: 由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。 而对于顶部，则是Java头对象，它实现synchronized的锁对象的基础. 一般而言，synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class pointer组成，其结构说明如下表： 虚拟机位数 头对象结构 说明 32/64bit Mark Word 存储对象的hashCode、锁信息或分代年龄或GC标志等信息 32/64bit Class pointer 类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例 其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等以下是32位JVM的Mark Word默认存储结构由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，如32位JVM下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构： 其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） ObjectMonitor() { _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示 由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因,有了上述知识基础后，下面我们将进一步分析synchronized在字节码层面的具体语义实现。 4.2 字节码层级-synchronized代码块底层原理JVM 是通过进入、退出对象监视器( Monitor )来实现对方法、同步块的同步的。 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 现在我们重新定义一个synchronized修饰的同步代码块，在代码块中操作共享变量i，如下 public class SyncCodeBlock { public int i; public void syncTask(){ //同步代码库 synchronized (this){ i++; } } } 编译上述代码并使用javap反编译后得到字节码如下(这里我们省略一部分没有必要的信息)： MD5 checksum c80bc322c87b312de760942820b4fed5 Compiled from \"SyncCodeBlock.java\" public class com.zejian.concurrencys.SyncCodeBlock minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: //........省略常量池中数据 //构造函数 public com.zejian.concurrencys.SyncCodeBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init>\":()V 4: return LineNumberTable: line 7: 0 //===========主要看看syncTask方法实现================ public void syncTask(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //注意此处，进入同步方法 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit //注意此处，退出同步方法 16: goto 24 19: astore_2 20: aload_1 21: monitorexit //注意此处，退出同步方法 22: aload_2 23: athrow 24: return Exception table: //省略其他字节码....... } SourceFile: \"SyncCodeBlock.java\" 我们主要关注字节码中的如下代码 3: monitorenter //进入同步方法 //..........省略其他 15: monitorexit //退出同步方法 16: goto 24 //省略其他....... 21: monitorexit //退出同步方法 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令. 其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置. 当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。 如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。 倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。 值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。 为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。 从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 4.3 字节码层级-synchronized方法底层原理方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。 JVM可以从方法常量池中的方法表结构(method_info Structure) 中的ACC_SYNCHRONIZED访问标志区分一个方法是否同步方法。 当方法调用时，调用指令将会 检查方法的ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。 在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。 下面我们看看字节码层面如何实现： public class SyncMethod { public int i; public synchronized void syncTask(){ i++; } } 使用javap反编译后的字节码如下： Last modified 2017-6-2; size 308 bytes MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94 Compiled from \"SyncMethod.java\" public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10 } SourceFile: \"SyncMethod.java\" 从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是``ACC_SYNCHRONIZED`标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 这便是synchronized锁在同步代码块和同步方法上实现的基本原理。 5. Java虚拟机对synchronized的优化在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。 5.1 偏向锁偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。 偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。 但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 5.2 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。 轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 5.3 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。 这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 5.4 锁消除消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。 5.5 锁升级过程 new → 偏向锁 → 轻量级锁 （无锁, 自旋锁，自适应自旋）→ 重量级锁 synchronized优化的过程和markword息息相关 用markword中最低的三位代表锁状态 其中1位是偏向锁位 两位是普通锁位用markword中最低的三位代表锁状态 其中1位是偏向锁位 两位是普通锁位 Object o = new Object()锁 = 0 01 无锁态注意：如果偏向锁打开，默认是匿名偏向状态 o.hashCode()001 + hashcode 00000001 10101101 00110100 00110110 01011001 00000000 00000000 00000000 little endian big endian 00000000 00000000 00000000 01011001 00110110 00110100 10101101 00000000 默认synchronized(o)00 -&gt; 轻量级锁默认情况 偏向锁有个时延，默认是4秒why? 因为JVM虚拟机自己有一些默认启动的线程，里面有好多sync代码，这些sync代码启动时就知道肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作，效率较低。 -XX:BiasedLockingStartupDelay=0 如果设定上述参数new Object () - &gt; 101 偏向锁 -&gt;线程ID为0 -&gt; Anonymous BiasedLock打开偏向锁，new出来的对象，默认就是一个可偏向匿名对象101 如果有线程上锁上偏向锁，指的就是，把markword的线程ID改为自己线程ID的过程偏向锁不可重偏向 批量偏向 批量撤销 如果有线程竞争撤销偏向锁，升级轻量级锁线程在自己的线程栈生成LockRecord ，用CAS操作将markword设置为指向自己这个线程的LR的指针，设置成功者得到锁 如果竞争加剧竞争加剧：有线程超过10次自旋， -XX:PreBlockSpin， 或者自旋线程数超过CPU核数的一半， 1.6之后，加入自适应自旋 Adapative Self Spinning ， JVM自己控制升级重量级锁：-&gt; 向操作系统申请资源，linux mutex , CPU从3级-0级系统调用，线程挂起，进入等待队列，等待操作系统的调度，然后再映射回用户空间 偏向锁默认是打开的，但是有一个时延，如果要观察到偏向锁，应该设定参数 为什么有自旋锁还需要重量级锁？ 自旋锁什么时候升级为重量级锁？ 自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗 重量级锁有等待队列，所有拿不到锁的进入等待队列，不需要消耗CPU资源 偏向锁是否一定比自旋锁效率高？ 不一定，在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁撤销，这时候直接使用自旋锁 JVM启动过程，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开 6 关于synchronized 可能需要了解的关键点6.1 synchronized的可重入性从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。如下： public class AccountingSync implements Runnable{ static AccountingSync instance=new AccountingSync(); static int i=0; static int j=0; @Override public void run() { for(int j=0;j&lt;1000000;j++){ //this,当前实例对象锁 synchronized(this){ i++; increase();//synchronized的可重入性 } } } public synchronized void increase(){ j++; } public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); } } 正如代码所演示的，在获取当前实例对象锁后进入synchronized代码块执行同步代码，并在代码块中调用了当前实例对象的另外一个synchronized方法，再次请求当前实例锁时，将被允许，进而执行方法体代码，这就是重入锁最直接的体现，需要特别注意另外一种情况，当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法。注意由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。 6.2 线程中断与synchronized6.2.1线程中断正如中断二字所表达的意义，在线程运行(run方法)中间打断它，在Java中，提供了以下3个有关线程中断的方法 //中断线程（实例方法） public void Thread.interrupt(); //判断线程是否被中断（实例方法） public boolean Thread.isInterrupted(); //判断是否被中断并清除当前中断状态（静态方法） public static boolean Thread.interrupted(); 当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态)，如下代码将演示该过程： public class InterruputSleepThread3 { public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread() { @Override public void run() { //while在try中，通过异常中断就可以退出run循环 try { while (true) { //当前线程处于阻塞状态，异常必须捕捉处理，无法往外抛出 TimeUnit.SECONDS.sleep(2); } } catch (InterruptedException e) { System.out.println(\"Interruted When Sleep\"); boolean interrupt = this.isInterrupted(); //中断状态被复位 System.out.println(\"interrupt:\"+interrupt); } } }; t1.start(); TimeUnit.SECONDS.sleep(2); //中断处于阻塞状态的线程 t1.interrupt(); /** * 输出结果: Interruted When Sleep interrupt:false */ } } 如上述代码所示，我们创建一个线程，并在线程中调用了sleep方法从而使用线程进入阻塞状态，启动线程后，调用线程实例对象的interrupt方法中断阻塞异常，并抛出InterruptedException异常，此时中断状态也将被复位。这里有些人可能会诧异，为什么不用Thread.sleep(2000);而是用TimeUnit.SECONDS.sleep(2);其实原因很简单，前者使用时并没有明确的单位说明，而后者非常明确表达秒的单位，事实上后者的内部实现最终还是调用了Thread.sleep(2000);，但为了编写的代码语义更清晰，建议使用TimeUnit.SECONDS.sleep(2);的方式，注意TimeUnit是个枚举类型。ok~，除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的，如下代码，将无法中断非阻塞状态下的线程： public class InterruputThread { public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(){ @Override public void run(){ while(true){ System.out.println(\"未被中断\"); } } }; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果(无限执行): 未被中断 未被中断 未被中断 ...... */ } } 虽然我们调用了interrupt方法，但线程t1并未被中断，因为处于非阻塞状态的线程需要我们手动进行中断检测并结束程序，改进后代码如下： public class InterruputThread { public static void main(String[] args) throws InterruptedException { Thread t1=new Thread(){ @Override public void run(){ while(true){ //判断当前线程是否被中断 if (this.isInterrupted()){ System.out.println(\"线程中断\"); break; } } System.out.println(\"已跳出循环,线程中断!\"); } }; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果: 线程中断 已跳出循环,线程中断! */ } } 是的，我们在代码中使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用interrupt()并不会导致中断状态重置。综合所述，可以简单总结一下中断两种情况，一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写： public void run(){ try { //判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位 while (!Thread.interrupted()) { TimeUnit.SECONDS.sleep(2); } } catch (InterruptedException e) { } }6.2.2 中断与synchronized事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。演示代码如下 /** * Created by zejian on 2017/6/2. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */ public class SynchronizedBlocked implements Runnable{ public synchronized void f() { System.out.println(\"Trying to call f()\"); while(true) // Never releases lock Thread.yield(); } /** * 在构造器中创建新线程并启动获取对象锁 */ public SynchronizedBlocked() { //该线程已持有当前实例锁 new Thread() { public void run() { f(); // Lock acquired by this thread } }.start(); } public void run() { //中断判断 while (true) { if (Thread.interrupted()) { System.out.println(\"中断线程!!\"); break; } else { f(); } } } public static void main(String[] args) throws InterruptedException { SynchronizedBlocked sync = new SynchronizedBlocked(); Thread t = new Thread(sync); //启动后调用f()方法,无法获取当前实例锁处于等待状态 t.start(); TimeUnit.SECONDS.sleep(1); //中断线程,无法生效 t.interrupt(); } } 我们在SynchronizedBlocked构造函数中创建一个新线程并启动获取调用f()获取到当前实例锁，由于SynchronizedBlocked自身也是线程，启动后在其run方法中也调用了f()，但由于对象锁被其他线程占用，导致t线程只能等到锁，此时我们调用了t.interrupt();但并不能中断线程。 6.3 等待唤醒机制与synchronized所谓等待唤醒机制本篇主要指的是notify/notifyAll和wait方法，在使用这3个方法时，必须处于synchronized代码块或者synchronized方法中，否则就会抛出IllegalMonitorStateException异常，这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。 synchronized (obj) { obj.wait(); obj.notify(); obj.notifyAll(); } 需要特别理解的一点是，与sleep方法不同的是wait方法调用完成后，线程将被暂停，但wait方法将会释放当前持有的监视器锁(monitor)，直到有线程调用notify/notifyAll方法后方能继续执行，而sleep方法只让线程休眠并不释放锁。同时notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。 原文链接：https://blog.csdn.net/javazejian/article/details/72828483 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"多线程","slug":"多线程","permalink":"http://fyvan.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"synchronized","slug":"synchronized","permalink":"http://fyvan.github.io/tags/synchronized/"}],"author":"fyang"},{"title":"ObjectMapper工具API","slug":"API-ObjectMapper","date":"2020-05-29T09:01:04.028Z","updated":"2020-06-18T08:14:25.623Z","comments":true,"path":"undefined/fcf2.html","link":"","permalink":"http://fyvan.github.io/undefined/fcf2.html","excerpt":"","text":"在了解ObjectMapper之前,我们先要了解下什么是JSON. JSON(JavaScript Object Notation) 是一种轻量级的基于文本的数据交换格式。它采用完全独立于语言的文本格式，易于读写同时也易于机器解析和生成(网络传输速率)，因此使JSON成为理想的数据交换语言。 Java中的三种JSON库：Jackson、Gson、Fastjson. 其中Jackson旧称为：Java(或JVM平台)\\的标准JSON库，或者是Java的*最佳JSON解析器*，或者简称为“Java的JSON”. Jackson是一个简单的、功能强大的、基于Java的应用库。它可以很方便完成Java对象和json对象(xml文档or其它格式）进行互转。Jackson社区相对比较活跃，更新速度也比较快。Jackson库有如下几大特性： 高性能且稳定：低内存占用，对大/小JSON串，大/小对象的解析表现均很优秀 流行度高：是很多流行框架的默认选择 容易使用：提供高层次的API，极大简化了日常使用案例 无需自己手动创建映射：内置了绝大部分序列化时和Java类型的映射关系 干净的JSON：创建的JSON具有干净、紧凑、体积小等特点 无三方依赖：仅依赖于JDK Spring生态加持：jackson是Spring家族的默认JSON/XML解析器 1. ObjectMapper工具API介绍ObjectMapper是Jackson三大核心模块(core module)中的数据绑定模块(com.fasterxml.jackson.databind)包下的程序, 可以从 String，File，InputStream，URL，自定义的 Java 类中读取 JSON，ObjectMapper 中的重载方法 readValue() 实现了这些功能。 2.ObjectMapper入门 POJO与JSON之间的互相转化 POJO类代码如下: @EqualsAndHashCode(callSuper = true) @Data @Accessors(chain = true) @NoArgsConstructor @AllArgsConstructor @TableName(\"tb_item_desc\") public class ItemDesc extends BasePojo{ @TableId //只设定主键,不能自增 private Long itemId; private String itemDesc; } 这里用private修饰属性, 使用lombok提供getters/setters. 互相转化具体实现如下: @Test public void test01() throws JsonProcessingException { //提供一个测试对象 ItemDesc itemDesc = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); //使用databind，我们需要一个最基础的对象com.fasterxml.jackson.databind.ObjectMapper ObjectMapper objectMapper = new ObjectMapper(); //1.对象转化为JSON String json = objectMapper.writeValueAsString(itemDesc); System.out.println(json); //测试结果: //{\"created\":1590854279701,\"updated\":1590854279701,\"itemId\":100,\"itemDesc\":\"测试数据\"} //2.JSON转化为对象 ItemDesc itemDesc2 = objectMapper.readValue(json,ItemDesc.class); System.out.println(itemDesc2.toString()+ \":\" + itemDesc2.getCreated()); //测试结果: //ItemDesc(itemId=100, itemDesc=测试数据):Sat May 30 23:57:59 CST 2020 } list集合转化 @Test public void test02() throws JsonProcessingException { //提供测试数据 ItemDesc itemDesc = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); ItemDesc itemDesc2 = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); //提供集合 List&lt;ItemDesc> list = new ArrayList&lt;>(); list.add(itemDesc); list.add(itemDesc2); //1.list转化为JSON String json = OBJECTMAPPER.writeValueAsString(list); System.out.println(json); //测试结果 //[{\"created\":1590854579886,\"updated\":1590854579886,\"itemId\":100,\"itemDesc\":\"测试数据\"},{\"created\":1590854579886,\"updated\":1590854579886,\"itemId\":101,\"itemDesc\":\"测试数据2\"}] //2.json转化为list List&lt;ItemDesc> list2 = OBJECTMAPPER.readValue(json,list.getClass()); System.out.println(list2); //测试结果 //[{created=1590854579886, updated=1590854579886, itemId=100, itemDesc=测试数据}, {created=1590854579886, updated=1590854579886, itemId=101, itemDesc=测试数据2}] 3. JSON转化的原理/** * 原理说明: * 1.对象转化JSON时,其实调用的是对象身上的getXXXX()方法. * 获取所有的getLyj()方法-----之后去掉get-----首字母小写---lyj属性. * json串中的key就是该属性.value就是属性的值. lyj:\"xxxxx\" * * 2.JSON转化为对象原理说明 * 1).定义转化对象的类型(ItemDesc.class) * 2).利用反射机制实例化对象 class.forName(class) 现在的属性都为null * 3).将json串解析 * object key:value * array value1,value2 * 4).根据json串中的属性的itemId,之后调用对象的(set+首字母大写)setItemId方法实现赋值 */ @Test public void test03() throws JsonProcessingException { ItemDesc itemDesc = new ItemDesc(); itemDesc.setItemId(100L) .setItemDesc(\"测试数据\") .setCreated(new Date()) .setUpdated(itemDesc.getCreated()); //思考:对象转化为JSON时,底层实现如何. String json = OBJECTMAPPER.writeValueAsString(itemDesc); System.out.println(json); //{id:1,name:\"xxxx\"} OBJECTMAPPER.readValue(json,ItemDesc.class); } 4. 封装ObjectMapperUtil:该方法的主要的作用 就是将对象与json实现灵活的转化,并且内部优化了异常. 为了通用,将ObjectMapperUtil写入common中. public class ObjectMapperUtil { //1.定义mapper对象 private static final ObjectMapper MAPPER = new ObjectMapper(); //该类被调用1次 则对象被创建1次 //static 属性属于类的 无论调用多少次 对象1个 类.OBJECTmAPPER=修改的对象 //static final 为了安全 不允许别人修改 //2.将对象转化为JSON public static String toJSON(Object target) { try { return MAPPER.writeValueAsString(target); } catch (JsonProcessingException e) { //检查异常转化为运行时异常 e.printStackTrace(); throw new RuntimeException(e); } } //3.将JSON串转化为对象 用户传递什么类型,就能返回什么对象 public static &lt;T> T toObj(String json,Class&lt;T> target) { try { return MAPPER.readValue(json, target); } catch (JsonProcessingException e) { e.printStackTrace(); throw new RuntimeException(e); } } } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"API","slug":"API","permalink":"http://fyvan.github.io/categories/API/"}],"tags":[{"name":"ObjectMapper","slug":"ObjectMapper","permalink":"http://fyvan.github.io/tags/ObjectMapper/"}],"author":"fyang"},{"title":"CentOS 7安装Docker","slug":"SoftwareInstall-2020-05-28-CentOS-Docker","date":"2020-05-28T13:13:32.898Z","updated":"2020-06-18T08:20:00.343Z","comments":true,"path":"undefined/674f.html","link":"","permalink":"http://fyvan.github.io/undefined/674f.html","excerpt":"","text":"1. 前言Docker 使用越来越多，安装也很简单，本次记录一下基本的步骤。 Docker 目前支持 CentOS 7 及以后的版本，内核要求至少为 3.10。 Docker 官网有安装步骤，本文只是记录一下，您也可以参考 Get Docker CE for CentOS 2. 环境说明RedHat 7.6 (Minimal Install) [root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 3. 准备工作 操作系统要求 CentOS 7 以后都可以安装 Docker 了，也可以确认一下。 [root@localhost ~]# uname -a Linux localhost.localdomain 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux Docker 需要用到 centos-extra 这个源，如果关闭了，需要重启启用，可以参考 Available Repositories for CentOS。 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。 vim /etc/yum.repos.d/docker-ce.repo 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1 卸载旧版本的Docker 旧版本的 Docker 被叫做 docker 或 docker-engine，如果安装了旧版本的 Docker ，您需要卸载掉它。 我的系统上没有安装,所以结果下 [root@localhost ~]# yum remove docker \\ > docker-client \\ > docker-client-latest \\ > docker-common \\ > docker-latest \\ > docker-latest-logrotate \\ > docker-logrotate \\ > docker-engine 已加载插件：fastestmirror 参数 docker 没有匹配 参数 docker-client 没有匹配 参数 docker-client-latest 没有匹配 参数 docker-common 没有匹配 参数 docker-latest 没有匹配 参数 docker-latest-logrotate 没有匹配 参数 docker-logrotate 没有匹配 参数 docker-engine 没有匹配 不删除任何软件包 旧版本的内容在 /var/lib/docker 下，目录中的镜像(images), 容器(containers), 存储卷(volumes), 和 网络配置（networks）都可以保留。 Docker CE 包，目前的包名为 docker-ce。 4. 安装Docker-CE: 安装准备 为了方便添加软件源，支持 device-mapper 存储类型，安装如下软件包 [root@localhost ~]# sudo yum update [root@localhost ~]# sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加 yum 软件源 添加 Docker 稳定版本的 yum 软件源 # 官方源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 阿里云源 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装 更新一下 yum 软件源的缓存，并安装 Docker,下载慢的话可以尝试使用下面阿里云Docker CE 镜像源站安装 [root@localhost ~]# sudo yum update [root@localhost ~]# sudo yum -y install docker-ce 如果弹出 GPG key 的接收提示，请确认是否为 060a 61c5 1b55 8a7f 742b 77aa c52f eb6b 621e 9f35，如果是，可以接受并继续安装。 至此，Docker 已经安装完成了，Docker 服务是没有启动的，操作系统里的 docker 组被创建，但是没有用户在这个组里。 注意 默认的 docker 组是没有用户的（也就是说需要使用 sudo 才能使用 docker 命令）。您可以将用户添加到 docker 组中（此用户就可以直接使用 docker 命令了）。 加入 docker 用户组命令 sudo usermod -aG docker USER_NAME 用户更新组信息后，重新登录系统即可生效。 5. 安装指定版本Docker-CE: 查找Docker-CE的版本: yum list docker-ce.x86_64 --showduplicates | sort -r Loading mirror speeds from cached hostfile Loaded plugins: branch, fastestmirror, langpacks docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable Available Packages 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos) sudo yum -y install docker-ce-[VERSION] 注意：在某些版本之后，docker-ce安装出现了其他依赖包，如果安装失败的话请关注错误信息。例如 docker-ce 17.03 之后，需要先安装 docker-ce-selinux。 yum list docker-ce-selinux- --showduplicates | sort -r sudo yum -y install docker-ce-selinux-[VERSION] 通过经典网络、VPC网络内网安装时，用以下命令替换Step 2中的命令 经典网络：sudo yum-config-manager –add-repo http://mirrors.aliyuncs.com/doer-ce/linux/centos/docker-ce.repo VPC网络：sudo yum-config-manager –add-repo http://mirrors.could.aliyuncs.com/docker-ce/linux/centos/docker-ce.repo 6. 启动Docker启动 docker 服务 sudo systemctl start docker 添加到开机启动 sudo systemctl enable docker 7. 安装校验[root@localhost ~]# docker version Client: Version: 17.03.0-ce API version: 1.26 Go version: go1.7.5 Git commit: 3a232c8 Built: Tue Feb 28 07:52:04 2017 OS/Arch: linux/amd64 Server: Version: 17.03.0-ce API version: 1.26 (minimum version 1.12) Go version: go1.7.5 Git commit: 3a232c8 Built: Tue Feb 28 07:52:04 2017 OS/Arch: linux/amd64 Experimental: false 运行 hello-world 镜像 sudo docker run hello-world 8. 更新和卸载使用 yum 管理，更新和卸载都很方便。 更新Docker CE sudo yum update docker-ce 卸载Docker CE sudo yum remove docker-ce 删除本地文件 注意，docker 的本地文件，包括镜像(images), 容器(containers), 存储卷(volumes)等，都需要手工删除。默认目录存储在 /var/lib/docker。 sudo rm -rf /var/lib/docker 9. Docker拉取镜像慢解决方法镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。 新版的 Docker 使用 /etc/docker/daemon.conf（Linux） 或者 %programdata%\\docker\\config\\daemon.json（Windows） 来配置 Daemon。 请在该配置文件中加入（没有该文件的话，请先建一个）： { “registry-mirrors”: [“http://hub-mirror.c.163.com\"]} document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://fyvan.github.io/tags/Docker/"}],"author":"fyang"},{"title":"Redis安装与用法","slug":"SoftwareInstall-2020-05-27-CentsOS-Redis","date":"2020-05-27T01:06:48.520Z","updated":"2020-06-18T08:19:42.281Z","comments":true,"path":"undefined/d618.html","link":"","permalink":"http://fyvan.github.io/undefined/d618.html","excerpt":"","text":"1. 在Redis官网下载软件包下载地址 2. 上传文件到Linux使用lrzsz或者ftp上传 [root@localhost src]# rz -E rz waiting to receive. [root@localhost src]# ls images jdk1.8 nginx-1.19.0 redis-6.0.3.tar.gz tomcats # 检查防火墙状态是否关闭 [root@localhost src]# firewall-cmd --state not running 3. 解压Redis压缩包# 解压并删除tar.gz压缩包 [root@localhost src]# tar -xvf redis-5.0.4.tar.gz [root@localhost src]# rm -f redis-5.0.4.tar.gz [root@localhost src]# ls images jdk1.8 nginx-1.19.0 redis-5.0.4 tomcats 4. 安装Redis 进入解压后的redis目录 [root@localhost src]# cd redis-5.0.4/ [root@localhost redis-5.0.4]# ll 总用量 252 -rw-rw-r--. 1 root root 99445 3月 19 2019 00-RELEASENOTES -rw-rw-r--. 1 root root 53 3月 19 2019 BUGS -rw-rw-r--. 1 root root 1894 3月 19 2019 CONTRIBUTING -rw-rw-r--. 1 root root 1487 3月 19 2019 COPYING drwxrwxr-x. 6 root root 124 3月 19 2019 deps -rw-rw-r--. 1 root root 11 3月 19 2019 INSTALL -rw-rw-r--. 1 root root 151 3月 19 2019 Makefile -rw-rw-r--. 1 root root 4223 3月 19 2019 MANIFESTO -rw-rw-r--. 1 root root 20555 3月 19 2019 README.md -rw-rw-r--. 1 root root 62155 3月 19 2019 redis.conf -rwxrwxr-x. 1 root root 275 3月 19 2019 runtest -rwxrwxr-x. 1 root root 280 3月 19 2019 runtest-cluster -rwxrwxr-x. 1 root root 281 3月 19 2019 runtest-sentinel -rw-rw-r--. 1 root root 9710 3月 19 2019 sentinel.conf drwxrwxr-x. 3 root root 4096 3月 19 2019 src drwxrwxr-x. 10 root root 167 3月 19 2019 tests drwxrwxr-x. 8 root root 4096 3月 19 2019 utils 编译redis [root@localhost src]# make cd src && make all make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” CC Makefile.dep make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” ... LINK redis-server INSTALL redis-sentinel CC redis-cli.o LINK redis-cli CC redis-benchmark.o LINK redis-benchmark INSTALL redis-check-rdb INSTALL redis-check-aof Hint: It's a good idea to run 'make test' ;) make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” 执行安装 [root@localhost redis-5.0.4]# make install cd src && make install make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” CC Makefile.dep make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” make[1]: 进入目录“/usr/local/src/redis-5.0.4/src” Hint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install make[1]: 离开目录“/usr/local/src/redis-5.0.4/src” 5. 修改Redis配置文件 关闭IP绑定 注释配置文件中的IP绑定 只有去除IP绑定,远程机才能进行访问 关闭保护模式 protected-mode yes yes—to—&gt;no 开启后台启动 daemonize yes no—to—&gt;yes 阻止启动redis后独占终端 Esc———-:wq———-保存退出 6. Reids命令可以在官网查看Redis命令的使用https://redis.io/commands 启动Redis [root@localhost redis-5.0.4]# redis-server redis.conf 9700:C 27 May 2020 17:47:09.537 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 9700:C 27 May 2020 17:47:09.537 # Redis version=5.0.4, bits=64, commit=00000000, modified=0, pid=9700, just started 9700:C 27 May 2020 17:47:09.537 # Configuration loaded 检查Redis进程信息 [root@localhost redis-5.0.4]# ps -ef | grep redis root 9701 1 0 17:47 ? 00:00:00 redis-server *:6379 root 9708 1448 0 17:48 pts/0 00:00:00 grep --color=auto redis 关闭Redis [root@localhost redis-5.0.4]# redis-cli -p 6379 shutdown 进入Redis客户端 [root@localhost redis-5.0.4]# redis-cli -p 6379 127.0.0.1:6379> # 使用默认端口6379可以省略不写 [root@localhost redis-5.0.4]# redis-cli 关闭客户端 Ctrl + C6.1 String类型数据 命令 说明 案例 set 添加key-value set username admin get 根据key获取数据 get username strlen 根据key获取值的长度 strlen key exists 判断key是否存在 exists name 返回1存在 0不存在 del 删除redis中的key del key Keys 用于查询符合条件的key keys * 查询redis中全部的key keys n?me 使用占位符获取数据 keys nam* 获取nam开头的数据 mset 赋值多个key-value mset key1 value1 key2 value2 key3 value3 mget 获取多个key的值 mget key1 key2 append 对某个key的值进行追加 append key value type 检查某个key的类型 type key select 切换redis数据库 select 0-15 redis中共有16个数据库 flushdb 清空单个数据库 flushdb flushall 清空全部数据库 flushall incr 自动加1 incr key decr 自动减1 decr key incrby 指定数值添加 incrby 10 decrby 指定数值减 decrby 10 expire 指定key的生效时间 单位秒 expire key 20 key20秒后失效 pexpire 指定key的失效时间 单位毫秒 pexpire key 2000 key 2000毫秒后失效 ttl 检查key的剩余存活时间 ttl key -2数据不存在 -1该数据永不超时 persist 撤销key的失效时间 persist key 6.2 Hash类型说明:可以用散列类型保存对象和属性值 例子:User对象{id:2,name:小明,age:19} 命令 说明 案例 hset 为对象添加数据 hset key field value hget 获取对象的属性值 hget key field hexists 判断对象的属性是否存在 HEXISTS key field 1表示存在 0表示不存在 hdel 删除hash中的属性 hdel user field [field …] hgetall 获取hash全部元素和值 HGETALL key hkyes 获取hash中的所有字段 HKEYS key hlen 获取hash中所有属性的数量 hlen key hmget 获取hash里面指定字段的值 hmget key field [field …] hmset 为hash的多个字段设定值 hmset key field value [field value …] hsetnx 设置hash的一个字段,只有当这个字段不存在时有效 HSETNX key field value hstrlen 获取hash中指定key的值的长度 HSTRLEN key field hvals 获取hash的所有值 HVALS user 6.3 List类型说明:Redis中的List集合是双端循环列表,分别可以从左右两个方向插入数据. List集合可以当做队列使用,也可以当做栈使用 队列:存入数据的方向和获取数据的方向相反 栈:存入数据的方向和获取数据的方向相同 命令 说明 案例 lpush 从队列的左边入队一个或多个元素 LPUSH key value [value …] rpush 从队列的右边入队一个或多个元素 RPUSH key value [value …] lpop 从队列的左端出队一个元素 LPOP key rpop 从队列的右端出队一个元素 RPOP key lpushx 当队列存在时从队列的左侧入队一个元素 LPUSHX key value rpushx 当队列存在时从队列的右侧入队一个元素 RPUSHx key value lrange 从列表中获取指定返回的元素 LRANGE key start stop Lrange key 0 -1 获取全部队列的数据 lrem 从存于 key 的列表里移除前 count 次出现的值为 value 的元素。 这个 count 参数通过下面几种方式影响这个操作： · count &gt; 0: 从头往尾移除值为 value 的元素。 · count &lt; 0: 从尾往头移除值为 value 的元素。 · count = 0: 移除所有值为 value 的元素。 LREM list -2 “hello” 会从存于 list 的列表里移除最后两个出现的 “hello”。 需要注意的是，如果list里没有存在key就会被当作空list处理，所以当 key 不存在的时候，这个命令会返回 0。 Lset 设置 index 位置的list元素的值为 value LSET key index value 6.4 Redis事务命令说明:redis中操作可以添加事务的支持.一项任务可以由多个redis命令完成,如果有一个命令失败导致入库失败时.需要实现事务回滚. 命令 说明 案例 multi 标记一个事务开始 127.0.0.1:6379&gt; MULTI OK exec 执行所有multi之后发的命令 127.0.0.1:6379&gt; EXEC OK discard 丢弃所有multi之后发的命令 7. Redis高级应用7.1 在pom.xml中添加jar包文件说明:在JT-PARENT项目中添加jar包文件 &lt;!-- jedis --> &lt;dependency> &lt;groupId>redis.clients&lt;/groupId> &lt;artifactId>jedis&lt;/artifactId> &lt;version>${jedis.version}&lt;/version> &lt;/dependency> &lt;!--添加spring-datajar包 --> &lt;dependency> &lt;groupId>org.springframework.data&lt;/groupId> &lt;artifactId>spring-data-redis&lt;/artifactId> &lt;version>1.4.1.RELEASE&lt;/version> &lt;/dependency> 7.2 String类型数据测试package com.jt.test; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Test; import redis.clients.jedis.Jedis; import redis.clients.jedis.params.SetParams; public class TestRedis { @Test public void testString01(){ //1.连接Redis String host = \"192.168.126.129\"; int port= 6379; Jedis jedis = new Jedis(host, port); //2.操作redis jedis.set(\"2002\",\"学习好辛苦\"); String value = jedis.get(\"2002\"); System.out.println(value); //3.判断redis中是否有指定数据 if(!jedis.exists(\"2002\")){ jedis.set(\"2002\",\"两会精神\"); } //4.删除 jedis.del(\"2002\"); //5.检索数据 System.out.println(jedis.keys(\"*\")); //6.清空数据 jedis.flushAll(); } //测试类的初始化操作 private Jedis jedis; @BeforeEach public void init(){ jedis = new Jedis(\"192.168.126.129\", 6379); } //如果采用expire则不能保证超时时间的原子性操作!!! //lock锁: 死锁 @Test public void testStringEX() throws InterruptedException { jedis.set(\"abc\",\"测试数据的有效期\"); //1.没有设定超时时间,用不过期 //int a = 1/0; //如果发生异常,数据已存入redis数据库中 jedis.expire(\"abc\",5); //2.设定超时 Thread.sleep(2000); Long seconds = jedis.ttl(\"abc\"); System.out.println(\"abc剩余的存活时间: \" + seconds); jedis.persist(\"abc\"); //保证赋值的原子性操作 jedis.setex(\"www\",10,\"超时测试\"); } /** * 需求:如果a存在,则不允许重新赋值 * @throws InterruptedException */ @Test public void testStringNX() throws InterruptedException { /*jedis.set(\"a\",\"123\"); jedis.set(\"a\",\"456\"); System.out.println(jedis.get(\"a\")); if (!jedis.exists(\"a\")){ jedis.set(\"a\",\"11111111\"); } System.out.println(jedis.get(\"a\"));*/ //如果key不存在时,则赋值 jedis.setnx(\"a\",\"123\"); jedis.setnx(\"a\",\"456\"); System.out.println(jedis.get(\"a\")); //123 } /** * 1.保证超时时间的原子性操作 EX * 2.保证如果key存在,则不允许赋值 NX * 需求:既满足超时定义,又要满足数据不允许修改 * SetParams:参数 * EX: 秒 * PX: 毫秒 * NX: 有值不修改 * XX: 如果key不存在,则数据不修改 */ @Test public void testStringEXNX(){ SetParams setParams = new SetParams(); setParams.ex(20).nx(); jedis.set(\"a\",\"66666666666\",setParams); jedis.set(\"a\",\"1111111111111111\",setParams); System.out.println(jedis.get(\"a\")); } } 7.3 hash类型测试/** * 一般会将有关联关系的数据利用hash方式进行保存. * orderID: * userID:下单用户 * price: xxxxx * items: [xxxxx] * orderShipping: xxxxx */ @Test public void testHash(){ jedis.hset(\"orderID\",\"userID\",\"100\"); jedis.hset(\"orderID\",\"price\",\"2341.34\"); jedis.hset(\"orderID\",\"items\",\"描述信息\"); jedis.hset(\"orderID\",\"orderShipping\",\"物流信息\"); System.out.println(jedis.hgetAll(\"orderID\")); System.out.println(jedis.hkeys(\"orderID\")); System.out.println(jedis.hvals(\"orderID\")); } 结果展现: 操作完成!!!1 {userID=100, items=描述信息, orderShipping=物流信息, price=2341.34} [userID, items, orderShipping, price] [100, 2341.34, 描述信息, 物流信息] 7.4 List类型测试@Test public void testList(){ jedis.lpush(\"list1\",\"1,2,3,4,5\"); String value1 = jedis.rpop(\"list1\"); System.out.println(value1); //1,2,3,4,5 jedis.lpush(\"list2\",\"1\",\"2\",\"3\",\"4\",\"5\"); String value2 = jedis.rpop(\"list2\"); System.out.println(value2); //1 } 结果展现: 1,2,3,4,5 1 7.5 事务测试@Test public void testTX(){ Transaction transaction = jedis.multi(); //开始事务 try{ transaction.set(\"a\",\"a\"); transaction.set(\"b\",\"b\"); transaction.exec(); //提交事务 }catch (Exception e){ transaction.discard(); //事务回滚 } } 注意: 虽然redis提供了事务操作,但是该事务是一种弱事务. 只对单台redis有效 如果存在多台redis,并且需要使用事务控制,一般使用队列的形式进行事务控制 8. SpringBoot整合Redis8.1 整合Redis的步骤 将redis的配置文件写入到properties文件中. 利用SpringBoot的配置类整合Redis. 实现Redis的复用. 8.2 编辑properties文件 说明: 为了实现redis整合的通用,所以将redis.properties文件放到jt-common中 #配置单台redis redis.host=192.168.126.129 redis.port=6379 8.3 编辑redis.config配置文件 作用:将redis对象交给spring容器进行管理.并且用户通过@Autowired注解动态获取对象. 细节:在jt-common中编辑配置类 配置类: @Configuration //标识配置类 一般和@Bean注解连用 @PropertySource(\"classpath:/properties/redis.properties\") public class RedisConfig { @Value(\"${redis.host}\") private String host; @Value(\"${redis.port}\") private Integer port; //将哪个对象交给容器管理,返回值就是什么对象 @Bean public Jedis jedis(){ return new Jedis(host, port); } } 测试: @SpringBootTest public class RedisConfigTests { @Autowired private Jedis jedis; @Test public void redisConfTest(){ jedis.set(\"key\",\"Hello Redis\"); String value = jedis.get(\"key\"); System.out.println(value); } } 结果: document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, Redis","slug":"CentOS7-Redis","permalink":"http://fyvan.github.io/tags/CentOS7-Redis/"}],"author":"fyang"},{"title":"CentOS7安装Mysql","slug":"SoftwareInstall-2020-05-26-CentOS-mysql","date":"2020-05-26T08:09:00.910Z","updated":"2020-06-18T08:19:18.401Z","comments":true,"path":"undefined/4871.html","link":"","permalink":"http://fyvan.github.io/undefined/4871.html","excerpt":"","text":"1. 安装Maria DB使用yum安装 (需要配置好yum,有网络) yum install mariadb-server 需要依赖, 输入y 回车继续 安装完成后如下所示: 2. MariaDB 命令 启动数据库: systemctl start mariadb 停止数据库: systemctl stop mariadb 重启数据库: systemctl restart mariadb 3. MariaDB 配置输入mysql_secure_installation命令配置数据库,如下注释中的解释 [root@localhost src]# mysql_secure_installation NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] Y # 设置密码 y New password: # 新密码 Re-enter new password: # 再次输入密码 Password updated successfully! Reloading privilege tables.. ... Success! By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] Y #是否移除匿名用户,输入Y,回车继续 ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. # 拒绝root远程登录,n, 不管y/n,都会拒绝root远程登录 Disallow root login remotely? [Y/n] n ... skipping. By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. # 删除test数据库,y:删除 n:不删除. 数据库中会有一个test数据库,一般不需要 Remove test database and access to it? [Y/n] n ... skipping. Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] y # 重新加载权限表,y. 或者重启服务也行 ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! 4. 数据库登录测试使用用户名:root &amp; 密码:root 登录数据库 [root@localhost src]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 7 Server version: 5.5.65-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> 5. 设定远程访问说明:Mysql数据库默认条件下不允许远程用户访问数据库,只允许本地服务通过127.0.0.1/localhost的方式访问! 需求:想通过Windows的SqlYog程序远程访问数据库,则必须修改mysql的权限列表. 本地登录数据库: [root@localhost src]# mysql -uroot -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 8 Server version: 5.5.65-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> 查看并切换数据库: MariaDB [(none)]> show databases; # 查看数据库 +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | test | +--------------------+ 4 rows in set (0.00 sec) MariaDB [(none)]> use mysql; # 切换数据库 Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed MariaDB [mysql]> 查看数据库表信息: MariaDB [mysql]> show tables; # 查看数据库表信息 +---------------------------+ | Tables_in_mysql | +---------------------------+ | columns_priv | | db | | event | | func | | general_log | | help_category | | help_keyword | | help_relation | | help_topic | | host | | ndb_binlog_index | | plugin | | proc | | procs_priv | | proxies_priv | | servers | | slow_log | | tables_priv | | time_zone | | time_zone_leap_second | | time_zone_name | | time_zone_transition | | time_zone_transition_type | | user | +---------------------------+ 24 rows in set (0.00 sec) 查看root账户权限信息 # host : 表示允许访问的主机 # user : 用户信息 # password : 密码信息 (MD5加密) MariaDB [mysql]> select host,user,password from user; +-----------+------+-------------------------------------------+ | host | user | password | +-----------+------+-------------------------------------------+ | localhost | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | 127.0.0.1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | ::1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | +-----------+------+-------------------------------------------+ 3 rows in set (0.00 sec) 修改用户权限列表,实现用户远程访问 将与主机名相等的字段改为\" % \",我的主机名为root MariaDB [mysql]> update user set host='%' where host='localhost'; Query OK, 1 rows affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 MariaDB [mysql]> select host,user,password from user; +-----------+------+-------------------------------------------+ | host | user | password | +-----------+------+-------------------------------------------+ | % | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | 127.0.0.1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | | ::1 | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | +-----------+------+-------------------------------------------+ 3 rows in set (0.00 sec) 刷新权限列表或者重启数据库服务 # 刷新权限列表 MariaDB [mysql]> flush privileges; Query OK, 0 rows affected (0.00 sec) # 或者重启数据库服务 [root@localhost src]# systemctl restart mariadb [root@localhost src]# 关闭Linux防火墙,使用SQLyog连接数据库 设置Linux开机自动启动数据库服务 [root@localhost ~]# systemctl enable mariadb Created symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service. 6. Linux中的防火墙 检查防火墙状态信息 [root@localhost src]# firewall-cmd --state running 临时关闭防火墙操作,系统重启后防火墙会重新开启. [root@localhost src]# systemctl stop firewalld.service [root@localhost src]# firewall-cmd --state not running 开启防火墙操作 [root@localhost src]# systemctl stop firewalld.service [root@localhost src]# firewall-cmd --state not running 永久关闭防火墙操作 # 表示系统下次启动时不开启防火墙 [root@localhost src]# systemctl disable firewalld.service Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service. Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service. # 防火墙还是运行状态 [root@localhost src]# firewall-cmd --state running # 还需要将当前防火墙关闭 [root@localhost src]# systemctl stop firewalld.service [root@localhost src]# firewall-cmd --state not running 永久开启防火墙操作 # 表示系统下次启动时开启防火墙 [root@localhost src]# systemctl enable firewalld.service Created symlink from /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service to /usr/lib/systemd/system/firewalld.service. Created symlink from /etc/systemd/system/multi-user.target.wants/firewalld.service to /usr/lib/systemd/system/firewalld.service. # 防火墙还是关闭状态 [root@localhost src]# firewall-cmd --state not running # 还需要将当前防火墙开启 [root@localhost src]# systemctl start firewalld.service [root@localhost src]# firewall-cmd --state running 7. 使用Docker安装mysql项目的底层数据库采用MySQL，而MySQL采用衍生版本Percona，并且采用docker容器化的方式进行部署。 什么是percona？ Percona 为 MySQL 数据库服务器进行了改进，在功能和性能上较 MySQL 有着很显著的提升。该版本提升了在高负载情况下的 InnoDB 的性能、为 DBA 提供一些非常有用的性能诊断工具；另外有更多的参数和命令来控制服务器行为。Percona Server 只包含 MySQL 的服务器版，并没有提供相应对 MySQL 的 Connector 和 GUI 工具进行改进。Percona Server 使用了一些 google-mysql-tools, Proven Scaling, Open Query 对 MySQL 进行改造。官网：https://www.percona.com/software/mysql-database 安装部署 #镜像地址：https://hub.docker.com/_/percona/ #拉取镜像 docker pull percona:5.7.23 #创建容器 docker create --name percona -v /data/mysql-data:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root percona:5.7.23 c5af61393e45d4565c247139f7daea1acce7b057a722fd877ee4e456e2ffc3a0 #参数解释： --name： percona 指定是容器的名称 -v： /data/mysql-data:/var/lib/mysql 将主机目录/data/mysql-data挂载到容器 的/var/lib/mysql上 -p： 3306:3306 设置端口映射，主机端口是3306，容器内部端口3306 -e： MYSQL_ROOT_PASSWORD=root 设置容器参数，设置root用户的密码为root percona:5.7.23： 镜像名:版本 #启动容器 docker start percona 测试： 启动percona的时候发现没啥问题，但是在docker ps查看的时候会发现没有percona，而且查看/data/mysql-data文件也没有写入内容。 使用docker ps -a查看就可以看见问题 Exited (1) About a minute ago 服务闪退了 解决方案 给data文件添加权限即可 chmod -R 777 /data 测试宿主机客户端: 连接成功 8. docker常用命令列出所有容器ID docker ps -aq 查看所有运行或者不运行容器 docker ps -a 停止所有的container（容器），这样才能够删除其中的images： docker stop $(docker ps -a -q) 或者 docker stop $(docker ps -aq) 如果想要删除所有container（容器）的话再加一个指令： docker rm $(docker ps -a -q) 或者 docker rm $(docker ps -aq) 查看当前有些什么images docker images 删除images（镜像），通过image的id来指定删除谁 docker rmi 想要删除untagged images，也就是那些id为的image的话可以用 docker rmi $(docker images | grep \"^\" | awk \"{print $3}\") 要删除全部image（镜像）的话 docker rmi $(docker images -q) 强制删除全部image的话 强制删除全部image的话 docker rmi -f $(docker images -q) 从容器到宿主机复制 docker cp tomcat：/webapps/js/text.js /home/admin docker cp 容器名: 容器路径 宿主机路径 从宿主机到容器复制 从宿主机到容器复制 docker cp /home/admin/text.js tomcat：/webapps/js docker cp 宿主路径中文件 容器名 容器路径 删除所有停止的容器 docker container prune 删除所有不使用的镜像 docker image prune --force --all或者docker image prune -f -a 停止、启动、杀死、重启一个容器 停止、启动、杀死、重启一个容器 docker stop Name或者ID docker start Name或者ID docker kill Name或者ID docker restart name或者ID docker进入容器，查看配置文件 docker进入容器，查看配置文件 docker exec ：在运行的容器中执行命令 -d :分离模式: 在后台运行 -i :即使没有附加也保持STDIN（标准输入） 打开,以交互模式运行容器，通常与 -t 同时使用； -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； docker exec -it f94d2c317477 /bin/bash出现root@f94d2c317477:/usr/share/elasticsearch/config# vi elasticsearch.ymlbash: vi: command not found apt-get update && apt-get install vim -y 修改配置、退出容器 1、如果要正常退出不关闭容器，请按Ctrl+P+Q进行退出容器 2、如果使用exit退出，那么在退出之后会关闭容器，可以使用下面的流程进行恢复 使用docker restart命令重启容器 使用docker attach命令进入容器 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, mariadb","slug":"CentOS7-mariadb","permalink":"http://fyvan.github.io/tags/CentOS7-mariadb/"}],"author":"fyang"},{"title":"CentOS7安装Nginx","slug":"SoftwareInstall-2020-05-26-Centos-nginx","date":"2020-05-26T08:04:06.090Z","updated":"2020-06-18T08:19:31.666Z","comments":true,"path":"undefined/981a.html","link":"","permalink":"http://fyvan.github.io/undefined/981a.html","excerpt":"","text":"1. 下载Linux版的Ngnix 下载链接 2. 上传文件到Linux服务器使用lrzsz方式上传,直接拖拽 3. 解压上传文件,并删除压缩包# 解压文件 [root@localhost src]# tar -xzvf nginx-1.19.0.tar.gz nginx-1.19.0/ nginx-1.19.0/auto/ ...... nginx-1.19.0/auto/cc/name nginx-1.19.0/auto/cc/owc nginx-1.19.0/auto/cc/sunc # 查看文件目录结构 [root@localhost src]# ls images jdk1.8 nginx-1.19.0 nginx-1.19.0.tar.gz tomcats # 删除压缩包 [root@localhost src]# rm -rf nginx-1.19.0.tar.gz 4. 安装Nginxnginx安装中会有源文件目录和工作目录之分 配置Nginx # 查看文件目录结构 [root@localhost nginx-1.19.0]# ls auto CHANGES CHANGES.ru conf configure contrib html LICENSE man README src [root@localhost nginx-1.19.0]# ./configure checking for OS + Linux 3.10.0-1062.18.1.el7.x86_64 x86_64 checking for C compiler ... found + using GNU C compiler + gcc version: 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ....... # 校验文件 creating objs/Makefile Configuration summary + using system PCRE library + OpenSSL library is not used + using system zlib library nginx path prefix: \"/usr/local/nginx\" # 工作目录 nginx binary file: \"/usr/local/nginx/sbin/nginx\" nginx modules path: \"/usr/local/nginx/modules\" nginx configuration prefix: \"/usr/local/nginx/conf\" nginx configuration file: \"/usr/local/nginx/conf/nginx.conf\" nginx pid file: \"/usr/local/nginx/logs/nginx.pid\" nginx error log file: \"/usr/local/nginx/logs/error.log\" nginx http access log file: \"/usr/local/nginx/logs/access.log\" nginx http client request body temporary files: \"client_body_temp\" nginx http proxy temporary files: \"proxy_temp\" nginx http fastcgi temporary files: \"fastcgi_temp\" nginx http uwsgi temporary files: \"uwsgi_temp\" nginx http scgi temporary files: \"scgi_temp\" 编译源文件 [root@localhost nginx-1.19.0]# make make -f objs/Makefile make[1]: 进入目录“/usr/local/src/nginx-1.19.0” cc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\ ...... -Wl,-E sed -e \"s|%%PREFIX%%|/usr/local/nginx|\" \\ -e \"s|%%PID_PATH%%|/usr/local/nginx/logs/nginx.pid|\" \\ -e \"s|%%CONF_PATH%%|/usr/local/nginx/conf/nginx.conf|\" \\ -e \"s|%%ERROR_LOG_PATH%%|/usr/local/nginx/logs/error.log|\" \\ < man/nginx.8 > objs/nginx.8 make[1]: 离开目录“/usr/local/src/nginx-1.19.0” 执行安装指令 [root@localhost nginx-1.19.0]# make install make -f objs/Makefile install make[1]: 进入目录“/usr/local/src/nginx-1.19.0” test -d '/usr/local/nginx' || mkdir -p '/usr/local/nginx' ... make[1]: 离开目录“/usr/local/src/nginx-1.19.0” 检查安装路径 # 工作目录 [root@localhost nginx-1.19.0]# whereis nginx nginx: /usr/local/nginx 安装中报错信息: #安装Nginx时报错 ./configure: error: the HTTP rewrite module requires the PCRE library. #安装pcre-devel解决问题 yum -y install pcre-devel #错误提示： ./configure: error: the HTTP cache module requires md5 functions from OpenSSL library. You can either disable the module by using --without-http-cache option, or install the OpenSSL library into the system, or build the OpenSSL library statically from the source with nginx by using --with-http_ssl_module --with-openssl= options. # 解决办法： yum -y install openssl openssl-devel # 总结： yum -y install pcre-devel openssl openssl-devel ./configure --prefix=/usr/local/nginx make make install 5. Nginx命令 进入工作目录,查看目录结构 [root@localhost nginx-1.19.0]# cd /usr/local/nginx/ [root@localhost nginx]# ll 总用量 4 drwxr-xr-x. 2 root root 4096 5月 27 11:43 conf # 配置文件 drwxr-xr-x. 2 root root 40 5月 27 11:43 html # 欢迎页 drwxr-xr-x. 2 root root 6 5月 27 11:43 logs # 日志文件 drwxr-xr-x. 2 root root 19 5月 27 11:43 sbin # nginx命令 使用nginx命令 启动nginx并查看进程 ./nginx [root@localhost nginx]# cd sbin/ [root@localhost sbin]# ll 总用量 3764 -rwxr-xr-x. 1 root root 3851112 5月 27 11:43 nginx [root@localhost sbin]# ./nginx [root@localhost sbin]# ps -ef | grep nginx root 12672 1 0 11:49 ? 00:00:00 nginx: master process ./nginx nobody 12673 12672 0 11:49 ? 00:00:00 nginx: worker process root 12687 1829 0 11:49 pts/0 00:00:00 grep --color=auto nginx 更新nginx配置 [root@localhost sbin]# ./nginx -s reload 停止nginx服务 [root@localhost sbin]# ./nginx -s stop 6. 测试Nginxwindow浏览器访问localhost,虚拟机访问分配的ip地址:192.168.126.129 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, Nginx","slug":"CentOS7-Nginx","permalink":"http://fyvan.github.io/tags/CentOS7-Nginx/"}],"author":"fyang"},{"title":"CentOS7安装jdk1.8","slug":"SoftwareInstall-2020-05-26-Centos-jdk","date":"2020-05-26T07:25:41.609Z","updated":"2020-06-18T08:19:04.332Z","comments":true,"path":"undefined/f754.html","link":"","permalink":"http://fyvan.github.io/undefined/f754.html","excerpt":"","text":"1. 安装lrzsz我们常用ftp上传一些文件到Linux服务器,或者从LInux服务器上下载一些文件到本地.如果只是传输一些小文件的话,可以使用lrzsz,作为ftp的代替品. 使用如下命令安装lrzsz yum -y install lrzsz 安装完成后在Xshell中到想安装的目录下,我的是在/usr/local/src/,直接拖拽上传: 2. 解压上传的jdk文件tar -zxvf jdk-8u51-linux-x64.tar.gz 解压完成后目录文件如下: 3. 删除jdk的压缩包rm -f jdk-8u51-linux-x64.tar.gz 4. 重命名jdk的解压文件夹[root@localhost src]# mv jdk1.8.0_51 jdk1.8 [root@localhost src]# ll 总用量 0 drwxr-xr-x. 8 10 143 255 6月 9 2015 jdk1.8 5. 配置环境变量#修改/etc/profile文件,添加下面内容 export JAVA_HOME=/usr/local/src/jdk1.8 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib #配置类加载器 6. 刷新环境变量,是配置立即生效[root@localhost jdk1.8.0]# source /etc/profile 7. 验证安装结果如下显示jdk版本则表示成功 [root@localhost jdk1.8.0]# java -version java version \"1.8.0_51\" Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"CentOS7, jdk1.8","slug":"CentOS7-jdk1-8","permalink":"http://fyvan.github.io/tags/CentOS7-jdk1-8/"}],"author":"fyang"},{"title":"MySql数据库优化","slug":"Mysql优化面试-2020-05-25","date":"2020-05-25T12:20:53.927Z","updated":"2020-06-18T08:18:08.871Z","comments":true,"path":"undefined/276e.html","link":"","permalink":"http://fyvan.github.io/undefined/276e.html","excerpt":"","text":"1. 概述1.1 为什么要优化 系统的吞吐量瓶颈往往出现在数据库的访问速度上 随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢 数据是存放在磁盘上的，读写速度无法和内存相比 1.2 如何优化 设计数据库时：数据库表、字段的设计，存储引擎 利用好MySQL自身提供的功能，如索引等 横向扩展：MySQL集群、负载均衡、读写分离 SQL语句的优化（收效甚微） 2. 字段设计 字段类型的选择，设计规范，范式，常见设计案例 2.1 原则：尽量使用整型表示字符串2.1.1存储IPINET_ATON(str)，address to number INET_NTOA(number)，number to address 2.1.2 MySQL内部的枚举类型（单选）和集合（多选）类型但是因为维护成本较高因此不常使用，使用关联表的方式来替代enum 2.2 原则：定长和非定长数据类型的选择 decimal不会损失精度，存储空间会随数据的增大而增大。double占用固定空间，较大数的存储会损失精度。非定长的还有varchar、text 2.2.1 金额 对数据的精度要求较高，小数的运算和存储存在精度问题（不能将所有小数转换成二进制） 2.2.2 定点数decimalprice decimal(8,2)有2位小数的定点数，定点数支持很大的数（甚至是超过int,bigint存储范围的数） 2.2.3 小单位大数额避免出现小数元-&gt;分 2.2.4字符串存储定长char，非定长varchar、text（上限65535，其中varchar还会消耗1-3字节记录长度，而text使用额外空间记录长度） 2.3 原则：尽可能选择小的数据类型和指定短的长度2.4 原则：尽可能使用 not null非null字段的处理要比null字段的处理高效些！且不需要判断是否为null。 null在MySQL中，不好处理，存储需要额外空间，运算也需要特殊的运算符。如select null = null和select null &lt;&gt; null（&lt;&gt;为不等号）有着同样的结果，只能通过is null和is not null来判断字段是否为null。 如何存储？MySQL中每条记录都需要额外的存储空间，表示每个字段是否为null。因此通常使用特殊的数据进行占位，比如int not null default 0、string not null default ‘’ 2.5 原则：字段注释要完整，见名知意2.6 原则：单表字段不宜过多二三十个就极限了 2.7 原则：可以预留字段 在使用以上原则之前首先要满足业务需求 3. 关联表的设计 外键foreign key只能实现一对一或一对多的映射 3.1 一对一如商品的基本信息（item）和商品的详细信息（item_intro），通常使用相同的主键或者增加一个外键字段（item_id） 3.2 一对多使用外键 3.3 多对多单独新建一张表将多对多拆分成两个一对多 4. 范式 Normal Format 数据表的设计规范，一套越来越严格的规范体系（如果需要满足N范式，首先要满足N-1范式）。N 4.1 第一范式1NF：字段原子性字段原子性，字段不可再分割。 关系型数据库，默认满足第一范式 注意比较容易出错的一点，在一对多的设计中使用逗号分隔多个外键，这种方法虽然存储方便，但不利于维护和索引（比如查找带标签java的文章） 4.2 第二范式：消除对主键的部分依赖 即在表中加上一个与业务逻辑无关的字段作为主键 主键：可以唯一标识记录的字段或者字段集合。 course_name course_class weekday（周几） course_teacher MySQL 教育大楼1525 周一 张三 Java 教育大楼1521 周三 李四 MySQL 教育大楼1521 周五 张三 依赖：A字段可以确定B字段，则B字段依赖A字段。比如知道了下一节课是数学课，就能确定任课老师是谁。于是周几和下一节课和就能构成复合主键，能够确定去哪个教室上课，任课老师是谁等。但我们常常增加一个id作为主键，而消除对主键的部分依赖。 对主键的部分依赖：某个字段依赖复合主键中的一部分。 解决方案：新增一个独立字段作为主键。 4.3 第三范式：消除对主键的传递依赖传递依赖：B字段依赖于A，C字段又依赖于B。比如上例中，任课老师是谁取决于是什么课，是什么课又取决于主键id。因此需要将此表拆分为两张表日程表和课程表（独立数据独立建表）： id weekday course_class course_id 1001 周一 教育大楼1521 3546 course_id course_name course_teacher 3546 Java 张三 这样就减少了数据的冗余（即使周一至周日每天都有Java课，也只是course_id:3546出现了7次） 5. 存储引擎选择 早期问题：如何选择MyISAM和Innodb？ 现在不存在这个问题了，Innodb不断完善，从各个方面赶超MyISAM，也是MySQL默认使用的。 存储引擎Storage engine：MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。 5.1 功能差异show engines Engine Support Comment InnoDB DEFAULT Supports transactions, row-level locking, and foreign keys MyISAM YES MyISAM storage engine 5.2 存储差异 MyISAM Innodb 文件格式 数据和索引是分别存储的，数据.MYD，索引.MYI 数据和索引是集中存储的，.ibd 文件能否移动 能，一张表就对应.frm、MYD、MYI3个文件 否，因为关联的还有data下的其它文件 记录存储顺序 按记录插入顺序保存 按主键大小有序插入 空间碎片（删除记录并flush table 表名之后，表文件大小不变） 产生。定时整理：使用命令optimize table 表名实现 不产生 事务 不支持 支持 外键 不支持 支持 锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的） 表级锁定 行级锁定、表级锁定，锁定力度小并发能力高 锁扩展 表级锁（table-level lock）：lock tables &lt;table_name1&gt;,&lt;table_name2&gt;... read/write，unlock tables &lt;table_name1&gt;,&lt;table_name2&gt;...。其中read是共享锁，一旦锁定任何客户端都不可读；write是独占/写锁，只有加锁的客户端可读可写，其他客户端既不可读也不可写。锁定的是一张表或几张表。 行级锁（row-level lock）：锁定的是一行或几行记录。共享锁：select * from &lt;table_name&gt; where &lt;条件&gt; LOCK IN SHARE MODE;，对查询的记录增加共享锁；select * from &lt;table_name&gt; where &lt;条件&gt; FOR UPDATE;，对查询的记录增加排他锁。这里值得注意的是：innodb的行锁，其实是一个子范围锁，依据条件锁定部分范围，而不是就映射到具体的行上，因此还有一个学名：间隙锁。比如select * from stu where id &lt; 20 LOCK IN SHARE MODE会锁定id在20左右以下的范围，你可能无法插入id为18或22的一条新纪录。 5.3 选择依据如果没有特别的需求，使用默认的Innodb即可。 MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键保证数据完整性。比如OA自动化办公系统。 6. 索引 关键字与数据的映射关系称为索引（==包含关键字和对应的记录在磁盘中的地址==）。关键字是从数据当中提取的用于标识、检索数据的特定内容。 6.1 索引检索为什么快？ 关键字相对于数据本身，数据量小 关键字是有序的，二分查找可快速确定位置 图书馆为每本书都加了索引号（类别-楼层-书架）、字典为词语解释按字母顺序编写目录等都用到了索引。 6.2 MySQL中索引类型 普通索引（key），唯一索引（unique key），主键索引（primary key），全文索引（fulltext key） 三种索引的索引方式是一样的，只不过对索引的关键字有不同的限制： 普通索引：对关键字没有限制 唯一索引：要求记录提供的关键字不能重复 主键索引：要求关键字唯一且不为null 6.3 索引管理语法6.3.1 查看索引show create table 表名`： desc 表名 6.3.2 创建索引6.3.2.1 创建表之后建立索引create TABLE user_index( id int auto_increment primary key, first_name varchar(16), last_name VARCHAR(16), id_card VARCHAR(18), information text ); -- 更改表结构 alter table user_index -- 创建一个first_name和last_name的复合索引，并命名为name add key name (first_name,last_name), -- 创建一个id_card的唯一索引，默认以字段名作为索引名 add UNIQUE KEY (id_card), -- 鸡肋，全文索引不支持中文 add FULLTEXT KEY (information); show create table user_index 6.3.2.2 创建表时指定索引CREATE TABLE user_index2 ( id INT auto_increment PRIMARY KEY, first_name VARCHAR (16), last_name VARCHAR (16), id_card VARCHAR (18), information text, KEY name (first_name, last_name), FULLTEXT KEY (information), UNIQUE KEY (id_card) ); 6.3.3 删除索引根据索引名删除普通索引、唯一索引、全文索引：alter table 表名 drop KEY 索引名 alter table user_index drop KEY name; alter table user_index drop KEY id_card; alter table user_index drop KEY information; 删除主键索引：alter table 表名 drop primary key（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）： 需要取消自增长再行删除： alter table user_index -- 重新定义字段 MODIFY id int, drop PRIMARY KEY 但通常不会删除主键，因为设计主键一定与业务逻辑无关。 6.4 执行计划explainCREATE TABLE innodb1 ( id INT auto_increment PRIMARY KEY, first_name VARCHAR (16), last_name VARCHAR (16), id_card VARCHAR (18), information text, KEY name (first_name, last_name), FULLTEXT KEY (information), UNIQUE KEY (id_card) ); insert into innodb1 (first_name,last_name,id_card,information) values ('张','三','1001','华山派'); 我们可以通过explain selelct来分析SQL语句执行前的执行计划： 由上图可看出此SQL语句是按照主键索引来检索的。 执行计划是：当执行SQL语句时，首先会分析、优化，形成执行计划，在按照执行计划执行。 6.5 索引使用场景（重点）6.5.1 where 上图中，根据id查询记录，因为id字段仅建立了主键索引，因此此SQL执行可选的索引只有主键索引，如果有多个，最终会选一个较优的作为检索的依据。 -- 增加一个没有建立索引的字段 alter table innodb1 add sex char(1); -- 按sex检索时可选的索引为null EXPLAIN SELECT * from innodb1 where sex='男'; 可以尝试在一个字段未建立索引时，根据该字段查询的效率，然后对该字段建立索引（alter table 表名 add index(字段名)），同样的SQL执行的效率，你会发现查询效率会有明显的提升（数据量越大越明显）。 6.5.2 order by当我们使用order by将查询结果按照某个字段排序时，如果该字段没有建立索引，那么执行计划会将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），这个操作是很影响性能的，因为需要将查询涉及到的所有数据从磁盘中读到内存（如果单条数据过大或者数据量过多都会降低效率），更无论读到内存之后的排序了。 但是如果我们对该字段建立索引alter table 表名 add index(字段名)，那么由于索引本身是有序的，因此直接按照索引的顺序和映射关系逐条取出数据即可。而且如果分页的，那么只用取出索引表某个范围内的索引对应的数据，而不用像上述那取出所有数据进行排序再返回某个范围内的数据。（从磁盘取数据是最影响性能的） 6.5.3 join 对join语句匹配关系（on）涉及的字段建立索引能够提高效率 6.5.4 索引覆盖如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后==只写必要的查询字段==，以增加索引覆盖的几率。 这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。 6.6 语法细节（要点） 在满足索引使用的场景下（where/order by/join on或索引覆盖），索引也不一定被使用 6.6.1 字段要独立出现比如下面两条SQL语句在语义上相同，但是第一条会使用主键索引而第二条不会。 select * from user where id = 20-1; select * from user where id+1 = 20; 6.6.2 like查询，不能以通配符开头比如搜索标题包含mysql的文章： select * from article where title like '%mysql%'; 这种SQL的执行计划用不了索引（like语句匹配表达式以通配符开头），因此只能做全表扫描，效率极低，在实际工程中几乎不被采用。而一般会使用第三方提供的支持中文的全文索引来做。 但是 关键字查询 热搜提醒功能还是可以做的，比如键入mysql之后提醒mysql 教程、mysql 下载、mysql 安装步骤等。用到的语句是： select * from article where title like 'mysql%'; 这种like是可以利用索引的（当然前提是title字段建立过索引）。 6.6.3 复合索引只对第一个字段有效建立复合索引： alter table person add index(first_name,last_name); 其原理就是将索引先按照从first_name中提取的关键字排序，如果无法确定先后再按照从last_name提取的关键字排序，也就是说该索引表只是按照记录的first_name字段值有序。 因此select * from person where first_name = ?是可以利用索引的，而select * from person where last_name = ?无法利用索引。 那么该复合索引的应用场景是什么？组合查询 比如对于select * person from first_name = ? and last_name = ?，复合索引就比对first_name和last_name单独建立索引要高效些。很好理解，复合索引首先二分查找与first_name = ?匹配的记录，再在这些记录中二分查找与last_name匹配的记录，只涉及到一张索引表。而分别单独建立索引则是在first_name索引表中二分找出与first_name = ?匹配的记录，再在last_name索引表中二分找出与last_name = ?的记录，两者取交集。 6.6.4 or，两边条件都有索引可用 一但有一边无索引可用就会导致整个SQL语句的全表扫描 6.6.5 状态值，不容易使用到索引如性别、支付状态等状态值字段往往只有极少的几种取值可能，这种字段即使建立索引，也往往利用不上。这是因为，一个状态值可能匹配大量的记录，这种情况MySQL会认为利用索引比全表扫描的效率低，从而弃用索引。索引是随机访问磁盘，而全表扫描是顺序访问磁盘，这就好比有一栋20层楼的写字楼，楼底下的索引牌上写着某个公司对应不相邻的几层楼，你去公司找人，与其按照索引牌的提示去其中一层楼没找到再下来看索引牌再上楼，不如从1楼挨个往上找到顶楼。 6.7 如何创建索引 建立基础索引：在where、order by、join字段上建立索引。 优化，组合索引：基于业务逻辑 如果条件经常性出现在一起，那么可以考虑将多字段索引升级为复合索引 如果通过增加个别字段的索引，就可以出现索引覆盖，那么可以考虑为该字段建立索引 查询时，不常用到的索引，应该删除掉 6.8 前缀索引语法：index(field(10))，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。 前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。 实操的难度：在于前缀截取的长度。 我们可以利用select count(*)/count(distinct left(password,prefixLen));，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录） 6.9 索引的存储结构6.9.1 BTreebtree（多路平衡查找树）是一种广泛应用于==磁盘上实现索引功能==的一种数据结构，也是大多数数据库索引表的实现。 以add index(first_name,last_name)为例： BTree的一个node可以存储多个关键字，node的大小取决于计算机的文件系统，因此我们可以通过减小索引字段的长度使结点存储更多的关键字。如果node中的关键字已满，那么可以通过每个关键字之间的子节点指针来拓展索引表，但是不能破坏结构的有序性，比如按照first_name第一有序、last_name第二有序的规则，新添加的韩香就可以插到韩康之后。白起 &lt; 韩飞 &lt; 韩康 &lt; 李世民 &lt; 赵奢 &lt; 李寻欢 &lt; 王语嫣 &lt; 杨不悔。这与二叉搜索树的思想是一样的，只不过二叉搜索树的查找效率是log(2,N)（以2为底N的对数），而BTree的查找效率是log(x,N)（其中x为node的关键字数量，可以达到1000以上）。 从log(1000+,N)可以看出，少量的磁盘读取即可做到大量数据的遍历，这也是btree的设计目的。 6.9.2 B+Tree聚簇结构聚簇结构（也是在BTree上升级改造的）中，关键字和记录是存放在一起的。 在MySQL中，仅仅只有Innodb的==主键索引为聚簇结构==，其它的索引包括Innodb的非主键索引都是典型的BTree结构。 6.9.3 哈希索引在索引被载入内存时，使用哈希结构来存储。 7. 查询缓存 缓存select语句的查询结果 7.1 在配置文件中开启缓存windows上是my.ini，linux上是my.cnf 在[mysqld]段中配置query_cache_type： 0：不开启 1：开启，默认缓存所有，需要在SQL语句中增加select sql-no-cache提示来放弃缓存 2：开启，默认都不缓存，需要在SQL语句中增加select sql-cache来主动缓存（==常用==） 更改配置后需要重启以使配置生效，重启后可通过show variables like ‘query_cache_type’;来查看： show variables like 'query_cache_type'; query_cache_type DEMAND 7.2 在客户端设置缓存大小通过配置项query_cache_size来设置： show variables like 'query_cache_size'; query_cache_size 0 set global query_cache_size=64*1024*1024; show variables like 'query_cache_size'; query_cache_size 67108864 7.2 将查询结果缓存select sql_cache * from user; 7.3 重置缓存reset query cache; 7.4 缓存失效问题（大问题）当数据表改动时，基于该数据表的任何缓存都会被删除。（表层面的管理，不是记录层面的管理，因此失效率较高） 7.5 注意事项 应用程序，不应该关心query cache的使用情况。可以尝试使用，但不能由query cache决定业务逻辑，因为query cache由DBA来管理。 缓存是以SQL语句为key存储的，因此即使SQL语句功能相同，但如果多了一个空格或者大小写有差异都会导致匹配不到缓存。 8. 分区一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。 当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，==保证其单个文件的执行效率==。 最常见的分区方案是按id分区，如下将id的哈希值对10取模将数据均匀分散到10个.ibd存储文件中： create table article( id int auto_increment PRIMARY KEY, title varchar(64), content text )PARTITION by HASH(id) PARTITIONS 10 查看data目录： 服务端的表分区对于客户端是透明的，客户端还是照常插入数据，但服务端会按照分区算法分散存储数据。 8.1 MySQL提供的分区算法 分区依据的字段必须是主键的一部分，分区是为了快速定位数据，因此该字段的搜索频次较高应作为强检索字段，否则依照该字段分区毫无意义 8.1.1 hash(field)相同的输入得到相同的输出。输出的结果跟输入是否具有规律无关。==仅适用于整型字段== 8.1.2 key(field)和hash(field)的性质一样，只不过key是==处理字符串==的，比hash()多了一步从字符串中计算出一个整型在做取模操作。 create table article_key( id int auto_increment, title varchar(64), content text, PRIMARY KEY (id,title) -- 要求分区依据字段必须是主键的一部分 )PARTITION by KEY(title) PARTITIONS 10 8.1.3 range算法是一种条件分区算法，按照数据大小范围分区（将数据使用某种条件，分散到不同的分区中）。 如下，按文章的发布时间将数据按照2018年8月、9月、10月分区存放： create table article_range( id int auto_increment, title varchar(64), content text, created_time int, -- 发布时间到1970-1-1的毫秒数 PRIMARY KEY (id,created_time) -- 要求分区依据字段必须是主键的一部分 )charset=utf8 PARTITION BY RANGE(created_time)( PARTITION p201808 VALUES less than (1535731199), -- select UNIX_TIMESTAMP('2018-8-31 23:59:59') PARTITION p201809 VALUES less than (1538323199), -- 2018-9-30 23:59:59 PARTITION p201810 VALUES less than (1541001599) -- 2018-10-31 23:59:59 ); 注意：条件运算符只能使用==less than==，这以为着较小的范围要放在前面，比如上述p201808,p201819,p201810分区的定义顺序依照created_time数值范围从小到大，不能颠倒。 insert into article_range values(null,'MySQL优化','内容示例',1535731180); flush tables; -- 使操作立即刷新到磁盘文件 由于插入的文章的发布时间1535731180小于1535731199（2018-8-31 23:59:59），因此被存储到p201808分区中，这种算法的存储到哪个分区取决于数据状况。 8.1.4 list算法也是一种条件分区，按照列表值分区（in (值列表)）。 create table article_list( id int auto_increment, title varchar(64), content text, status TINYINT(1), -- 文章状态：0-草稿，1-完成但未发布，2-已发布 PRIMARY KEY (id,status) -- 要求分区依据字段必须是主键的一部分 )charset=utf8 PARTITION BY list(status)( PARTITION writing values in(0,1), -- 未发布的放在一个分区 PARTITION published values in (2) -- 已发布的放在一个分区 ); insert into article_list values(null,'mysql优化','内容示例',0); flush tables; 8.2 分区管理语法8.2.1 range/list8.2.1.1增加分区前文中我们尝试使用range对文章按照月份归档，随着时间的增加，我们需要增加一个月份： alter table article_range add partition( partition p201811 values less than (1543593599) -- select UNIX_TIMESTAMP('2018-11-30 23:59:59') -- more ); 8.2.1.2删除分区alter table article_range drop PARTITION p201808 注意：删除分区后，分区中原有的数据也会随之删除！ 8.2.2key/hash8.2.2.1 新增分区alter table article_key add partition partitions 4 8.2.2.2 销毁分区alter table article_key coalesce partition 6 key/hash分区的管理不会删除数据，但是每一次调整（新增或销毁分区）都会将所有的数据重写分配到新的分区上。==效率极低==，最好在设计阶段就考虑好分区策略。 8.3 分区的使用当数据表中的数据量很大时，分区带来的效率提升才会显现出来。 只有检索字段为分区字段时，分区带来的效率提升才会比较明显。因此，==分区字段的选择很重要==，并且==业务逻辑要尽可能地根据分区字段做相应调整==（尽量使用分区字段作为查询条件）。 9. 水平分割和垂直分割 水平分割：通过建立结构相同的几张表分别存储数据 垂直分割：将经常一起使用的字段放在一个单独的表中，分割后的表记录之间是一一对应关系。 9.1 分表原因 为数据库减压 分区算法局限 数据库支持不完善（5.1之后mysql才支持分区操作） 9.2 id重复的解决方案 借用第三方应用如memcache、redis的id自增器 单独建一张只包含id一个字段的表，每次自增该字段作为数据记录的id 10. 集群 横向扩展：从根本上（单机的硬件处理能力有限）提升数据库性能 。由此而生的相关技术：读写分离、负载均衡 10.1 安装和配置主从复制10.1.1 环境 Red Hat Enterprise Linux Server release 7.0 (Maipo)（虚拟机） mysql5.7（下载地址） 10.1.2 安装和配置 解压到对外提供的服务的目录（我自己专门创建了一个/export/server来存放） tar xzvf mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz -C /export/server cd /export/server mv mysql-5.7.23-linux-glibc2.12-x86_64 mysql 添加mysql目录的所属组和所属者： groupadd mysql useradd -r -g mysql mysql cd /export/server chown -R mysql:mysql mysql/ chmod -R 755 mysql/ 创建mysql数据存放目录（其中/export/data是我创建专门用来为各种服务存放数据的目录） mkdir /export/data/mysql 初始化mysql服务 cd /export/server/mysql ./bin/mysqld --basedir=/export/server/mysql --datadir=/export/data/mysql --user=mysql --pid-file=/export/data/mysql/mysql.pid --initialize 如果成功会显示mysql的root账户的初始密码，记下来以备后续登录。如果报错缺少依赖，则使用yum instally依次安装即可 配置my.cnf vim /etc/my.cnf [mysqld] basedir=/export/server/mysql datadir=/export/data/mysql socket=/tmp/mysql.sock user=mysql server-id=10 # 服务id，在集群时必须唯一，建议设置为IP的第四段 port=3306 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd [mysqld_safe] log-error=/export/data/mysql/error.log pid-file=/export/data/mysql/mysql.pid # # include all files from the config directory # !includedir /etc/my.cnf.d 将服务添加到开机自动启动 cp /export/server/mysql/support-files/mysql.server /etc/init.d/mysqld 启动服务 service mysqld start 配置环境变量，在/etc/profile中添加如下内容 # mysql env MYSQL_HOME=/export/server/mysql MYSQL_PATH=$MYSQL_HOME/bin PATH=$PATH:$MYSQL_PATH export PATH 使配置即可生效 source /etc/profile 使用root登录 mysql -uroot -p # 这里填写之前初始化服务时提供的密码 登录上去之后，更改root账户密码（我为了方便将密码改为root），否则操作数据库会报错 set password=password('root'); flush privileges; 设置服务可被所有远程客户端访问 use mysql; update user set host='%' where user='root'; flush privileges; 这样就可以在宿主机使用navicat远程连接虚拟机linux上的mysql了 10.1.3配置主从节点10.1.3.1 配置master 以linux（192.168.10.10）上的mysql为master，宿主机（192.168.10.1）上的mysql为slave配置主从复制。 修改master的my.cnf如下 [mysqld] basedir=/export/server/mysql datadir=/export/data/mysql socket=/tmp/mysql.sock user=mysql server-id=10 port=3306 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd log-bin=mysql-bin # 开启二进制日志 expire-logs-days=7 # 设置日志过期时间，避免占满磁盘 binlog-ignore-db=mysql # 不使用主从复制的数据库 binlog-ignore-db=information_schema binlog-ignore-db=performation_schema binlog-ignore-db=sys binlog-do-db=test #使用主从复制的数据库 [mysqld_safe] log-error=/export/data/mysql/error.log pid-file=/export/data/mysql/mysql.pid # # include all files from the config directory # !includedir /etc/my.cnf.d 重启master service mysqld restart 登录master查看配置是否生效（ON即为开启，默认为OFF）： mysql> show variables like 'log_bin'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_bin | ON | +---------------+-------+ 在master的数据库中建立备份账号：backup为用户名，%表示任何远程地址，用户back可以使用密码1234通过任何远程客户端连接master grant replication slave on *.* to 'backup'@'%' identified by '1234' 查看user表可以看到我们刚创建的用户： mysql> use mysql mysql> select user,authentication_string,host from user; +---------------+-------------------------------------------+-----------+ | user | authentication_string | host | +---------------+-------------------------------------------+-----------+ | root | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B | % | | mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost | | mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | localhost | | backup | *A4B6157319038724E3560894F7F932C8886EBFCF | % | +---------------+-------------------------------------------+-----------+ 新建test数据库，创建一个article表以备后续测试 CREATE TABLE `article` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` varchar(64) DEFAULT NULL, `content` text, PRIMARY KEY (`id`) ) CHARSET=utf8; 重启服务并刷新数据库状态到存储文件中（with read lock表示在此过程中，客户端只能读数据，以便获得一个一致性的快照） [root@zhenganwen ~]# service mysqld restart Shutting down MySQL.... SUCCESS! Starting MySQL. SUCCESS! [root@zhenganwen mysql]# mysql -uroot -proot mysql> flush tables with read lock; Query OK, 0 rows affected (0.00 sec) 查看master上当前的二进制日志和偏移量（记一下其中的File和Position） mysql> show master status \\G *************************** 1. row *************************** File: mysql-bin.000002 Position: 154 Binlog_Do_DB: test Binlog_Ignore_DB: mysql,information_schema,performation_schema,sys Executed_Gtid_Set: 1 row in set (0.00 sec) File表示实现复制功能的日志，即上图中的Binary log；Position则表示Binary log日志文件的偏移量之后的都会同步到slave中，那么在偏移量之前的则需要我们手动导入。 主服务器上面的任何修改都会保存在二进制日志Binary log里面，从服务器上面启动一个I/O thread（实际上就是一个主服务器的客户端进程），连接到主服务器上面请求读取二进制日志，然后把读取到的二进制日志写到本地的一个Realy log里面。从服务器上面开启一个SQL thread定时检查Realy log，如果发现有更改立即把更改的内容在本机上面执行一遍。 如果一主多从的话，这时主库既要负责写又要负责为几个从库提供二进制日志。此时可以稍做调整，将二进制日志只给某一从，这一从再开启二进制日志并将自己的二进制日志再发给其它从。或者是干脆这个从不记录只负责将二进制日志转发给其它从，这样架构起来性能可能要好得多，而且数据之间的延时应该也稍微要好一些 手动导入，从master中导出数据 mysqldump -uroot -proot -hlocalhost test > /export/data/test.sql 将test.sql中的内容在slave上执行一遍。 10.1.3.2 配置slave 修改slave的my.ini文件中的[mysqld]部分 log-bin=mysql server-id=1 #192.168.10.1 保存修改后重启slave，WIN+R-&gt;services.msc-&gt;MySQL5.7-&gt;重新启动 登录slave检查log_bin是否以被开启： show VARIABLES like 'log_bin'; 配置与master的同步复制： stop slave; change master to master_host='192.168.10.10', -- master的IP master_user='backup', -- 之前在master上创建的用户 master_password='1234', master_log_file='mysql-bin.000002', -- master上 show master status \\G 提供的信息 master_log_pos=154; 启用slave节点并查看状态 mysql> start slave; mysql> show slave status \\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.10.10 Master_User: backup Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000002 Read_Master_Log_Pos: 154 Relay_Log_File: DESKTOP-KUBSPE0-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 537 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 10 Master_UUID: f68774b7-0b28-11e9-a925-000c290abe05 Master_Info_File: C:\\ProgramData\\MySQL\\MySQL Server 5.7\\Data\\master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec) 注意查看第4、14、15三行，若与我一致，表示slave配置成功 10.1.4 测试 关闭master的读取锁定 mysql> unlock tables; Query OK, 0 rows affected (0.00 sec) 向master中插入一条数据 mysql> use test mysql> insert into article (title,content) values ('mysql master and slave','record the cluster building succeed!:)'); Query OK, 1 row affected (0.00 sec) 查看slave是否自动同步了数据 mysql> insert into article (title,content) values ('mysql master and slave','record the cluster building succeed!:)'); Query OK, 1 row affected (0.00 sec) 至此，主从复制的配置成功！：) 使用mysqlreplicate命令快速搭建 Mysql 主从复制 10.2 读写分离读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。 10.2.1 方案一、定义两种连接就像我们在学JDBC时定义的DataBase一样，我们可以抽取出ReadDataBase,WriteDataBase implements DataBase，但是这种方式无法利用优秀的线程池技术如DruidDataSource帮我们管理连接，也无法利用Spring AOP让连接对DAO层透明。 10.2.2 方案二、使用Spring AOP如果能够使用Spring AOP解决数据源切换的问题，那么就可以和Mybatis、Druid整合到一起了。 我们在整合Spring1和Mybatis时，我们只需写DAO接口和对应的SQL语句，那么DAO实例是由谁创建的呢？实际上就是Spring帮我们创建的，它通过我们注入的数据源，帮我们完成从中获取数据库连接、使用连接执行 SQL 语句的过程以及最后归还连接给数据源的过程。 如果我们能在调用DAO接口时根据接口方法命名规范（增addXXX/createXXX、删deleteXX/removeXXX、改updateXXXX、查selectXX/findXXX/getXX/queryXXX）动态地选择数据源（读数据源对应连接master而写数据源对应连接slave），那么就可以做到读写分离了。 10.2.2.1 项目结构 10.2.2.2引入依赖其中，为了方便访问数据库引入了mybatis和druid，实现数据源动态切换主要依赖spring-aop和spring-aspects &lt;dependencies> &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>1.3.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis&lt;/artifactId> &lt;version>3.4.6&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-core&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-aop&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-jdbc&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>druid&lt;/artifactId> &lt;version>1.1.6&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>6.0.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-context&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-aspects&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;version>1.16.22&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-test&lt;/artifactId> &lt;version>5.0.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactId>junit&lt;/artifactId> &lt;version>4.12&lt;/version> &lt;/dependency> &lt;/dependencies> 10.2.2.3 数据类package top.zhenganwen.mysqloptimize.entity; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class Article { private int id; private String title; private String content; } 10.2.2.4 spring配置文件其中RoutingDataSourceImpl是实现动态切换功能的核心类，稍后介绍。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"> &lt;context:property-placeholder location=\"db.properties\">&lt;/context:property-placeholder> &lt;context:component-scan base-package=\"top.zhenganwen.mysqloptimize\"/> &lt;bean id=\"slaveDataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"> &lt;property name=\"driverClassName\" value=\"${db.driverClass}\"/> &lt;property name=\"url\" value=\"${master.db.url}\">&lt;/property> &lt;property name=\"username\" value=\"${master.db.username}\">&lt;/property> &lt;property name=\"password\" value=\"${master.db.password}\">&lt;/property> &lt;/bean> &lt;bean id=\"masterDataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"> &lt;property name=\"driverClassName\" value=\"${db.driverClass}\"/> &lt;property name=\"url\" value=\"${slave.db.url}\">&lt;/property> &lt;property name=\"username\" value=\"${slave.db.username}\">&lt;/property> &lt;property name=\"password\" value=\"${slave.db.password}\">&lt;/property> &lt;/bean> &lt;bean id=\"dataSourceRouting\" class=\"top.zhenganwen.mysqloptimize.dataSource.RoutingDataSourceImpl\"> &lt;property name=\"defaultTargetDataSource\" ref=\"masterDataSource\">&lt;/property> &lt;property name=\"targetDataSources\"> &lt;map key-type=\"java.lang.String\" value-type=\"javax.sql.DataSource\"> &lt;entry key=\"read\" value-ref=\"slaveDataSource\"/> &lt;entry key=\"write\" value-ref=\"masterDataSource\"/> &lt;/map> &lt;/property> &lt;property name=\"methodType\"> &lt;map key-type=\"java.lang.String\" value-type=\"java.lang.String\"> &lt;entry key=\"read\" value=\"query,find,select,get,load,\">&lt;/entry> &lt;entry key=\"write\" value=\"update,add,create,delete,remove,modify\"/> &lt;/map> &lt;/property> &lt;/bean> &lt;!-- Mybatis文件 --> &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"> &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\" /> &lt;property name=\"dataSource\" ref=\"dataSourceRouting\" /> &lt;property name=\"mapperLocations\" value=\"mapper/*.xml\"/> &lt;/bean> &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"> &lt;property name=\"basePackage\" value=\"top.zhenganwen.mysqloptimize.mapper\" /> &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\" /> &lt;/bean> &lt;/beans> dp.properties dp.properties master.db.url=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC master.db.username=root master.db.password=root slave.db.url=jdbc:mysql://192.168.10.10:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC slave.db.username=root slave.db.password=root db.driverClass=com.mysql.jdbc.Driver mybatis-config.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"> &lt;configuration> &lt;typeAliases> &lt;typeAlias type=\"top.zhenganwen.mysqloptimize.entity.Article\" alias=\"Article\"/> &lt;/typeAliases> &lt;/configuration> 10.2.2.5 mapper接口和配置文件ArticleMapper.java package top.zhenganwen.mysqloptimize.mapper; import org.springframework.stereotype.Repository; import top.zhenganwen.mysqloptimize.entity.Article; import java.util.List; @Repository public interface ArticleMapper { List&lt;Article> findAll(); void add(Article article); void delete(int id); } ArticleMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?> &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" > &lt;mapper namespace=\"top.zhenganwen.mysqloptimize.mapper.ArticleMapper\"> &lt;select id=\"findAll\" resultType=\"Article\"> select * from article &lt;/select> &lt;insert id=\"add\" parameterType=\"Article\"> insert into article (title,content) values (#{title},#{content}) &lt;/insert> &lt;delete id=\"delete\" parameterType=\"int\"> delete from article where id=#{id} &lt;/delete> &lt;/mapper> 10.2.2.6 核心类 RoutingDataSourceImpl package top.zhenganwen.mysqloptimize.dataSource; import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource; import java.util.*; /** * RoutingDataSourceImpl class * 数据源路由 * * @author zhenganwen, blog:zhenganwen.top * @date 2018/12/29 */ public class RoutingDataSourceImpl extends AbstractRoutingDataSource { /** * key为read或write * value为DAO方法的前缀 * 什么前缀开头的方法使用读数据员，什么开头的方法使用写数据源 */ public static final Map&lt;String, List&lt;String>> METHOD_TYPE_MAP = new HashMap&lt;String, List&lt;String>>(); /** * 由我们指定数据源的id，由Spring切换数据源 * * @return */ @Override protected Object determineCurrentLookupKey() { System.out.println(\"数据源为：\"+DataSourceHandler.getDataSource()); return DataSourceHandler.getDataSource(); } public void setMethodType(Map&lt;String, String> map) { for (String type : map.keySet()) { String methodPrefixList = map.get(type); if (methodPrefixList != null) { METHOD_TYPE_MAP.put(type, Arrays.asList(methodPrefixList.split(\",\"))); } } } } 它的主要功能是，本来我们只配置一个数据源，因此Spring动态代理DAO接口时直接使用该数据源，现在我们有了读、写两个数据源，我们需要加入一些自己的逻辑来告诉调用哪个接口使用哪个数据源（读数据的接口使用slave，写数据的接口使用master。这个告诉Spring该使用哪个数据源的类就是AbstractRoutingDataSource，必须重写的方法determineCurrentLookupKey返回数据源的标识，结合spring配置文件（下段代码的5，6两行） &lt;bean id=\"dataSourceRouting\" class=\"top.zhenganwen.mysqloptimize.dataSource.RoutingDataSourceImpl\"> &lt;property name=\"defaultTargetDataSource\" ref=\"masterDataSource\">&lt;/property> &lt;property name=\"targetDataSources\"> &lt;map key-type=\"java.lang.String\" value-type=\"javax.sql.DataSource\"> &lt;entry key=\"read\" value-ref=\"slaveDataSource\"/> &lt;entry key=\"write\" value-ref=\"masterDataSource\"/> &lt;/map> &lt;/property> &lt;property name=\"methodType\"> &lt;map key-type=\"java.lang.String\" value-type=\"java.lang.String\"> &lt;entry key=\"read\" value=\"query,find,select,get,load,\">&lt;/entry> &lt;entry key=\"write\" value=\"update,add,create,delete,remove,modify\"/> &lt;/map> &lt;/property> &lt;/bean> 如果determineCurrentLookupKey返回read那么使用slaveDataSource，如果返回write就使用masterDataSource。 DataSourceHandler package top.zhenganwen.mysqloptimize.dataSource; /** * DataSourceHandler class * &lt;p> * 将数据源与线程绑定，需要时根据线程获取 * * @author zhenganwen, blog:zhenganwen.top * @date 2018/12/29 */ public class DataSourceHandler { /** * 绑定的是read或write，表示使用读或写数据源 */ private static final ThreadLocal&lt;String> holder = new ThreadLocal&lt;String>(); public static void setDataSource(String dataSource) { System.out.println(Thread.currentThread().getName()+\"设置了数据源类型\"); holder.set(dataSource); } public static String getDataSource() { System.out.println(Thread.currentThread().getName()+\"获取了数据源类型\"); return holder.get(); } } DataSourceAspect package top.zhenganwen.mysqloptimize.dataSource; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.context.annotation.EnableAspectJAutoProxy; import org.springframework.stereotype.Component; import java.util.List; import java.util.Set; import static top.zhenganwen.mysqloptimize.dataSource.RoutingDataSourceImpl.METHOD_TYPE_MAP; /** * DataSourceAspect class * * 配置切面，根据方法前缀设置读、写数据源 * 项目启动时会加载该bean，并按照配置的切面（哪些切入点、如何增强）确定动态代理逻辑 * @author zhenganwen,blog:zhenganwen.top * @date 2018/12/29 */ @Component //声明这是一个切面，这样Spring才会做相应的配置，否则只会当做简单的bean注入 @Aspect @EnableAspectJAutoProxy public class DataSourceAspect { /** * 配置切入点：DAO包下的所有类的所有方法 */ @Pointcut(\"execution(* top.zhenganwen.mysqloptimize.mapper.*.*(..))\") public void aspect() { } /** * 配置前置增强，对象是aspect()方法上配置的切入点 */ @Before(\"aspect()\") public void before(JoinPoint point) { String className = point.getTarget().getClass().getName(); String invokedMethod = point.getSignature().getName(); System.out.println(\"对 \"+className+\"$\"+invokedMethod+\" 做了前置增强，确定了要使用的数据源类型\"); Set&lt;String> dataSourceType = METHOD_TYPE_MAP.keySet(); for (String type : dataSourceType) { List&lt;String> prefixList = METHOD_TYPE_MAP.get(type); for (String prefix : prefixList) { if (invokedMethod.startsWith(prefix)) { DataSourceHandler.setDataSource(type); System.out.println(\"数据源为：\"+type); return; } } } } } 10.2.2.7 测试读写分离 如何测试读是从slave中读的呢？可以将写后复制到slave中的数据更改，再读该数据就知道是从slave中读了。注意，一但对slave做了写操作就要重新手动将slave与master同步一下，否则主从复制就会失效。 package top.zhenganwen.mysqloptimize.dataSource; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import top.zhenganwen.mysqloptimize.entity.Article; import top.zhenganwen.mysqloptimize.mapper.ArticleMapper; @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = \"classpath:spring-mybatis.xml\") public class RoutingDataSourceTest { @Autowired ArticleMapper articleMapper; @Test public void testRead() { System.out.println(articleMapper.findAll()); } @Test public void testAdd() { Article article = new Article(0, \"我是新插入的文章\", \"测试是否能够写到master并且复制到slave中\"); articleMapper.add(article); } @Test public void testDelete() { articleMapper.delete(2); } } 10.3 负载均衡10.3.1 负载均衡算法 轮询 加权轮询：按照处理能力来加权 负载分配：依据当前的空闲状态（但是测试每个节点的内存使用率、CPU利用率等，再做比较选出最闲的那个，效率太低） 10.4 高可用在服务器架构时，为了保证服务器7x24不宕机在线状态，需要为每台单点服务器（由一台服务器提供服务的服务器，如写服务器、数据库中间件）提供冗余机。 对于写服务器来说，需要提供一台同样的写-冗余服务器，当写服务器健康时（写-冗余通过心跳检测），写-冗余作为一个从机的角色复制写服务器的内容与其做一个同步；当写服务器宕机时，写-冗余服务器便顶上来作为写服务器继续提供服务。对外界来说这个处理过程是透明的，即外界仅通过一个IP访问服务。 11. 典型SQL11.1 线上DDLDDL(Database Definition Language)是指数据库表结构的定义（create table）和维护（alter table）的语言。在线上执行DDL，在低于MySQL5.6版本时会导致全表被独占锁定，此时表处于维护、不可操作状态，这会导致该期间对该表的所有访问无法响应。但是在MySQL5.6之后，支持Online DDL，大大缩短了锁定时间。 优化技巧是采用的维护表结构的DDL（比如增加一列，或者增加一个索引），是==copy==策略。思路：创建一个满足新结构的新表，将旧表数据==逐条==导入（复制）到新表中，以保证==一次性锁定的内容少==（锁定的是正在导入的数据），同时旧表上可以执行其他任务。导入的过程中，将对旧表的所有操作以日志的形式记录下来，导入完毕后，将更新日志在新表上再执行一遍（确保一致性）。最后，新表替换旧表（在应用程序中完成，或者是数据库的rename，视图完成）。 但随着MySQL的升级，这个问题几乎淡化了。 11.2 数据库导入语句在恢复数据时，可能会导入大量的数据。此时为了快速导入，需要掌握一些技巧： 导入时先禁用索引和约束： alter table table-name disable keys 待数据导入完成之后，再开启索引和约束，一次性创建索引 alter table table-name enable keys 数据库如果使用的引擎是Innodb，那么它默认会给每条写指令加上事务（这也会消耗一定的时间），因此建议先手动开启事务，再执行一定量的批量导入，最后手动提交事务。 如果批量导入的SQL指令格式相同只是数据不同，那么你应该先prepare==预编译==一下，这样也能节省很多重复编译的时间。 11.3 limit offset,rows尽量保证不要出现大的offset，比如limit 10000,10相当于对已查询出来的行数弃掉前10000行后再取10行，完全可以加一些条件过滤一下（完成筛选），而不应该使用limit跳过已查询到的数据。这是一个==offset做无用功==的问题。对应实际工程中，要避免出现大页码的情况，尽量引导用户做条件过滤。 11.4 select * 要少用即尽量选择自己需要的字段select，但这个影响不是很大，因为网络传输多了几十上百字节也没多少延时，并且现在流行的ORM框架都是用的select *，只是我们在设计表的时候注意将大数据量的字段分离，比如商品详情可以单独抽离出一张商品详情表，这样在查看商品简略页面时的加载速度就不会有影响了。 11.5 order by rand()不要用它的逻辑就是随机排序（为每条数据生成一个随机数，然后根据随机数大小进行排序）。如select * from student order by rand() limit 5的执行效率就很低，因为它为表中的每条数据都生成随机数并进行排序，而我们只要前5条。 解决思路：在应用程序中，将随机的主键生成好，去数据库中利用主键检索。 11.6 单表和多表查询多表查询：join、子查询都是涉及到多表的查询。如果你使用explain分析执行计划你会发现多表查询也是一个表一个表的处理，最后合并结果。因此可以说单表查询将计算压力放在了应用程序上，而多表查询将计算压力放在了数据库上。 现在有ORM框架帮我们解决了单表查询带来的对象映射问题（查询单表时，如果发现有外键自动再去查询关联表，是一个表一个表查的）。 11.7 count(*)在MyISAM存储引擎中，会自动记录表的行数，因此使用count(*)能够快速返回。而Innodb内部没有这样一个计数器，需要我们手动统计记录数量，解决思路就是单独使用一张表： id table count 1 student 100 11.8 limit 1如果可以确定仅仅检索一条，建议加上limit 1，其实ORM框架帮我们做到了这一点（查询单条的操作都会自动加上limit 1）。 12. 慢查询日志 用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。 12.1 开启慢查询日志配置项：slow_query_log 可以使用show variables like ‘slov_query_log’查看是否开启，如果状态值为OFF，可以使用set GLOBAL slow_query_log = on来开启，它会在datadir下产生一个xxx-slow.log的文件。 12.2 设置临界时间配置项：long_query_time 查看：show VARIABLES like 'long_query_time'，单位秒 设置：set long_query_time=0.5 实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉 12.3 查看日志一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中 13. profile信息配置项：profiling 13.1 开启profileset profiling=on 开启后，所有的SQL执行的详细信息都会被自动记录下来 mysql> show variables like 'profiling'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | profiling | OFF | +---------------+-------+ 1 row in set, 1 warning (0.00 sec) mysql> set profiling=on; Query OK, 0 rows affected, 1 warning (0.00 sec) 13.2 查看profile信息show profiles mysql> show variables like 'profiling'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | profiling | ON | +---------------+-------+ 1 row in set, 1 warning (0.00 sec) mysql> insert into article values (null,'test profile',':)'); Query OK, 1 row affected (0.15 sec) mysql> show profiles; +----------+------------+-------------------------------------------------------+ | Query_ID | Duration | Query | +----------+------------+-------------------------------------------------------+ | 1 | 0.00086150 | show variables like 'profiling' | | 2 | 0.15027550 | insert into article values (null,'test profile',':)') | +----------+------------+-------------------------------------------------------+ 13.3 通过Query_ID查看某条SQL所有详细步骤的时间show profile for query Query_ID 上面show profiles的结果中，每个SQL有一个Query_ID，可以通过它查看执行该SQL经过了哪些步骤，各消耗了多场时间 14. 典型的服务器配置 以下的配置全都取决于实际的运行环境 max_connections，最大客户端连接数 mysql> show variables like 'max_connections'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 151 | +-----------------+-------+ table_open_cache，表文件句柄缓存（表数据是存储在磁盘上的，缓存磁盘文件的句柄方便打开文件读取数据） mysql> show variables like 'table_open_cache'; +------------------+-------+ | Variable_name | Value | +------------------+-------+ | table_open_cache | 2000 | +------------------+-------+ key_buffer_size，索引缓存大小（将从磁盘上读取的索引缓存到内存，可以设置大一些，有利于快速检索） mysql> show variables like 'key_buffer_size'; +-----------------+---------+ | Variable_name | Value | +-----------------+---------+ | key_buffer_size | 8388608 | +-----------------+---------+ innodb_buffer_pool_size，Innodb存储引擎缓存池大小（对于Innodb来说最重要的一个配置，如果所有的表用的都是Innodb，那么甚至建议将该值设置到物理内存的80%，Innodb的很多性能提升如索引都是依靠这个） mysql> show variables like 'innodb_buffer_pool_size'; +-------------------------+---------+ | Variable_name | Value | +-------------------------+---------+ | innodb_buffer_pool_size | 8388608 | +-------------------------+---------+ innodb_file_per_table（innodb中，表数据存放在.ibd文件中，如果将该配置项设置为ON，那么一个表对应一个ibd文件，否则所有innodb共享表空间） 15. 压测工具mysqlslap安装MySQL时附带了一个压力测试工具mysqlslap（位于bin目录下） 15.1 自动生成sql测试C:\\Users\\zaw>mysqlslap --auto-generate-sql -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 1.219 seconds Minimum number of seconds to run all queries: 1.219 seconds Maximum number of seconds to run all queries: 1.219 seconds Number of clients running queries: 1 Average number of queries per client: 0 15.2 并发测试C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=100 -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 3.578 seconds Minimum number of seconds to run all queries: 3.578 seconds Maximum number of seconds to run all queries: 3.578 seconds Number of clients running queries: 100 Average number of queries per client: 0 C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 5.718 seconds Minimum number of seconds to run all queries: 5.718 seconds Maximum number of seconds to run all queries: 5.718 seconds Number of clients running queries: 150 Average number of queries per client: 0 15.3 多轮测试C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 --iterations=10 -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Average number of seconds to run all queries: 5.398 seconds Minimum number of seconds to run all queries: 4.313 seconds Maximum number of seconds to run all queries: 6.265 seconds Number of clients running queries: 150 Average number of queries per client: 0 15.4 存储引擎测试C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 --iterations=3 --engine=innodb -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Running for engine innodb Average number of seconds to run all queries: 5.911 seconds Minimum number of seconds to run all queries: 5.485 seconds Maximum number of seconds to run all queries: 6.703 seconds Number of clients running queries: 150 Average number of queries per client: 0 C:\\Users\\zaw>mysqlslap --auto-generate-sql --concurrency=150 --iterations=3 --engine=myisam -uroot -proot mysqlslap: [Warning] Using a password on the command line interface can be insecure. Benchmark Running for engine myisam Average number of seconds to run all queries: 53.104 seconds Minimum number of seconds to run all queries: 46.843 seconds Maximum number of seconds to run all queries: 60.781 seconds Number of clients running queries: 150 Average number of queries per client: 0 转载自：掘金-程序员乔戈里 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://fyvan.github.io/tags/MySql/"}],"author":"fyang"},{"title":"SpringMVC运行流程","slug":"SpringMVC-2020-05-25-run","date":"2020-05-25T00:51:16.453Z","updated":"2020-06-18T08:23:05.325Z","comments":true,"path":"undefined/2bdb.html","link":"","permalink":"http://fyvan.github.io/undefined/2bdb.html","excerpt":"","text":"1. SpringMVC执行流程图解 2. 组件说明 DispatcherServlet：前端控制器。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性,系统扩展性提高。由框架实现 HandlerMapping：处理器映射器。HandlerMapping负责根据用户请求的url找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，根据一定的规则去查找,例如：xml配置方式，实现接口方式，注解方式等。由框架实现 Handler：处理器。Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。 HandlAdapter：处理器适配器。通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。由框架实现。 ModelAndView是springmvc的封装对象，将model和view封装在一起。 ViewResolver：视图解析器。ViewResolver负责将处理结果生成View视图，ViewResolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 View:是springmvc的封装对象，是一个接口, springmvc框架提供了很多的View视图类型，包括：jspview，pdfview,jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 3. Springmvc执行流程 用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求转发给处理器映射器HandlerMapping。 处理器映射器根据url请求找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。 DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作 执行处理器Handler(Controller，也叫页面控制器)。 Handler执行完成返回ModelAndView HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。 DispatcherServlet响应用户。 4. 执行流程代码4.1 用户发送url请求至前端控制器DispatcherServlet/** * Exposes the DispatcherServlet-specific request attributes and delegates to {@link #doDispatch} * for the actual dispatching. */ @Override protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { if (logger.isDebugEnabled()) { String requestUri = urlPathHelper.getRequestUri(request); logger.debug(\"DispatcherServlet with name '\" + getServletName() + \"' processing \" + request.getMethod() + \" request for [\" + requestUri + \"]\"); } //保护现场 // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object> attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) { logger.debug(\"Taking snapshot of request attributes before include\"); attributesSnapshot = new HashMap&lt;String, Object>(); Enumeration&lt;?> attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) { String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(\"org.springframework.web.servlet\")) { attributesSnapshot.put(attrName, request.getAttribute(attrName)); } } } //将框架相关信息存储至request，方便后面的处理器和视图用到 // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) { request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); } request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); //请求分发 try { doDispatch(request, response); } finally { // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) { restoreAttributesAfterInclude(request, attributesSnapshot); } } } 4.2 开始处理请求 通过url查找HandlerMap中最相近的key(url)，然后由key获取HandlerMapping对象 通过处理器映射器获取处理器 通过查询处理器适配器获得 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; int interceptorIndex = -1; try { ModelAndView mv; boolean errorView = false; try { processedRequest = checkMultipart(request); // Determine handler for the current request //步骤4.3.1~4.3.4用于获取包含处理器Handler和拦截器AdapterIntercepters的处理器执行链HandlerExecutionChain mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) { noHandlerFound(processedRequest, response); return; } // Determine handler adapter for the current request. //步骤4.4.1~4.4.2,根据HandlerExecutionChain中的处理器Handler获取处理器适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) { String requestUri = urlPathHelper.getRequestUri(request); logger.debug(\"Last-Modified value for [\" + requestUri + \"] is: \" + lastModified); } if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) { return; } } // Apply preHandle methods of registered interceptors. HandlerInterceptor[] interceptors = mappedHandler.getInterceptors(); if (interceptors != null) { for (int i = 0; i &lt; interceptors.length; i++) { HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(processedRequest, response, mappedHandler.getHandler())) { triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); return; } interceptorIndex = i; } } // Actually invoke the handler. //4.5.1~4.5.3通过处理器适配器HandlerApapter来调用处理器完成对请求的处理 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // Do we need view name translation? if (mv != null &amp;&amp; !mv.hasView()) { mv.setViewName(getDefaultViewName(request)); } // Apply postHandle methods of registered interceptors. if (interceptors != null) { for (int i = interceptors.length - 1; i >= 0; i--) { HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(processedRequest, response, mappedHandler.getHandler(), mv); } } } catch (ModelAndViewDefiningException ex) { logger.debug(\"ModelAndViewDefiningException encountered\", ex); mv = ex.getModelAndView(); } catch (Exception ex) { Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(processedRequest, response, handler, ex); errorView = (mv != null); } // Did the handler return a view to render? if (mv != null &amp;&amp; !mv.wasCleared()) { render(mv, processedRequest, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request); } } else { if (logger.isDebugEnabled()) { logger.debug(\"Null ModelAndView returned to DispatcherServlet with name '\" + getServletName() + \"': assuming HandlerAdapter completed request handling\"); } } // Trigger after-completion for successful outcome. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); } catch (Exception ex) { // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; } catch (Error err) { ServletException ex = new NestedServletException(\"Handler processing failed\", err); // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; } finally { // Clean up any resources used by a multipart request. if (processedRequest != request) { cleanupMultipart(processedRequest); } } } 4.3.1 getHandler(HttpServletRequest request)，经由HandlerMapping对象获取HandlerExecutionChain(处理器和拦截器)/** * Return the HandlerExecutionChain for this request. * &lt;p>Tries all handler mappings in order. * @param request current HTTP request * @return the HandlerExecutionChain, or &lt;code>null&lt;/code> if no handler could be found */ protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { for (HandlerMapping hm : this.handlerMappings) { if (logger.isTraceEnabled()) { logger.trace( \"Testing handler map [\" + hm + \"] in DispatcherServlet with name '\" + getServletName() + \"'\"); } HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) { return handler; } } return null; } 4.3.2.1 getHandler(HttpServletRequest request)，经由request获取处理器，获取处理器Handler后，再获取拦截器，最后组成HandlerExecutionChain/** * Look up a handler for the given request, falling back to the default * handler if no specific one is found. * @param request current HTTP request * @return the corresponding handler instance, or the default handler * @see #getHandlerInternal */ public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { Object handler = getHandlerInternal(request); if (handler == null) { handler = getDefaultHandler(); } if (handler == null) { return null; } // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } return getHandlerExecutionChain(handler, request); } 4.3.2.2 根据查找到的处理器Handler和request获取包含Handler和AdaptedInterceptors的HandlerExecutionChainprotected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) { HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain) ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler); chain.addInterceptors(getAdaptedInterceptors()); String lookupPath = urlPathHelper.getLookupPathForRequest(request); for (MappedInterceptor mappedInterceptor : mappedInterceptors) { if (mappedInterceptor.matches(lookupPath, pathMatcher)) { chain.addInterceptor(mappedInterceptor.getInterceptor()); } } return chain; } /** * Return the adapted interceptors as HandlerInterceptor array. * @return the array of HandlerInterceptors, or &lt;code>null&lt;/code> if none */ protected final HandlerInterceptor[] getAdaptedInterceptors() { int count = adaptedInterceptors.size(); return (count > 0) ? adaptedInterceptors.toArray(new HandlerInterceptor[count]) : null; } 4.3.3 getHandlerInternal(HttpServletRequest request)获取Handler/** * Look up a handler for the URL path of the given request. * @param request current HTTP request * @return the handler instance, or &lt;code>null&lt;/code> if none found */ @Override protected Object getHandlerInternal(HttpServletRequest request) throws Exception { String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); Object handler = lookupHandler(lookupPath, request); if (handler == null) { // We need to care for the default handler directly, since we need to // expose the PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE for it as well. Object rawHandler = null; if (\"/\".equals(lookupPath)) { rawHandler = getRootHandler(); } if (rawHandler == null) { rawHandler = getDefaultHandler(); } if (rawHandler != null) { // Bean name or resolved handler? if (rawHandler instanceof String) { String handlerName = (String) rawHandler; rawHandler = getApplicationContext().getBean(handlerName); } validateHandler(rawHandler, request); handler = buildPathExposingHandler(rawHandler, lookupPath, lookupPath, null); } } if (handler != null &amp;&amp; logger.isDebugEnabled()) { logger.debug(\"Mapping [\" + lookupPath + \"] to \" + handler); } else if (handler == null &amp;&amp; logger.isTraceEnabled()) { logger.trace(\"No handler mapping found for [\" + lookupPath + \"]\"); } return handler; } 4.3.4 lookupHandler(lookupPath, request)根据给定url path和request获取Handlerprotected Object lookupHandler(String urlPath, HttpServletRequest request) throws Exception { // Direct match? Object handler = this.handlerMap.get(urlPath); if (handler != null) { // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } validateHandler(handler, request); return buildPathExposingHandler(handler, urlPath, urlPath, null); } // Pattern match? List&lt;String> matchingPatterns = new ArrayList&lt;String>(); for (String registeredPattern : this.handlerMap.keySet()) { if (getPathMatcher().match(registeredPattern, urlPath)) { matchingPatterns.add(registeredPattern); } } String bestPatternMatch = null; Comparator&lt;String> patternComparator = getPathMatcher().getPatternComparator(urlPath); if (!matchingPatterns.isEmpty()) { Collections.sort(matchingPatterns, patternComparator); if (logger.isDebugEnabled()) { logger.debug(\"Matching patterns for request [\" + urlPath + \"] are \" + matchingPatterns); } bestPatternMatch = matchingPatterns.get(0); } if (bestPatternMatch != null) { handler = this.handlerMap.get(bestPatternMatch); // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); } validateHandler(handler, request); String pathWithinMapping = getPathMatcher().extractPathWithinPattern(bestPatternMatch, urlPath); // There might be multiple 'best patterns', let's make sure we have the correct URI template variables // for all of them Map&lt;String, String> uriTemplateVariables = new LinkedHashMap&lt;String, String>(); for (String matchingPattern : matchingPatterns) { if (patternComparator.compare(bestPatternMatch, matchingPattern) == 0) { uriTemplateVariables .putAll(getPathMatcher().extractUriTemplateVariables(matchingPattern, urlPath)); } } if (logger.isDebugEnabled()) { logger.debug(\"URI Template variables for request [\" + urlPath + \"] are \" + uriTemplateVariables); } return buildPathExposingHandler(handler, bestPatternMatch, pathWithinMapping, uriTemplateVariables); } // No handler found... return null; } 4.4.1 HandlerAdapter getHandlerAdapter(Object handler)根据Handler获取HandlerAdapter/** * Return the HandlerAdapter for this handler object. * @param handler the handler object to find an adapter for * @throws ServletException if no HandlerAdapter can be found for the handler. This is a fatal error. */ protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException { for (HandlerAdapter ha : this.handlerAdapters) { if (logger.isTraceEnabled()) { logger.trace(\"Testing handler adapter [\" + ha + \"]\"); } if (ha.supports(handler)) { return ha; } } throw new ServletException(\"No adapter for handler [\" + handler + \"]: Does your handler implement a supported interface like Controller?\"); } 4.4.2 supports(Object handler)public boolean supports(Object handler) { return (handler instanceof Controller); } 4.5.1 使用处理器完成对请求的处理public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { ((Servlet) handler).service(request, response); return null; } public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { HttpServletRequest request; HttpServletResponse response; if (!(req instanceof HttpServletRequest &amp;&amp; res instanceof HttpServletResponse)) { throw new ServletException(\"non-HTTP request or response\"); } request = (HttpServletRequest) req; response = (HttpServletResponse) res; service(request, response); } 4.5.2 service(HttpServletRequest req, HttpServletResponse resp)protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { long lastModified = getLastModified(req); if (lastModified == -1) { // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); } else { long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) { // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); } else { resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } } } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); } } 4.5.3 doGet(HttpServletRequest req, HttpServletResponse resp)protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String protocol = req.getProtocol(); String msg = lStrings.getString(\"http.method_get_not_supported\"); if (protocol.endsWith(\"1.1\")) { resp.sendError(HttpServletResponse.SC_METHOD_NOT_ALLOWED, msg); } else { resp.sendError(HttpServletResponse.SC_BAD_REQUEST, msg); } } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"框架,spring","slug":"框架-spring","permalink":"http://fyvan.github.io/categories/%E6%A1%86%E6%9E%B6-spring/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://fyvan.github.io/tags/SpringMVC/"}],"author":"fyang"},{"title":"Docker 安装 MongoDB","slug":"SoftwareInstall-2020-05-24-use-docker-install-mongodb","date":"2020-05-24T13:28:05.303Z","updated":"2020-06-18T08:18:52.586Z","comments":true,"path":"undefined/b285.html","link":"","permalink":"http://fyvan.github.io/undefined/b285.html","excerpt":"","text":"1. 搜索镜像查找Docker Hub上的mongo镜像。 root@Aspire:~# docker search mongo NAME DESCRIPTION STARS OFFICIAL AUTOMATED mongo MongoDB document databases provide high avai… 6877 [OK] mongo-express Web-based MongoDB admin interface, written w… 692 [OK] tutum/mongodb MongoDB Docker image – listens in port 27017… 230 [OK] 2. 拉取MongoDB镜像拉取Docker Hub上的mongo镜像。 root@Aspire:~# docker pull mongo Using default tag: latest latest: Pulling from library/mongo 23884877105a: Downloading [============> ] 6.626MB/26.69MB bc38caa0f5b9: Download complete 2910811b6c42: Download complete 36505266dcc6: Download complete a4d269900d94: Download complete 5e2526abb80a: Download complete d3eece1f39ec: Download complete 358ed78d3204: Download complete 1a878b8604ae: Download complete dde03a2883d0: Download complete 4ffe534daa34: Downloading [=======> ] 19.36MB/129.1MB f164ba21e17c: Download complete 6494c387442c: Download complete 3. 查看本地镜像列表查看MongoDB镜像是否拉取成功。 root@Aspire:~# docker images | grep mongo mongo latest 3f3daf863757 4 weeks ago 388MB 4. 创建存储目录创建MongoDB持久化文件目录。 mkdir -p /home/data/mongo/data 5. 启动容器options说明: –restart=always: 重启策略 -d: 后台运行容器，并返回容器ID -p: 端口映射，格式为：主机(宿主)端口:容器端口 –name: 为容器指定一个名称 -v: 给容器挂载存储卷，挂载到容器的某个目录 root@Aspire:~# docker run --restart=always -p 27017:27017 --name mongo -v /home/data/mongo/data:/data/db -d mongo --auth #启动后的信息 96e65e736ef5fa393b0b04bad17f955cb94bc6b1b378b534166ccba87e003366 6. 查看容器信息查看容器ID信息 root@Aspire:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 96e65e736ef5 mongo \"docker-entrypoint.s…\" 4 minutes ago Up 4 minutes 0.0.0.0:27017->27017/tcp mongo 7. 配置MongoDB权限以admin用户身份进入mongo 命令: docker exec -it 容器ID mongo admin root@Aspire:~# docker exec -it 96e65e736ef5 mongo admin > db.createUser({user: 'admin', pwd: 'admin', roles: [{role: \"root\", db: \"admin\"}]}); Successfully added user: { \"user\" : \"admin\", \"roles\" : [ { \"role\" : \"root\", \"db\" : \"admin\" } ] } > exit;MongoDB shell version v4.2.6 connecting to: mongodb://127.0.0.1:27017/admin?compressors=disabled&amp;gssapiServiceName=mongodb Implicit session: session { \"id\" : UUID(\"ed34651c-15c1-4b1a-8074-c44976f7b48f\") } MongoDB server version: 4.2.6 Welcome to the MongoDB shell. For interactive help, type \"help\". For more comprehensive documentation, see http://docs.mongodb.org/ Questions? Try the support group http://groups.google.com/group/mongodb-user > > db.createUser({user: 'admin', pwd: 'admin', roles: [{role: \"root\", db: \"admin\"}]}); 2020-05-24T15:43:19.449+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > Successfully added user: { ... \"user\" : \"admin\", ... \"roles\" : [ ... { ... \"role\" : \"root\", ... \"db\" : \"admin\" ... } ... ] ... } 2020-05-24T15:43:19.452+0000 E QUERY [js] uncaught exception: SyntaxError: unexpected token: identifier : @(shell):1:13 > > exit; 2020-05-24T15:43:27.456+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > 8. 测试测试否OK, MongoDB身份认证 root@Aspire:~# docker exec -it 96e65e736ef5 mongo admin > db.auth(\"admin\", \"admin\"); 1 > exit;MongoDB shell version v4.2.6 connecting to: mongodb://127.0.0.1:27017/admin?compressors=disabled&amp;gssapiServiceName=mongodb Implicit session: session { \"id\" : UUID(\"d2573daf-38b0-430e-aed3-e36187e8c800\") } MongoDB server version: 4.2.6 > > db.auth(\"admin\", \"admin\"); 2020-05-24T15:45:54.154+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > 1 1 > > exit; 2020-05-24T15:45:58.341+0000 E QUERY [js] uncaught exception: SyntaxError: expected expression, got '>' : @(shell):1:0 > > document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"}],"tags":[{"name":"Ubantu,MongoDB","slug":"Ubantu-MongoDB","permalink":"http://fyvan.github.io/tags/Ubantu-MongoDB/"}],"author":"fyang"},{"title":"hello hexo","slug":"hello-world","date":"2020-05-24T03:24:07.081Z","updated":"2020-05-24T07:50:33.460Z","comments":true,"path":"undefined/b659.html","link":"","permalink":"http://fyvan.github.io/undefined/b659.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[],"tags":[]}],"categories":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/categories/JVM/"},{"name":"面试","slug":"面试","permalink":"http://fyvan.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Project","slug":"Project","permalink":"http://fyvan.github.io/categories/Project/"},{"name":"software","slug":"software","permalink":"http://fyvan.github.io/categories/software/"},{"name":"多线程","slug":"多线程","permalink":"http://fyvan.github.io/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"API","slug":"API","permalink":"http://fyvan.github.io/categories/API/"},{"name":"Software","slug":"Software","permalink":"http://fyvan.github.io/categories/Software/"},{"name":"框架,spring","slug":"框架-spring","permalink":"http://fyvan.github.io/categories/%E6%A1%86%E6%9E%B6-spring/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://fyvan.github.io/tags/JVM/"},{"name":"Spring","slug":"Spring","permalink":"http://fyvan.github.io/tags/Spring/"},{"name":"Tomcat","slug":"Tomcat","permalink":"http://fyvan.github.io/tags/Tomcat/"},{"name":"jt","slug":"jt","permalink":"http://fyvan.github.io/tags/jt/"},{"name":"redis","slug":"redis","permalink":"http://fyvan.github.io/tags/redis/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://fyvan.github.io/tags/Zookeeper/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"http://fyvan.github.io/tags/IntelliJ-IDEA/"},{"name":"synchronized","slug":"synchronized","permalink":"http://fyvan.github.io/tags/synchronized/"},{"name":"ObjectMapper","slug":"ObjectMapper","permalink":"http://fyvan.github.io/tags/ObjectMapper/"},{"name":"Docker","slug":"Docker","permalink":"http://fyvan.github.io/tags/Docker/"},{"name":"CentOS7, Redis","slug":"CentOS7-Redis","permalink":"http://fyvan.github.io/tags/CentOS7-Redis/"},{"name":"CentOS7, mariadb","slug":"CentOS7-mariadb","permalink":"http://fyvan.github.io/tags/CentOS7-mariadb/"},{"name":"CentOS7, Nginx","slug":"CentOS7-Nginx","permalink":"http://fyvan.github.io/tags/CentOS7-Nginx/"},{"name":"CentOS7, jdk1.8","slug":"CentOS7-jdk1-8","permalink":"http://fyvan.github.io/tags/CentOS7-jdk1-8/"},{"name":"MySql","slug":"MySql","permalink":"http://fyvan.github.io/tags/MySql/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://fyvan.github.io/tags/SpringMVC/"},{"name":"Ubantu,MongoDB","slug":"Ubantu-MongoDB","permalink":"http://fyvan.github.io/tags/Ubantu-MongoDB/"}]}